<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Pascal's Triangle C++ coding challenge</title>
        
        <meta name="robots" content="noindex" />
        
        


        <!-- Custom HTML head -->
        


        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="A discussion of C++ programming techniques through the medium of Pascal's Triangle">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        
        <link rel="stylesheet" href="fonts/fonts.css">
        

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="pascals_triangle.html">Pascal's Triangle Coding Challenge</a></li><li class="chapter-item expanded affix "><a href="submissions.html">Submissions</a></li><li class="chapter-item expanded "><a href="loops/loops.html"><strong aria-hidden="true">1.</strong> Loops make the world go round (and round...)</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="loops/dont_do_unnecessary_work.html"><strong aria-hidden="true">1.1.</strong> Don't do more work than you need to?</a></li><li class="chapter-item expanded "><a href="loops/memory_allocation_matters.html"><strong aria-hidden="true">1.2.</strong> Memory allocation matters</a></li><li class="chapter-item expanded "><a href="loops/tracing_function_calls.html"><strong aria-hidden="true">1.3.</strong> Tracing function calls</a></li><li class="chapter-item expanded "><a href="loops/cost_of_allocation.html"><strong aria-hidden="true">1.4.</strong> Cost of allocation</a></li><li class="chapter-item expanded "><a href="loops/be_kind_to_your_cache.html"><strong aria-hidden="true">1.5.</strong> Be kind to your cache</a></li><li class="chapter-item expanded "><a href="loops/span.html"><strong aria-hidden="true">1.6.</strong> When everything looks like a nail</a></li><li class="chapter-item expanded "><a href="loops/summary.html"><strong aria-hidden="true">1.7.</strong> Summary</a></li></ol></li><li class="chapter-item expanded "><a href="everything_is_a_matrix.html"><strong aria-hidden="true">2.</strong> Everything is a matrix</a></li><li class="chapter-item expanded "><a href="stl_algorithms.html"><strong aria-hidden="true">3.</strong> STL algorithms</a></li><li class="chapter-item expanded "><a href="threads/threads_to_the_rescue.html"><strong aria-hidden="true">4.</strong> Threads to the rescue!</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="threads/async.html"><strong aria-hidden="true">4.1.</strong> Making a stink about std::async</a></li><li class="chapter-item expanded "><a href="threads/work_stealing.html"><strong aria-hidden="true">4.2.</strong> Work stealing</a></li><li class="chapter-item expanded "><a href="threads/allocators.html"><strong aria-hidden="true">4.3.</strong> Allocators</a></li><li class="chapter-item expanded "><a href="threads/amdahls_law.html"><strong aria-hidden="true">4.4.</strong> Use moar cores!</a></li><li class="chapter-item expanded "><a href="threads/cleverness.html"><strong aria-hidden="true">4.5.</strong> Clever ain't always fast</a></li><li class="chapter-item expanded "><a href="threads/summary.html"><strong aria-hidden="true">4.6.</strong> Summary</a></li></ol></li><li class="chapter-item expanded "><a href="all_your_tests_are_terrible.html"><strong aria-hidden="true">5.</strong> All your tests are terrible!</a></li><li class="chapter-item expanded "><a href="laziness.html"><strong aria-hidden="true">6.</strong> Laziness is the first step towards efficiency</a></li><li class="chapter-item expanded "><a href="ranges.html"><strong aria-hidden="true">7.</strong> How to kill your compile times</a></li><li class="chapter-item expanded "><a href="constexpr_cake.html"><strong aria-hidden="true">8.</strong> Have your constexpr cake and eat it</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="optimizer_magic.html"><strong aria-hidden="true">8.1.</strong> The optimizer is magic</a></li></ol></li><li class="chapter-item expanded "><a href="property_based_testing.html"><strong aria-hidden="true">9.</strong> A surprise win for property based testing</a></li><li class="chapter-item expanded "><a href="code_alignment_issues.html"><strong aria-hidden="true">10.</strong> A free 50% speed boost. Randomly.</a></li><li class="chapter-item expanded "><a href="conclusion.html"><strong aria-hidden="true">11.</strong> Conclusion</a></li><li class="chapter-item expanded "><a href="appendices/problem_statement.html"><strong aria-hidden="true">12.</strong> Appendix I - Original problem statement</a></li><li class="chapter-item expanded "><a href="appendices/test_setup.html"><strong aria-hidden="true">13.</strong> Appendix II - Benchmark hardware and setup</a></li><li class="chapter-item expanded "><a href="submissions_appendix.html"><strong aria-hidden="true">14.</strong> Appendix III - Submissions</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="solutions/Baseline.html"><strong aria-hidden="true">14.1.</strong> Baseline</a></li><li class="chapter-item expanded "><a href="solutions/AskingCrow.html"><strong aria-hidden="true">14.2.</strong> AskingCrow</a></li><li class="chapter-item expanded "><a href="solutions/BumbleBeetle.html"><strong aria-hidden="true">14.3.</strong> BumbleBeetle</a></li><li class="chapter-item expanded "><a href="solutions/CluelessWolverine.html"><strong aria-hidden="true">14.4.</strong> CluelessWolverine</a></li><li class="chapter-item expanded "><a href="solutions/CluelessWolverine2.html"><strong aria-hidden="true">14.5.</strong> CluelessWolverine2</a></li><li class="chapter-item expanded "><a href="solutions/Fortran4Ever.html"><strong aria-hidden="true">14.6.</strong> Fortran4Ever</a></li><li class="chapter-item expanded "><a href="solutions/simple_basic_solution.html"><strong aria-hidden="true">14.7.</strong> simple_basic_solution</a></li><li class="chapter-item expanded "><a href="solutions/user_usery.html"><strong aria-hidden="true">14.8.</strong> user_usery</a></li><li class="chapter-item expanded "><a href="solutions/FlyingDesitter_arh.html"><strong aria-hidden="true">14.9.</strong> FlyingDesitter_arh</a></li><li class="chapter-item expanded "><a href="solutions/pascalsTriangle.for.html"><strong aria-hidden="true">14.10.</strong> pascalsTriangle.for</a></li><li class="chapter-item expanded "><a href="solutions/GroovyZone.html"><strong aria-hidden="true">14.11.</strong> GroovyZone</a></li><li class="chapter-item expanded "><a href="solutions/LordVader.html"><strong aria-hidden="true">14.12.</strong> LordVader</a></li><li class="chapter-item expanded "><a href="solutions/LordVader2_arh.html"><strong aria-hidden="true">14.13.</strong> LordVader2_arh</a></li><li class="chapter-item expanded "><a href="solutions/Pixelf.html"><strong aria-hidden="true">14.14.</strong> Pixelf</a></li><li class="chapter-item expanded "><a href="solutions/Pixelf_TBB_arh.html"><strong aria-hidden="true">14.15.</strong> Pixelf_TBB_arh</a></li><li class="chapter-item expanded "><a href="solutions/Pixelf_TBB_scalable_alloc_arh.html"><strong aria-hidden="true">14.16.</strong> Pixelf_TBB_scalable_alloc_arh</a></li><li class="chapter-item expanded "><a href="solutions/Pixelf_TBB_boost_arh.html"><strong aria-hidden="true">14.17.</strong> Pixelf_TBB_boost_arh</a></li><li class="chapter-item expanded "><a href="solutions/Pixelf_TBB_monotonic_alloc_arh.html"><strong aria-hidden="true">14.18.</strong> Pixelf_TBB_monotonic_alloc_arh</a></li><li class="chapter-item expanded "><a href="solutions/Pixelf_TBB_single_array_arh.html"><strong aria-hidden="true">14.19.</strong> Pixelf_TBB_single_array_arh</a></li><li class="chapter-item expanded "><a href="solutions/Pixelf_TBB_spans_arh.html"><strong aria-hidden="true">14.20.</strong> Pixelf_TBB_spans_arh</a></li><li class="chapter-item expanded "><a href="solutions/DigitalGerbil.html"><strong aria-hidden="true">14.21.</strong> DigitalGerbil</a></li><li class="chapter-item expanded "><a href="solutions/TerrificPhantom.html"><strong aria-hidden="true">14.22.</strong> TerrificPhantom</a></li><li class="chapter-item expanded "><a href="solutions/Porpoison.html"><strong aria-hidden="true">14.23.</strong> Porpoison</a></li><li class="chapter-item expanded "><a href="solutions/ArchBanana.html"><strong aria-hidden="true">14.24.</strong> ArchBanana</a></li><li class="chapter-item expanded "><a href="solutions/ArchBanana2_arh.html"><strong aria-hidden="true">14.25.</strong> ArchBanana2_arh</a></li><li class="chapter-item expanded "><a href="solutions/EvilDoughnut.html"><strong aria-hidden="true">14.26.</strong> EvilDoughnut</a></li><li class="chapter-item expanded "><a href="solutions/FrostyMongoose.html"><strong aria-hidden="true">14.27.</strong> FrostyMongoose</a></li><li class="chapter-item expanded "><a href="solutions/Proteus.html"><strong aria-hidden="true">14.28.</strong> Proteus</a></li><li class="chapter-item expanded "><a href="solutions/Erwin.html"><strong aria-hidden="true">14.29.</strong> Erwin</a></li><li class="chapter-item expanded "><a href="solutions/FireFly.html"><strong aria-hidden="true">14.30.</strong> FireFly</a></li><li class="chapter-item expanded "><a href="solutions/LightningHippo_arh.html"><strong aria-hidden="true">14.31.</strong> LightningHippo_arh</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                        
                    </div>

                    <h1 class="menu-title">Pascal's Triangle C++ coding challenge</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        
                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" name="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1><a class="header" href="#pascals-triangle-coding-challenge" id="pascals-triangle-coding-challenge">Pascal's Triangle Coding Challenge</a></h1>
<p><em>by Alastair Harrison</em></p>
<style>
.center {
  display: block;
  margin-left: auto;
  margin-right: auto;
  width: 50%;
}
</style>
<p>
<img src="images/pascals_triangle.svg" style="width:50%" class="center">
</p><br/>
<p>In May 2020, I set a mini C++ coding challenge for friends and colleagues where
the task was to write a simple program to generate Pascal's Triangle. The idea
was that we'd have a bit of a chat about the different design decisions people
made and see which approach was 'best'.</p>
<p>That's not quite what happened though. I received a good number of submissions
and immediately set about writing benchmarks. It turned out that some solutions
were <strong>hundreds</strong> of times faster than others.</p>
<p>I came up with hypotheses about what was happening, only to have those
hypotheses torn to shreds when I tried to prove them. I asked experts for help.
They casually suggested avenues of investigation that ended up taking weeks of
effort to chase down, but yielded some fascinating insights along the way.</p>
<p>At one point in the journey, I noticed something deeply unsettling about my
benchmarks: I'd deleted <em>one</em> line from a program because it wasn't necessary
and the benchmark suddenly took <strong>twice as long</strong> to run. How can a program get
<em>so much slower</em> when it's doing less work?! And what use is a benchmark if it
isn't robust to apparently innocuous changes in the code?</p>
<p>What you'll find here are the surprising and interesting results of my
absurd struggle to get to the bottom of what was going on. Along the way we'll
encounter all sorts of useful tools for peering inside the inner workings of a
C++ program.</p>
<p>We'll talk about algorithms, memory allocation, cache friendliness,
multi-threading, testing strategies, stealing and downright cheating. And some
other stuff, too.</p>
<p>Thanks to everyone who submitted a solution or a review! And thanks to Arnaud
Desitter, Geoff Hester and Kirsty McNaught for their patience and excellent
advice.</p>
<p>You can see the original problem statement in
<a href="appendices/problem_statement.html">Appendix I - Original Problem Statement</a>.</p>
<h1><a class="header" href="#submissions-received" id="submissions-received">Submissions received</a></h1>
<p>This is a list of all of the submissions I received for the coding challenge.
The links will take you to the source code as well as any reviews that were
received for the submission.</p>
<p><strong>Submissions that have the suffix <code>_arh</code> are ones that I created in order to
demonstrate interesting things.</strong></p>
<p>I don't suggest that you dive in to these links immediately. The text will guide
you through the most important features.</p>
<h3><a class="header" href="#baseline-solution" id="baseline-solution">Baseline solution</a></h3>
<ul>
<li><a href="./solutions/Baseline.html">Baseline</a></li>
</ul>
<h3><a class="header" href="#a-hrefloopsloopshtmlloops-make-the-world-go-round-and-rounda" id="a-hrefloopsloopshtmlloops-make-the-world-go-round-and-rounda"><a href="./loops/loops.html">Loops make the world go round (and round...)</a></a></h3>
<ul>
<li><a href="./solutions/AskingCrow.html">AskingCrow</a></li>
<li><a href="./solutions/BumbleBeetle.html">BumbleBeetle</a></li>
<li><a href="./solutions/CluelessWolverine.html">CluelessWolverine</a></li>
<li><a href="./solutions/CluelessWolverine2.html">CluelessWolverine2</a></li>
<li><a href="./solutions/Fortran4Ever.html">Fortran4Ever</a></li>
<li><a href="./solutions/simple_basic_solution.html">simple_basic_solution</a></li>
<li><a href="./solutions/user_usery.html">user_usery</a></li>
<li><a href="./solutions/FlyingDesitter_arh.html">FlyingDesitter_arh</a></li>
</ul>
<h3><a class="header" href="#a-hrefeverything_is_a_matrixhtmleverything-is-a-matrixa" id="a-hrefeverything_is_a_matrixhtmleverything-is-a-matrixa"><a href="everything_is_a_matrix.html">Everything is a matrix</a></a></h3>
<ul>
<li><a href="./solutions/pascalsTriangle.for.html">pascalsTriangle.for</a></li>
</ul>
<h3><a class="header" href="#a-hrefstl_algorithmshtmlstl-algorithms-have-awful-namesa" id="a-hrefstl_algorithmshtmlstl-algorithms-have-awful-namesa"><a href="stl_algorithms.html">STL algorithms have awful names</a></a></h3>
<ul>
<li><a href="./solutions/GroovyZone.html">GroovyZone</a></li>
<li><a href="./solutions/LordVader.html">LordVader</a></li>
</ul>
<h3><a class="header" href="#a-hrefthreadsthreads_to_the_rescuehtmlthreads-to-the-rescuea" id="a-hrefthreadsthreads_to_the_rescuehtmlthreads-to-the-rescuea"><a href="./threads/threads_to_the_rescue.html">Threads to the rescue!</a></a></h3>
<ul>
<li><a href="./solutions/Pixelf.html">Pixelf</a></li>
<li><a href="./solutions/Pixelf_TBB_arh.html">Pixelf_TBB_arh</a></li>
<li><a href="./solutions/Pixelf_TBB_scalable_alloc_arh.html">Pixelf_TBB_scalable_alloc_arh</a></li>
<li><a href="./solutions/Pixelf_TBB_spans_arh.html">Pixelf_TBB_spans_arh</a></li>
<li><a href="./solutions/Pixelf_TBB_boost_arh.html">Pixelf_TBB_boost_arh</a></li>
<li><a href="./solutions/Pixelf_TBB_monotonic_alloc_arh.html">Pixelf_TBB_monotonic_alloc_arh</a></li>
<li><a href="./solutions/Pixelf_TBB_single_array_arh.html">Pixelf_TBB_single_array_arh</a></li>
</ul>
<h3><a class="header" href="#a-hrefall_your_tests_are_terriblehtmlall-your-tests-are-terriblea" id="a-hrefall_your_tests_are_terriblehtmlall-your-tests-are-terriblea"><a href="./all_your_tests_are_terrible.html">All your tests are terrible</a></a></h3>
<ul>
<li><a href="./solutions/DigitalGerbil.html">DigitalGerbil</a></li>
<li><a href="./solutions/TerrificPhantom.html">TerrificPhantom</a></li>
</ul>
<h3><a class="header" href="#a-hreflazinesshtmllaziness-is-the-first-step-towards-efficiencya" id="a-hreflazinesshtmllaziness-is-the-first-step-towards-efficiencya"><a href="laziness.html">Laziness is the first step towards efficiency</a></a></h3>
<ul>
<li><a href="./solutions/Porpoison.html">Porpoison</a></li>
</ul>
<h3><a class="header" href="#a-hrefrangeshtmlhow-to-kill-your-compile-timesa" id="a-hrefrangeshtmlhow-to-kill-your-compile-timesa"><a href="ranges.html">How to kill your compile times</a></a></h3>
<ul>
<li><a href="./solutions/ArchBanana.html">ArchBanana</a></li>
<li><a href="./solutions/ArchBanana2_arh.html">ArchBanana2_arh</a></li>
<li><a href="./solutions/EvilDoughnut.html">EvilDoughnut</a></li>
<li><a href="./solutions/FrostyMongoose.html">FrostyMongoose</a></li>
<li><a href="./solutions/Proteus.html">Proteus</a></li>
</ul>
<h3><a class="header" href="#a-hrefconstexpr_cakehtmlhave-your-constexpr-cake-and-eat-ita" id="a-hrefconstexpr_cakehtmlhave-your-constexpr-cake-and-eat-ita"><a href="constexpr_cake.html">Have your constexpr cake and eat it</a></a></h3>
<ul>
<li><a href="./solutions/Erwin.html">Erwin</a></li>
<li><a href="./solutions/FireFly.html">FireFly</a></li>
<li><a href="./solutions/LightningHippo_arh.html">LightningHippo_arh</a></li>
</ul>
<h1><a class="header" href="#loops-make-the-world-go-round-and-round" id="loops-make-the-world-go-round-and-round">Loops make the world go round (and round...)</a></h1>
<p>We're going to start the journey by looking at some of the obvious and easily
fixed gotchas that silently drag down the performance of our programs.</p>
<p>Loops are the bread and butter of daily programming. As you'd expect, most
submissions for the Pascal's Triangle challenge were implemented in terms of a
pair of nested loops. The outer loop iterates over the rows of the triangle, and
the inner loop generates the elements in each row.</p>
<img src="loops/../images/row_scan.jpg" alt="row scan pattern" width="40%" class="center">
<p>The reviewers almost universally found these solutions to be readable and
maintainable, and guessed that they would all perform equally. Despite that,
many of the 'raw loop' based submissions contained some rough edges that made
them run quite a bit slower than necessary.</p>
<p>We're not just talking a few percent, either. The best performing of the bunch
is around <strong>7 times faster</strong> than the worst performing one, despite their very
similar code. The other loop-based solutions show a spread of performance between
those two extremes.</p>
<p>By applying the lessons learned from studying the submissions, we'll make a
version which is an impressive <strong>20 times faster</strong> than the worst performing
loop-based solution.</p>
<h2><a class="header" href="#spot-the-difference" id="spot-the-difference">Spot the difference</a></h2>
<p>In this section we'll concentrate mainly on two particular submissions:</p>
<ul>
<li><a href="loops/../solutions/AskingCrow.html">AskingCrow</a></li>
<li><a href="loops/../solutions/CluelessWolverine2.html">CluelessWolverine2</a></li>
</ul>
<p>Let's kick off by looking at their main logic side-by-side:</p>
<table>
<tr>
<th>
<a href="loops/../solutions/AskingCrow.html">AskingCrow</a>
</th>
<th>
<a href="loops/../solutions/CluelessWolverine2.html">CluelessWolverine2</a>
</th>
</tr>
<tr>
<td valign="top">
<pre><code class="language-c++"><!--
-->auto generate_rows(uint32_t num_rows) {
  std::vector&lt;std::vector&lt;uint64_t&gt;&gt; rows;
  std::vector&lt;uint64_t&gt; previous_row;

  while (rows.size() &lt num_rows) {
    std::vector&lt;uint64_t&gt; new_row;
    uint64_t previous_element = 0;
    for (const auto element : previous_row) {
      new_row.push_back(previous_element + element);
      previous_element = element;
    }

    new_row.push_back(1);
    rows.push_back(new_row);
    previous_row = new_row;
  }
  return rows;
}
</code></pre>
</td>
<td  valign="top">
<pre><code class="language-c++"><!--
-->auto generate_rows(uint32_t num_rows) {
  std::vector&lt;std::vector&lt;uint64_t&gt;&gt; triangle;
  triangle.reserve(num_rows);

  for (uint32_t i = 0; i &lt num_rows; i++) {
    std::vector&lt;uint64_t&gt; row(i + 1, 1);

    for (uint32_t j = 1; j &lt (i + 2) / 2; j++) {
      row[j] = row[i - j]
             = triangle[i - 1][j - 1] + triangle[i - 1][j];
    }

    triangle.push_back(std::move(row));
  }
  return triangle;
}
</code></pre>
</td>
</tr>
</table>
<p>At first glance they look very similar, but they're actually two extremes of the
performance spectrum amongst the loop-based submissions.</p>
<p>To show this, I set up a benchmark measuring the <strong>element throughput</strong> for each
of them. That's a measure of <strong>how many elements of pascal's triangle are
generated per second</strong>, plotted for a range of different triangle sizes. Higher is
better!</p>
<p><a href="loops/../images/generated/loops_best_and_worst_generate_throughput_log_scale_bench.svg"><img src="loops/../images/generated/loops_best_and_worst_generate_throughput_log_scale_bench.svg" alt="" /></a></p>
<p><em>These benchmarks are plotted on a log-log scale. Small differences in the
graphs may correspond to very large actual differences.</em></p>
<p>The vertical red line is important. It marks the point where integer overflow
occurs in the row values, because a 64-bit unsigned integer isn't large enough
to hold the correct values. Generating triangles larger than this is
<em>pointless</em>, as their contents become complete garbage. Nonetheless I thought it
would be fun to drive the algorithms beyond their valid domain, as there are
some quite interesting things going on.</p>
<p>For triangles with 64 rows (right on the red line), <a href="loops/../solutions/AskingCrow.html">AskingCrow</a>
is generating just over 40 million elements per second. Its competitor,
<a href="loops/../solutions/CluelessWolverine2.html">CluelessWolverine2</a> is banging out a
remarkable 316 million elements per second.</p>
<p>Take a look at those two code snippets again. How many things can you see that
might explain the difference in speed? When you're ready, click on.</p>
<style>
.center {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
</style>
<h1><a class="header" href="#dont-do-more-work-than-you-need-to" id="dont-do-more-work-than-you-need-to">Don't do more work than you need to?</a></h1>
<p>It's usually a good idea to avoid computing things that you don't need to
compute. <a href="loops/../solutions/CluelessWolverine2.html">CluelessWolverine2</a> takes
advantage of the fact that the rows of Pascal's triangle are symmetrical. It
computes only half of each row by summing pairs of values from the previous row,
but writes the value twice; once in the first half of the output row and again
in the second half of the row:</p>
<img src="loops/../images/bidirectional_fill.jpeg" alt="bidirectional fill" width="40%" class="center">
<p>Here's the code:</p>
<pre><code class="language-c++">for (uint32_t j = 1; j &lt; (i + 2) / 2; j++) {
  // Compute each non-1 entry and assign to both sides of triangle
  row[j] = row[i - j] = triangle[i - 1][j - 1] + triangle[i - 1][j];
}
</code></pre>
<p>Clever. But is it worth doing?</p>
<p>I created a new solution called <a href="loops/../solutions/Baseline.html">Baseline</a> which is
essentially <a href="loops/../solutions/CluelessWolverine2.html">CluelessWolverine2</a> without the
half-row optimisation. It's what I'd consider to be the 'canonical' nested-loop
solution.</p>
<table>
<tr>
<th>
<a href="loops/../solutions/Baseline.html">Baseline</a>
</th>
<th>
<a href="loops/../solutions/CluelessWolverine2.html">CluelessWolverine2</a>
</th>
</tr>
<tr>
<td valign="top">
<pre><code class="language-c++"><!--
-->auto generate_rows(uint32_t num_rows) {
  std::vector&lt;std::vector&lt;uint64_t&gt;&gt; triangle;
  triangle.reserve(num_rows);

  for (uint32_t i = 0; i &lt num_rows; ++i) {
    std::vector&lt;uint64_t&gt; row(i + 1, 1);

    for (uint32_t j = 1; j &lt i; ++j) {
      row[j] = triangle[i - 1][j - 1] + triangle[i - 1][j];
    }

    triangle.push_back(std::move(row));
  }
  return triangle;
}
</code></pre>
</td>
<td valign="top">
<pre><code class="language-c++"><!--
-->auto generate_rows(uint32_t num_rows) {
  std::vector&lt;std::vector&lt;uint64_t&gt;&gt; triangle;
  triangle.reserve(num_rows);

  for (uint32_t i = 0; i &lt num_rows; i++) {
    std::vector&lt;uint64_t&gt; row(i + 1, 1);

    for (uint32_t j = 1; j &lt (i + 2) / 2; j++) {
      row[j] = row[i - j]
             = triangle[i - 1][j - 1] + triangle[i - 1][j];
    }

    triangle.push_back(std::move(row));
  }
  return triangle;
}
</code></pre>
</td>
</tr>
</table>
<p>Here's how they do against each other:</p>
<h4><a class="header" href="#element-throughput" id="element-throughput">Element throughput</a></h4>
<p><a href="loops/../images/generated/cluelesswolverine2_generate_throughput_log_scale_bench.svg"><img src="loops/../images/generated/cluelesswolverine2_generate_throughput_log_scale_bench.svg" alt="" /></a></p>
<p>For small triangles, I'd say that's a wash. There's no real benefit to
duplicating the values. The extra subtraction to compute the second insertion
point has the same cost as just computing the element value directly by summing
previous elements.</p>
<p>But when the triangles get bigger, the 'optimisation' actually turns out to be a
hindrance! The double-ended memory access patterns aren't so cache-friendly once
the triangle ceases to fit inside the L1 cache. We'll be talking more about
cache-friendliness shortly, so I won't dwell on it here.</p>
<p>Secretly I was rather pleased that the optimisation was not worth having, because
that double-assignment in a single line of code makes me feel quite unwell 🤮.</p>
<p>Later on we'll see an instance where the half-row optimisation definitely
<em>does</em> improve performance. But as we've seen here, <strong>you can't know until you
measure!</strong></p>
<style>
img:hover {
  box-shadow: 0 0 2px 1px rgba(0, 140, 186, 0.5);
}
</style>
<h1><a class="header" href="#memory-allocation-matters" id="memory-allocation-matters">Memory allocation matters</a></h1>
<p>One of the slowest things we can do in a computer program is to allocate memory.
The default memory allocator has to deal with callers requiring chunks of memory
of all different sizes and for wildly varying durations. It needs to be able to
reuse returned memory chunks where possible, but avoid too much heap
fragmentation. It has no priors on the memory access patterns it will be
exposed to, and it must be thread safe. General purpose memory allocators are
<em>complex</em> and have to do a lot of book-keeping. That makes them expensive and
non-deterministic.</p>
<p>Once you've made sure that your algorithm is not doing anything overtly stupid
and that it has appropriate computational complexity, the next most fruitful
avenue for achieving performance gains is usually to be found in <a href="https://www.youtube.com/watch?v=ZXTI5iWHhrg">minimizing
memory allocations</a>.</p>
<p>For the moment we will concentrate mainly on the differences between the lowest
performing raw-loop solution, <a href="loops/../solutions/AskingCrow.html">AskingCrow</a> and the
highest performing raw-loop solution, <a href="loops/../solutions/CluelessWolverine2.html">CluelessWolverine2</a>.</p>
<p>We're going to use three powerful profiling tools to peer in to the inner
workings of them both and try to understand the performance disparity.</p>
<h1><a class="header" href="#tracing-allocations-with-heaptrack" id="tracing-allocations-with-heaptrack">Tracing allocations with HeapTrack</a></h1>
<p>We'll begin by analysing the memory usage of the two solutions using the
excellent <a href="https://github.com/KDE/heaptrack">HeapTrack</a> tool. I set up each
solution to generate 20,000 rows of pascal's triangle and used HeapTrack to
trace all of the memory allocations.</p>
<p>Where the Heaptrack plots have multiple colours, each colour corresponds to a
different source of allocations. The allocation sources are stacked on top of
each other, with the worst offender having the largest surface area and
appearing at the bottom of the stack.</p>
<h2><a class="header" href="#number-of-allocations" id="number-of-allocations">Number of allocations</a></h2>
<h4><a class="header" href="#cluelesswolverine2---number-of-allocations-for-20000-row-triangle" id="cluelesswolverine2---number-of-allocations-for-20000-row-triangle">CluelessWolverine2 - Number of allocations (for 20,000 row triangle)</a></h4>
<p><a href="loops/../images/heaptrack_CluelessWolverine2_allocations.png"><img src="loops/../images/heaptrack_CluelessWolverine2_allocations.png" alt="" /></a></p>
<p><a href="loops/../solutions/CluelessWolverine2.html">CluelessWolverine2</a> makes 20,000
allocations<sup class="footnote-reference"><a href="#1">1</a></sup> -- one for each row. Seems reasonable, given that every row
has a <code>std::vector</code> of its own. The graph is all one colour, indicating a single
source of allocations.</p>
<h4><a class="header" href="#askingcrow---number-of-allocations-for-20000-row-triangle" id="askingcrow---number-of-allocations-for-20000-row-triangle">AskingCrow - Number of allocations (for 20,000 row triangle)</a></h4>
<p>I couldn't show HeapTrack's tooltips in the screenshot, so I've added my own
high-quality labelling to show the sources of the allocations.
<a href="loops/../images/heaptrack_AskingCrow_allocations.png"><img src="loops/../images/heaptrack_AskingCrow_allocations.png" alt="" /></a></p>
<p><a href="loops/../solutions/AskingCrow.html">AskingCrow</a> makes over <strong>300,000 allocations</strong>.
That can't be healthy! Interestingly, the largest source of allocations by far
appears to be the call to <code>push_back</code> on the <code>new_row</code> vector.</p>
<h2><a class="header" href="#instantaneous-amount-of-ram-allocated" id="instantaneous-amount-of-ram-allocated">Instantaneous amount of RAM allocated</a></h2>
<p>What about the <em>amount</em> of memory allocated?</p>
<h4><a class="header" href="#cluelesswolverine2---instantaneous-amount-consumed-for-20000-row-triangle" id="cluelesswolverine2---instantaneous-amount-consumed-for-20000-row-triangle">CluelessWolverine2 - Instantaneous amount consumed (for 20,000 row triangle)</a></h4>
<p><a href="loops/../images/heaptrack_CluelessWolverine2_consumed.png"><img src="loops/../images/heaptrack_CluelessWolverine2_consumed.png" alt="" /></a></p>
<h4><a class="header" href="#askingcrow---instantaneous-amount-consumed-for-20000-row-triangle" id="askingcrow---instantaneous-amount-consumed-for-20000-row-triangle">AskingCrow - Instantaneous amount consumed (for 20,000 row triangle)</a></h4>
<p><a href="loops/../images/heaptrack_AskingCrow_consumed.png"><img src="loops/../images/heaptrack_AskingCrow_consumed.png" alt="" /></a></p>
<p>Both solutions have the same peak memory consumption of 1.6Gb, but that doesn't
tell the whole story. It's instructive look at the cumulative amount allocated.</p>
<h2><a class="header" href="#cumulative-amount-of-ram-allocated" id="cumulative-amount-of-ram-allocated">Cumulative amount of RAM allocated</a></h2>
<h4><a class="header" href="#cluelesswolverine2---cumulative-amount-allocated-for-20000-row-triangle" id="cluelesswolverine2---cumulative-amount-allocated-for-20000-row-triangle">CluelessWolverine2 - Cumulative amount allocated (for 20,000 row triangle)</a></h4>
<p><a href="loops/../images/heaptrack_CluelessWolverine2_allocated.png"><img src="loops/../images/heaptrack_CluelessWolverine2_allocated.png" alt="" /></a></p>
<h4><a class="header" href="#askingcrow---cumulative-amount-allocated-for-20000-row-triangle" id="askingcrow---cumulative-amount-allocated-for-20000-row-triangle">AskingCrow - Cumulative amount allocated (for 20,000 row triangle)</a></h4>
<p><a href="loops/../images/heaptrack_AskingCrow_allocated.png"><img src="loops/../images/heaptrack_AskingCrow_allocated.png" alt="" /></a></p>
<p><a href="loops/../solutions/CluelessWolverine2.html">CluelessWolverine2</a>
allocates a total of 1.6Gb, then gives it all back at the end. But
<a href="loops/../solutions/AskingCrow.html">AskingCrow</a> allocates a cumulative total of 8.0Gb!
Most of that churn comes from memory allocated <em>and deallocated</em> during the course of
generating each row of the triangle.</p>
<p>Click on to the next section, where we will use the <code>uftrace</code> tool to get
another view of the situation.</p>
<div class="footnote-definition" id="1"><sup class="footnote-definition-label">1</sup>
<p>OK, the executable actually makes more allocations than that, because of
the command-line parser, <a href="https://github.com/bfgroup/Lyra">Lyra</a>. Let's
agree to pretend those don't exist, hmm?</p>
</div>
<h1><a class="header" href="#tracing-function-calls-with-uftrace" id="tracing-function-calls-with-uftrace">Tracing function calls with <code>uftrace</code></a></h1>
<p>So we know that <a href="loops/../solutions/AskingCrow.html">AskingCrow</a> is allocating more
memory than <a href="loops/../solutions/CluelessWolverine2.html">CluelessWolverine2</a>. Using
another nifty tool called <a href="https://github.com/namhyung/uftrace">uftrace</a>, we can
look inside the <code>generate_rows</code> function and get a much clearer idea of exactly
where it's spending its time.</p>
<p>You can use <code>uftrace</code> on any binary that has been built using the <code>-pg</code> gcc
compiler flag. The flag inserts instrumentation into the binary that can trace
every single function call. <code>uftrace</code> uses the instrumentation to dump
a record of every function call into a log file for later analysis.</p>
<p>This sort of tracing has an impact on performance, so you should not take the
timings literally. It's also not able to trace functions that have been inlined
by the compiler<sup class="footnote-reference"><a href="#1">1</a></sup>. The main aim here is to get a feel for how much work the
two solutions are doing.</p>
<h2><a class="header" href="#profiling-function-calls-in-the-generate_rows-function" id="profiling-function-calls-in-the-generate_rows-function">Profiling function calls in the generate_rows function</a></h2>
<p>I built a different executable for each solution, and recorded a <code>uftrace</code>
profile for both of them as they generated a 20,000 row triangle:</p>
<pre><code class="language-bash">uftrace record ./profile_AskingCrow -s 20000
</code></pre>
<p>The <code>uftrace</code> recording for <a href="loops/../solutions/CluelessWolverine2.html">CluelessWolverine2</a>
was a modest 1.9Mb. <a href="loops/../solutions/AskingCrow.html">AskingCrow</a> generated a 6.0Gb
monster-trace 🤢. I think that means it made a few more function calls.</p>
<p>Once I had the recordings, I used the <code>uftrace graph</code> command to print the call
summaries. A lot of the function calls have been inlined by the compiler, so
what we're left with is mostly just the calls to memory management functions.</p>
<table>
<tr>
<th>
Slowest - AskingCrow
</th>
<th>
Fastest - CluelessWolverine2
</th>
</tr>
<tr>
<td valign="top">
<pre><code><!--
-->========== FUNCTION CALL GRAPH ==========
# TOTAL TIME   FUNCTION
   26.592  s : (2) AskingCrow::generate_rows
    9.126  s :  +-(200010000) std::vector::emplace_back
  391.701 ms :  | (287233) std::vector::_M_realloc_insert
  169.273 ms :  |  +-(287233) operator new
             :  |  |
   89.003 ms :  |  +-(267233) memmove
             :  |  |
   20.860 ms :  |  +-(267233) operator delete
             :  |
  457.251 us :  +-(16) std::vector::_M_realloc_insert
   35.081 us :  |  +-(32) operator new
             :  |  |
    8.453 us :  |  +-(16) memmove
             :  |  |
   48.272 us :  |  +-(15) operator delete
             :  |
   85.409 ms :  +-(39984) operator new
             :  |
  572.917 ms :  +-(39984) memmove
             :  |
    4.338 ms :  +-(40000) operator delete
}</code></pre>
</td>
<td  valign="top">
<pre><code><!--
-->========== FUNCTION CALL GRAPH ==========
# TOTAL TIME   FUNCTION
  441.709 ms : (1) CluelessWolverine2::generate_rows
    6.723 us :  +-(1) std::vector::reserve
    6.301 us :  | (1) operator new
             :  |
   25.663 ms :  +-(20000) operator new
</code></pre>
</td>
</tr>
</table>
<p><a href="loops/../solutions/AskingCrow.html">AskingCrow</a> is making a massive number of function
calls. A 20,000 row instance of Pascal's triangle has 200,010,000
elements in it, so it's not surprising to see <code>std::vector::emplace_back</code> being
called that many times. But there's also a huge number of calls to <code>std::vector::_M_realloc_insert</code>,
which is part of the container's automatic resizing mechanism. Each one of those
calls is in turn calling <code>new</code>, <code>memmove</code> and <code>delete</code>. On top of that, every one
of the 20,000 rows seems to be getting <em>two</em> each of <code>new</code>, <code>memmove</code> and <code>delete</code>.</p>
<p>Meanwhile, the svelte and shiny <a href="loops/../solutions/CluelessWolverine2.html">CluelessWolverine2</a>
is getting away with just one call to <code>new</code> for every row. We're not seeing
any calls to <code>delete</code> because the rows don't get deleted until the caller
of <code>generate_rows</code> has finished using them. That's not unique to
<a href="loops/../solutions/CluelessWolverine2.html">CluelessWolverine2</a>; it's just easier to
see because there are fewer other calls.</p>
<p>Now that we know what the bottlenecks are, we can take a look at the code to
explain the behaviour.</p>
<h2><a class="header" href="#identifying-the-rough-edges" id="identifying-the-rough-edges">Identifying the rough edges</a></h2>
<p>Here are the relevant parts of the two solutions side-by-side. I've removed lines
which aren't related to memory allocation.</p>
<table>
<tr>
<th>
Slowest - AskingCrow
</th>
<th>
Fastest - CluelessWolverine2
</th>
</tr>
<tr>
<td valign="top">
<pre><code class="language-c++"><!--
-->std::vector&lt;std::vector&lt;uint64_t&gt;&gt; rows;
std::vector&lt;uint64_t&gt; previous_row;

while (rows.size() &lt num_rows) {
  std::vector&lt;uint64_t&gt; new_row;

  ...

  for (const auto element : previous_row) {
    new_row.push_back(previous_element + element);
    ...
  }

  new_row.push_back(1);
  rows.push_back(new_row);
  previous_row = new_row;
}</code></pre>
</td>
<td  valign="top">
<pre><code class="language-c++">
std::vector&lt;std::vector&lt;uint64_t&gt;&gt; triangle;
triangle.reserve(num_rows);

for (uint32_t i = 0; i &lt num_rows; i++) {
  std::vector&lt;uint64_t&gt; row(i + 1, 1);

  for (uint32_t j = 1; j &lt (i + 2) / 2; j++) {
    row[j] = ...;
  }

  ...
  triangle.push_back(std::move(row));
}
</code></pre>
</td>
</tr>
</table>
<p>You can see how <a href="loops/../solutions/CluelessWolverine2.html">CluelessWolverine2</a> is
careful to take every opportunity to avoid unnecessary memory allocation.
Whenever it constructs a <code>std::vector</code>, it always either initializes the vector
with the correct number of elements:</p>
<pre><code class="language-c++">// Create row, pre-sized, all 1s.
std::vector&lt;uint64_t&gt; row(
  i + 1, // &lt;-- Number of elements
  1      // &lt;-- Initial value of elements
);
</code></pre>
<p>or reserves space for yet-to-be created elements:</p>
<pre><code class="language-c++">std::vector&lt;std::vector&lt;uint64_t&gt;&gt; triangle;
triangle.reserve(num_rows);
</code></pre>
<p>In contrast, <a href="loops/../solutions/AskingCrow.html">AskingCrow</a> begins by constructing
empty vectors:</p>
<pre><code class="language-c++">std::vector&lt;std::vector&lt;uint64_t&gt;&gt; rows;
std::vector&lt;uint64_t&gt; previous_row;
</code></pre>
<p>Then it simply relies on <code>push_back</code> to grow the vector when necessary. That's a
problem because whenever the vector outgrows its storage it needs to reallocate
a new and larger chunk of memory, copy<sup class="footnote-reference"><a href="#2">2</a></sup> all of the elements from the old
chunk into the new chunk and then deallocate the old chunk. But it's worse than
that. When you get a new chunk of memory from the allocator, it may not
be in the cache, so any access will pay the cost of a trip out to main memory.
For small Pascal's triangles, the cost of this memory management greatly
outweighs the cost of actually computing the values to go in the rows.</p>
<p>At the end of its main-loop body, <a href="loops/../solutions/CluelessWolverine2.html">CluelessWolverine2</a>
takes the current row and uses <code>std::move</code> to transfer it cheaply into the outer
vector. Effectively it rips out the guts of the local <code>row</code> variable and hands
them to the outer vector to use:</p>
<pre><code class="language-c++">triangle.push_back(std::move(row));
</code></pre>
<p><a href="loops/../solutions/AskingCrow.html">AskingCrow</a> <em>copies</em> the current row into the outer
vector (requiring an allocation and a <code>memcpy</code>) and then makes a <em>second</em> copy
of it into the <code>previous_row</code> object (which may also allocate before the <code>memcpy</code>).</p>
<pre><code class="language-c++">rows.push_back(new_row); // Always allocates
previous_row = new_row;  // May allocate if 'previous_row' needs resizing
</code></pre>
<p>In the next section we're going to look a little more at the cost of these
extra allocations, using the Tracy frame profiler.</p>
<div class="footnote-definition" id="1"><sup class="footnote-definition-label">1</sup>
<p>Inlining is where the compiler takes the body of a function and dumps the
whole contents of it into the calling function. This avoids a function
call, but more importantly it allows the optimizer to see right in to the
called function and potentially generate much faster code.</p>
</div>
<div class="footnote-definition" id="2"><sup class="footnote-definition-label">2</sup>
<p>Integer elements of a vector are always copied, because moving doesn't
make sense for trivially copyable types.</p>
</div>
<h1><a class="header" href="#visualising-the-cost-of-memory-allocation-with-the-tracy-frame-profiler" id="visualising-the-cost-of-memory-allocation-with-the-tracy-frame-profiler">Visualising the cost of memory allocation with the Tracy Frame Profiler</a></h1>
<p>We've seen that <a href="loops/../solutions/AskingCrow.html">AskingCrow</a> is doing a lot more
allocation than <a href="loops/../solutions/CluelessWolverine2.html">CluelessWolverine2</a>, but
what does it actually cost?</p>
<p><code>uftrace</code> was trivial to use and logged every function call. But it caused
a substantial slowdown of the program, and didn't allow the profiling to be
<em>targeted</em> where it was most needed. That's where the
<a href="https://github.com/wolfpld/tracy">Tracy</a> frame profiler comes in.</p>
<p>Tracy works quite differently from how a sampling-based profiler (think Linux
<code>perf</code>, Intel's
<a href="https://software.intel.com/content/www/us/en/develop/tools/vtune-profiler.html">VTune</a>
or Apple's <a href="https://help.apple.com/instruments/mac/8.0/#/dev7b09c84f5">Instruments</a>)
would work. They usually only gather coarse statistics that tell you the
percentage of total time spent in each function.</p>
<p>Instead Tracy allows us to mark up <em>exactly</em> the code we want to profile (using
simple macros), and captures logs every time that section of code is executed.
As before, the act of profiling will affect the timings, but Tracy
is remarkably low overhead and offers nanosecond resolution results. Oh, and the
visualisations it offers are downright snazzy.</p>
<p>We're going to benchmark just the time taken for the insertion of rows into the
outer vector, for a triangle with 20,000 rows.</p>
<h4><a class="header" href="#askingcrow" id="askingcrow">AskingCrow</a></h4>
<p><a href="loops/../solutions/AskingCrow.html">AskingCrow</a> constructs the outer vector without
reserving space and pushes new rows into it. When new rows are pushed, the outer
vector may need to be resized. Furthermore, each row is <em>copied</em> in to the outer
vector, which will <em>always</em> incur an allocation and a copy of all of the row
elements:</p>
<pre><code class="language-c++">std::vector&lt;std::vector&lt;uint64_t&gt;&gt; rows;
...
while (rows.size() &lt; num_rows)
  std::vector&lt;uint64_t&gt; new_row;
  ...
  rows.push_back(new_row);  // &lt;-- Mean 32.97us per call, for a total
                            //     of ~660ms over 20,000 calls.
                            // Note that 'new_row' is always copied here, which
                            // incurs another allocation.
}
</code></pre>
<h4><a class="header" href="#cluelesswolverine2" id="cluelesswolverine2">CluelessWolverine2</a></h4>
<p><a href="loops/../solutions/CluelessWolverine2.html">CluelessWolverine2</a> reserves space in the
outer vector and then <em>moves</em> the newly computed rows into it:</p>
<pre><code class="language-c++">std::vector&lt;std::vector&lt;uint64_t&gt;&gt; triangle;
triangle.reserve(num_rows);  // &lt;-- 9.18us, once

for (uint32_t i = 0; i &lt; num_rows; i++) {
  ...
  triangle.push_back(std::move(row)); // &lt;-- Mean 47ns per call, for a total
                                      //     of ~950us over 20,000 calls.
}
</code></pre>
<p>Over the course of constructing the whole triangle, <a href="loops/../solutions/AskingCrow.html">AskingCrow</a>
is spending 660ms pushing rows into the outer vector, but
<a href="loops/../solutions/CluelessWolverine2.html">CluelessWolverine2</a> is spending only 950us
doing the same thing. That's around <strong>700 times faster</strong>. Since running
<a href="loops/../solutions/AskingCrow.html">AskingCrow</a> under the Tracy profiler takes a
<em>total</em> of 1010ms, that 660ms for row allocations represents a massive portion
of the total run-time.</p>
<h1><a class="header" href="#the-geometric-allocation-behaviour-of-stdvector" id="the-geometric-allocation-behaviour-of-stdvector">The geometric allocation behaviour of <code>std::vector</code></a></h1>
<p>One of the reasons that <code>AskingCrow</code> is doing a lot of memory allocation is due
to the way that <code>std::vector</code> works. If you don't pre-reserve space in a
<code>std::vector</code> then it has no option but to just grow on demand. The precise
details are implementation defined, but most implementations use a scheme where
they multiply the capacity of the vector by a fixed factor whenever it needs to
grow. That's the most efficient thing you can do if you have no prior
knowledge about how many elements are going to be pushed in.</p>
<p>We can use Tracy to visualise the geometric nature of the allocations as
<a href="loops/../solutions/AskingCrow.html">AskingCrow</a> populates a triangle rows containing
20,000 elements. I think it's super cool to see.</p>
<p>I've annotated the solution's source code to label the various stages of the
algorithm with names like <code>Fill new row</code> and <code>Push back new row</code>. You'll see
those labels in the Tracy viewer. The labelled bars at the top represent the
amount of time spent in each zone. Selecting a zone (as I have done for <code>Fill new row</code>) shows zone-specific allocation information in the bottom half of the
screen.</p>
<p>There's a huge amount of information contained in this screenshot, so I've
highlighted the key parts.</p>
<h3><a class="header" href="#stdvector-growth-in-askingcrow" id="stdvector-growth-in-askingcrow">std::vector growth in AskingCrow</a></h3>
<p><a href="loops/../images/tracy_AskingCrow_vector_alloc.png"><img src="loops/../images/tracy_AskingCrow_vector_alloc.png" alt="" /></a></p>
<ol>
<li>
<p>First thing to notice is that there are 16 allocations and 15 deallocations
happening <em>while</em> the 20,000 row elements are computed. Those are due to the
row vector automatically growing itself occasionally, and could all be avoided
by correctly sizing the vector up-front.</p>
</li>
<li>
<p>The table in the bottom half of the screen shows how the amount of memory
allocated by the <code>std::vector</code> doubles at every stage - starting with 8 bytes
(enough to hold a single <code>uint64_t</code> value) and ending with 256 Kilobytes
(enough to hold 32,768 <code>uint64_t</code> values).</p>
</li>
<li>
<p>The yellow memory usage graph neatly shows the geometric nature of the
allocations.  You'll notice that it has a saw-tooth pattern to it. That's
because whenever the vector grows, the newly allocated buffer has to coexist
with the old buffer until all of the values have been copied over.
Only then can the old buffer be deallocated.</p>
<p>These memory allocations are relatively quick, because they are for very
common sizes -- the allocator can likely pull them straight out of a pool of
correctly sized chunks. In fact, inspecting the addresses of the allocated
memory in Tracy shows that in most cases the temporary row vectors are
allocated <em>exactly the same</em> chunks of memory every time. It's reusing them
over and over. That means they're already in the cache, so writing to that
memory will be super fast. If the allocator didn't do that, the performance
would be grindingly slow.</p>
</li>
<li>
<p>The last thing to notice is the relative size of the bars for the <code>Fill new row</code> zone and the <code>Push back new row</code> zone. Their length denotes the time they
took. Just pushing back the <code>new_row</code> into the outer <code>rows</code> vector takes longer
to do than filling the row with values!</p>
<p>The likely reason is that the memory allocator will need to find a <em>new</em>
chunk of memory for the destination vector, rather than reusing a previously
used chunk. Because it's a new piece of memory, there's no chance it will be
in the cache already. Copying all the row values into it will <em>always</em> incur
an expensive trip out to main memory.</p>
</li>
</ol>
<h1><a class="header" href="#be-kind-to-your-cache" id="be-kind-to-your-cache">Be kind to your cache</a></h1>
<p>So far I've only let you see benchmarks from two of the raw-loop solutions. Now
we'll plot all of them together. Recall that 'throughput' is the number of
elements of Pascal's Triangle that are computed every second. The higher the
throughput, the better the performance is.</p>
<p><a href="loops/../images/generated/loops_generate_throughput_log_scale_bench.svg"><img src="loops/../images/generated/loops_generate_throughput_log_scale_bench.svg" alt="" /></a></p>
<p>All of these solutions start to see a catastrophic drop-off when the size of the
triangle gets to around 2 Million elements (or ~2048 rows).</p>
<p>Remember that the graph uses a log-scale for the y-axis, so the effect is more
pronounced than it appears. Here's the same data plotted with a linear scale for
the y-axis:</p>
<p><a href="loops/../images/generated/loops_generate_throughput_linear_scale_bench.svg"><img src="loops/../images/generated/loops_generate_throughput_linear_scale_bench.svg" alt="" /></a></p>
<p>L3 Cache on the computer that generated the benchmarks is
sized at 16Mb. How many 64-bit integers can you fit in to 16Mb? Some
back-of-the-envelope calculations tell us that it's
<code>(16*1024*1024)/8 = 2,097,152</code> elements. Bingo! That's right where the drop-off
occurs for most solutions. </p>
<p>Once the algorithm can no longer keep the whole of Pascal's triangle in the
cache, it's having to pay the cost of paging out to the glacially-slow main
memory. You can see from the benchmarks that this stuff really matters.</p>
<p>Fortran4Ever allocates twice as much memory as any of the other solutions, so
its performance plunge starts sooner.</p>
<p>When we push these algorithms to generate 65,536 rows, the storage
requirements shoot up to 16Gb for a single triangle. By then we're definitely in
the territory of virtual memory - where data starts spilling out to disk.
Frankly it's astonishing that we still get such high throughput.</p>
<p>Later on, we'll talk about some solutions that have significantly lower memory
requirements and continue to perform well even as the row count climbs.</p>
<h1><a class="header" href="#when-everything-looks-like-a-nail-perhaps-you-need-a-spanner" id="when-everything-looks-like-a-nail-perhaps-you-need-a-spanner">When everything looks like a nail, perhaps you need a spanner</a></h1>
<style>
.center {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
</style>
<p>
<img src="loops/../images/span_layout.jpg" alt="Memory layout as a contiguous array" width="85%" class="center">
</p><br/>
<p>All of the loop-based solutions we've seen so far are constrained by the fact
that they have to return their result as a <code>std::vector&lt;std::vector&lt;uint64_t&gt;</code>.
Each of the rows of the triangle lives in its own <code>std::vector</code>, which has two
important implications:</p>
<ol>
<li>We need to perform a memory allocation for <em>every</em> row.</li>
<li>We have no control over where in memory those allocations are made.</li>
</ol>
<p>In this section we'll explore <em>one</em> approach for fixing both of those problems.
There are also viable solutions using custom allocators for STL
containers. I did implement some of those, but I didn't feel I could do justice
to them in this write-up, so we'll stick to talking about 'view' types.</p>
<h2><a class="header" href="#c20s-stdspan" id="c20s-stdspan">C++20's <code>std::span</code></a></h2>
<p>C++20 introduces <a href="https://en.cppreference.com/w/cpp/container/span"><code>std::span</code></a>,
which allows us to create lightweight 'views' onto underlying data. Whereas
<code>std::string_view</code> offers immutable views onto 'char-like' data, <code>std::span</code>
can point at contiguous arrays of <em>any</em> type. In addition, the underlying data
can optionally be mutated through the view.</p>
<p>Essentially <code>std::span</code> is just a class template which contains a pair of pointers to the
beginning and end of a contiguous chunk of data <em>that it does not own</em>. The reason
<code>std::span</code> is interesting is that it has methods like <code>begin</code>, <code>end</code>, <code>size</code>
and <code>operator[]</code>, which allow <code>std::span</code> to be used as if it were any other STL
container. The only difference is that you cannot insert or delete elements.
But you can mutate them.</p>
<p>We don't have access to <code>std::span</code> in C++17, but the
<a href="https://ericniebler.github.io/range-v3/">Range-v3</a> library contains
<code>ranges::span</code> which does a very similar job, so we'll use that instead.</p>
<h2><a class="header" href="#changing-the-return-type-of-generate_rows" id="changing-the-return-type-of-generate_rows">Changing the return type of <code>generate_rows</code></a></h2>
<p>A key insight is that the original challenge did not <em>require</em> <code>generate_rows</code> to return
a nested <code>std::vector&lt;std::vector&lt;uint64_t&gt;&gt;</code> data structure. It only required
it to return a type which behaves similarly. <code>ranges::span&lt;uint64_t&gt;</code> has all
the necessary methods for iterating over values, so we can change the return
type of the <code>generate_rows</code> function to be <code>std::vector&lt;ranges::span&lt;uint64_t&gt;&gt;</code>
and the unit tests will still compile. </p>
<p>This frees us from the requirement to allocate a separate array of <code>uint64_t</code>
elements for every row of pascal's triangle. Instead we can allocate a <em>single</em>
array of <code>rows * (rows+1) / 2</code> elements up front, which can accommodate the
whole triangle. Then we just create a lightweight <code>span</code> object for every row,
which points in to the appropriate part of the large array.</p>
<p>There's the added benefit of cache-friendliness here. When the CPU accesses
bytes from RAM, it reads them in chunks that are the same width as a cache-line.
On current architectures that would typically be 64-bytes at a time. There's also
a hardware 'cache prefetcher' that speculatively retrieves chunks of memory before
you need them. That works best when you access memory sequentially.</p>
<p>When our triangle row data was stored in individual <code>std::vector</code> instances,
there would be an almost-guaranteed cache-miss when the the algorithm hit the
beginning of each new row. With an up-front allocation of a single contiguous
block of memory, the prefetcher will <em>always</em> have grabbed the memory we need
when we roll on to the next row. That's neat.</p>
<h2><a class="header" href="#ownership-obstacles" id="ownership-obstacles">Ownership obstacles</a></h2>
<p>The problem with <code>span</code> objects is that they do not own the data they point to.
If you point a <code>span</code> at some piece of memory and then the owner of that memory
goes out of scope then you'll be left with a 'dangling' <code>span</code>. That's nothing
new -- C++ has had the problem of dangling pointers and references right from
the earliest days. But it is something we need to be very careful of when using
'view' objects such as <code>std::span</code> and <code>std::string_view</code>.</p>
<p>We need to somehow bundle the <em>ownership</em> of the triangle data in to the result
type returned by the <code>generate_rows</code> function, but still retain its compatibility
with the unit tests. Here's how we can do that:</p>
<pre><code class="language-c++">class PascalsTriangle {
  std::unique_ptr&lt;uint64_t[]&gt; values_;        // Underlying data
  std::vector&lt;ranges::span&lt;uint64_t&gt;&gt; rows_;  // Vector of lightweight row views

 public:
  PascalsTriangle(uint32_t num_rows);         // Constructor fills rows_ with data

  // Providing begin() and end() allows the PascalsTriangle type
  // to be iterated over.
  auto begin() const { return rows_.cbegin(); }
  auto end() const { return rows_.cend(); }
};

inline auto generate_rows(uint32_t num_rows) -&gt; PascalsTriangle {
  return PascalsTriangle(num_rows);
}
</code></pre>
<p>The <code>PascalsTriangle</code> class owns the underlying triangle data in the form of the
<code>values_</code> array. This could be implemented as a <code>std::vector</code>, but I chose to use a
<code>unique_ptr</code> because it avoids the up-front cost of value-initialisation that
<code>std::vector</code> imposes. <a href="https://accu.org/index.php/journals/2776">But that's a story</a>
for <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1072r1.html">another day</a>.</p>
<p>The sneaky part is that <code>PascalsTriangle</code> has <code>begin()</code> and <code>end()</code> methods that
return iterators into the <code>rows_</code> vector. That makes the <code>PascalsTriangle</code> type
look sufficiently 'container-like' that it will satisfy the interface requirements
of the unit tests. You can even use range-for loops on it:</p>
<pre><code class="language-c++">PascalsTriangle const triangle = generate_rows(42);

for (auto const&amp; row: triangle) {
  ...
}
</code></pre>
<h2><a class="header" href="#look-its-more-fasterer" id="look-its-more-fasterer">Look! It's more fasterer!</a></h2>
<p>Once the return-type is designed, the rest of the implementation is very
similar to all of the other raw-loop solutions. You can see it at
<a href="loops/../solutions/FlyingDesitter_arh.html">FlyingDesitter_arh</a>. I'd like to thank
<a href="https://cpponsea.uk/2020/sessions/reducing-memory-allocations-in-a-large-cpp-application.html">Arnaud Desitter</a> for reminding me to benchmark this.</p>
<p>Now, no matter the size of the triangle, we only ever make <em>two</em> allocations in
total. It makes a big difference.</p>
<p>Recall that in the <a href="loops/./dont_do_unnecessary_work.html">Don't do more work than you need to?</a>
section we cooked up a solution called <a href="loops/../solutions/Baseline.html">Baseline</a>
which was what I consider to be the 'canonical' raw-loop approach to generating
Pascal's Triangle. For 64-row triangles, <a href="loops/../solutions/FlyingDesitter_arh.html">FlyingDesitter_arh</a> is
<strong>10 times faster</strong> than <a href="loops/../solutions/Baseline.html">Baseline</a>. Tasty.</p>
<h4><a class="header" href="#element-throughput-log-scale" id="element-throughput-log-scale">Element throughput (log scale)</a></h4>
<p><a href="loops/../images/generated/FlyingDesitter_arh_generate_throughput_log_scale_bench.svg"><img src="loops/../images/generated/FlyingDesitter_arh_generate_throughput_log_scale_bench.svg" alt="" /></a></p>
<h4><a class="header" href="#element-throughput-linear-scale" id="element-throughput-linear-scale">Element throughput (linear scale)</a></h4>
<p><a href="loops/../images/generated/FlyingDesitter_arh_generate_throughput_linear_scale_bench.svg"><img src="loops/../images/generated/FlyingDesitter_arh_generate_throughput_linear_scale_bench.svg" alt="" /></a></p>
<p>OK, so we're done here? We can all go home?</p>
<p>Not really. This solution may be super-fast, but it has some pretty anti-social
storage requirements. The amount of memory it uses is <strong>quadratic</strong> in the
number of rows. And it still suffers from a catastrophic tumble when the
triangle spills out of L3 cache. I think we'll grade this one
'B+ (could do better)'.</p>
<h1><a class="header" href="#loopy-learnings" id="loopy-learnings">Loopy learnings</a></h1>
<style>
.center {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
</style>
<p>
<img src="loops/../images/rollercoaster.jpg" alt="A rollercoaster with loops" width="85%" class="center">
</p><br/>
<h2><a class="header" href="#tools" id="tools">Tools</a></h2>
<p>We looked at all of the raw-loop based submissions to the Pascal's Triangle
coding problem. The following open-source tools were helpful for understanding
their performance characteristics:</p>
<ul>
<li><a href="https://github.com/KDE/heaptrack">Heaptrack</a> for locating sources of memory
allocation.</li>
<li><a href="https://github.com/namhyung/uftrace">uftrace</a> for understanding the function
call graph.</li>
<li><a href="https://github.com/wolfpld/tracy">Tracy</a> for getting highly targeted profiling
information for particular zones of the program.</li>
</ul>
<p>I've ordered the tools by how involved they were to deploy. Heaptrack was
trivial to use direct from the command-line, with no modifications required to
the binary under test. It's really a no-brainer (but is Linux only).</p>
<p>'uftrace' needed the code to be built using a specific compiler flag, but after
that was as easy to use as heaptrack.</p>
<p>Tracy was the most powerful tool, but required linking the binary against a
client library and instrumenting the code to be profiled. But the insights it
can provide are frankly jaw-dropping.</p>
<h2><a class="header" href="#techniques" id="techniques">Techniques</a></h2>
<p>Some things we learned in this section to make loop-based algorithms go faster:</p>
<h3><a class="header" href="#profiling" id="profiling">Profiling</a></h3>
<ul>
<li><strong>Always measure the effect of your optimizations.</strong> Sometimes things don't
help as much as you'd hoped.</li>
</ul>
<h3><a class="header" href="#memory-allocation" id="memory-allocation">Memory allocation</a></h3>
<ul>
<li>Avoid memory allocation inside loops</li>
<li>If you know how big your vector will grow then use <code>.reserve()</code> up-front.</li>
<li>Don't allocate more memory than you need.</li>
</ul>
<h3><a class="header" href="#avoid-unnecessary-copies" id="avoid-unnecessary-copies">Avoid unnecessary copies</a></h3>
<ul>
<li><em>Move</em> vectors rather than copy them, if you can.</li>
<li>Try not to insert or remove elements anywhere other than the right-hand end
of a vector.</li>
</ul>
<h3><a class="header" href="#cache-friendliness" id="cache-friendliness">Cache friendliness</a></h3>
<ul>
<li>Arrange for your algorithm to access memory sequentially, so that the
prefetcher can cache the memory you need before you ask for it.</li>
<li>Aim to make your data structures fit in the cache</li>
<li>Corollary: avoid bloating your objects with lots of member variables. The
smaller they are, the more you'll fit in cache.</li>
</ul>
<p><sup class="footnote-reference"><a href="#1">1</a></sup> Image from https://pixabay.com/photos/rollercoaster-looping-amusement-801833/, used under 'Simplified Pixabay License'.</p>
<h1><a class="header" href="#everything-is-a-matrix" id="everything-is-a-matrix">Everything is a matrix</a></h1>
<p style="color:red;font-size:30px;">Section not complete</p>
<p>I received one beautiful submission written in Fortran. Fortran treats everything
as a matrix, so Pascal's Triangle becomes a square lower-triangular matrix. The
submission link includes comments from the author, which give a fascinating
insight into how the constraints imposed by a programming language can shape the
way that you have to think about a problem.</p>
<p>I'm afraid I didn't benchmark this one. Let's assume it was astonishingly fast.</p>
<h2><a class="header" href="#submissions-in-this-category" id="submissions-in-this-category">Submissions in this category</a></h2>
<ul>
<li><a href="./solutions/pascalsTriangle.for.html">pascalsTriangle.for</a></li>
</ul>
<h1><a class="header" href="#stl-algorithms" id="stl-algorithms">STL Algorithms</a></h1>
<p style="color:red;font-size:30px;">Section not complete</p>
<p>Two intrepid Programmers decided to use algorithms from the C++ standard
library, rather than hand-rolling loops.</p>
<p>Reviewers of the <a href="./loops/loops.html">loop-based solutions</a> universally reported that
they were readable and maintainable. So why is it that luminaries of the Modern
C++ community are continually pushing for us to use STL algorithms?</p>
<h3><a class="header" href="#why-use-the-stl" id="why-use-the-stl">Why use the STL?</a></h3>
<p>Here are some of the well-known talks on the subject. The first, by Sean Parent
is an absolute classic:</p>
<ul>
<li><a href="https://youtu.be/W2tWOdzgXHA">GoingNative 2013: Sean Parent &quot;C++ Seasoning&quot;</a></li>
<li><a href="https://www.youtube.com/watch?v=bFSnXNIsK4A">105 STL Algorithms in Less Than an Hour</a></li>
<li><a href="https://www.youtube.com/watch?v=pUEnO6SvAMo">CppCon 2019: Conor Hoekstra “Algorithm Intuition (part 1 of 2)”</a></li>
</ul>
<p>The main thrust of the argument is that using the STL algorithms raises the level
of abstraction of our code. It shields us from a number of very common bugs in
raw loops, such as off-by-one errors, incorrect handling of the empty case and
forgetting to increment counters.</p>
<p>Small raw loops can be very readable, but their readability does not scale well.
The longer the loop, the more effort it takes to reason about its effects. In
contrast, when we see a piece of code using <code>std::transform</code>, we know
immediately that the input collection will not be modified by the operation and
that every element of the output collection <em>must</em> be obtained by applying the
same operation to each of the input elements.</p>
<p>Programmers who are familiar with their STL algorithms can instantly gain
important knowledge about code that uses them, without having to spend brain
cycles on deciphering the contents of an ad-hoc loop. As <a href="https://www.youtube.com/watch?v=bFSnXNIsK4A&amp;feature=youtu.be&amp;t=280">Jonathan Boccara puts it</a>,
we should &quot;Level up to the STL algorithms, and not the other way round&quot;.</p>
<p>They don't actually help massively here but in more complex situations they can greatly reduce bugs (say this somewhere...) </p>
<h3><a class="header" href="#but-theyre-really-ugly" id="but-theyre-really-ugly">But they're really ugly!</a></h3>
<p>I drink a glass of STL kool-aid with my breakfast every morning. But when someone
says &quot;STL algorithms are hard to read with all that <code>begin</code> and <code>end</code> iterator
nonsense&quot;, I find myself guiltily agreeing<sup class="footnote-reference"><a href="#1">1</a></sup>. It's a hard sell.</p>
<p>C++20 really improves the situation by providing <a href="https://en.cppreference.com/w/cpp/algorithm/ranges">'constrained' versions</a>
of all of the STL algorithms. Now instead of having to write:</p>
<pre><code class="language-c++">auto how_many = std::count(v.begin(), v.end(), 42);
</code></pre>
<p>you can instead just do<sup class="footnote-reference"><a href="#2">2</a></sup>:</p>
<pre><code class="language-c++">auto how_many = ranges::count(v, 42);
</code></pre>
<p>Much better. The range versions of the algorithms offer other benefits, like
the ability to apply projection functions to the input data before passing it
through the algorithm. Exciting times.</p>
<p>If you want this in your pre-C++20 codebase <em>right now</em> then it's actually <a href="https://www.fluentcpp.com/2018/12/07/algorithms-on-ranges/">pretty
easy</a> to write a
library of simple wrapper functions around the STL algorithms. Or you can use
the <a href="https://ericniebler.github.io/range-v3/">range-v3</a> library.</p>
<h3><a class="header" href="#how-does-the-stl-help-us-for-generating-pascals-triangle" id="how-does-the-stl-help-us-for-generating-pascals-triangle">How does the STL help us for generating Pascal's Triangle?</a></h3>
<p>The STL algorithms do not promise to improve the performance of our code. We use
them to avoid common bugs and to give a common vocabulary for talking about
algorithms. We should not expect any of the STL-based Pascal's Triangle
solutions to out-perform the fastest of the raw-loop solutions.</p>
<p>Having said that, there <em>are</em> sometimes free performance optimizations if you use
STL algorithms. As an example, look at the <a href="https://github.com/microsoft/STL/blob/92508bed63/stl/src/vector_algorithms.cpp#L158">Microsoft STL's <code>std::reverse</code> implementation</a>
which employs substantial amounts of <a href="https://en.wikipedia.org/wiki/SIMD">SIMD</a>
trickery to achieve speed-ups. You don't get that in your average raw loop. As
far as I can tell, Clang's libc++ and gcc's libstdc++ standard library
implementations do not do anything similar. But they might in future.</p>
<h2><a class="header" href="#benchmarks" id="benchmarks">Benchmarks</a></h2>
<p><em>NOTE: The vertical red line marks the point where integer overflow occurs in the
row values. Generating triangles larger than this is pointless. We're only doing
it to see how the algorithms scale.</em></p>
<p>As well as the submissions from this category, the benchmark graphs include the
<a href="./solutions/Baseline.html">Baseline</a> solution introduced in the
<a href="./loops/loops.html">loops chapter</a>.</p>
<h4><a class="header" href="#time-to-generate-a-triangle" id="time-to-generate-a-triangle">Time to generate a triangle</a></h4>
<p><a href="./images/generated/stl_algorithms_generate_cpu_bench.svg"><img src="./images/generated/stl_algorithms_generate_cpu_bench.svg" alt="" /></a></p>
<h4><a class="header" href="#element-throughput-1" id="element-throughput-1">Element throughput</a></h4>
<p><a href="./images/generated/stl_algorithms_generate_throughput_log_scale_bench.svg"><img src="./images/generated/stl_algorithms_generate_throughput_log_scale_bench.svg" alt="" /></a></p>
<p><a href="./images/generated/stl_algorithms_generate_throughput_linear_scale_bench.svg"><img src="./images/generated/stl_algorithms_generate_throughput_linear_scale_bench.svg" alt="" /></a></p>
<h2><a class="header" href="#watch-out-for-back-insertion" id="watch-out-for-back-insertion">Watch out for back-insertion</a></h2>
<p>talk about concepts rather than the solutions themselves</p>
<p>The author of <a href="./solutions/LordVader.html">LordVader</a> chose to use C++17's
newly-introduced <a href="https://en.cppreference.com/w/cpp/algorithm/adjacent_difference"><code>std::adjacent_difference</code></a>
algorithm, which applies a transform to every adjacent pair of elements in a
collection. The name <code>adjacent_difference</code> unfortunately doesn't communicate the
true flexibility of the algorithm. By default it computes the <em>difference</em>
between adjacent pairs of values, but some overloads allow the caller to specify
a custom operation.</p>
<p><a href="./solutions/LordVader.html">LordVader</a> takes advantage of that ability to
replace the default 'difference' operation with <code>std::plus</code>, which has the
effect of summing pairs of elements from the previous row, which is precisely
what we need to do when computing rows of Pascal's Triangle.</p>
<p><a href="./solutions/LordVader.html">LordVader</a> is a really clean solution, and looks like
it should perform well. It takes care to minimise memory allocations by reserving
space in the vectors and avoids unnecessary copies.</p>
<p>I liked the use of <a href="https://shaharmike.com/cpp/rvo/#named-return-value-optimization-nrvo">Named Return Value Optimization</a> to put newly constructed rows into the outer vector:</p>
<pre><code class="language-c++">auto generate_next_row(std::vector&lt;uint64_t&gt; const&amp; last_row)
    -&gt; std::vector&lt;uint64_t&gt; {
  std::vector&lt;uint64_t&gt; new_row;
  
  ... fill row values ...
  
  return new_row; // &lt;-- NRVO means new_row gets constructed directly into the
                  //     result object. Not guaranteed (even by C++17), but most
                  //     compilers do it when optimizations are enabled.
}

auto generate_rows(uint32_t num_rows) -&gt; std::vector&lt;std::vector&lt;uint64_t&gt;&gt; {
  ...

  for (uint32_t i = 1; i &lt; num_rows; ++i) {
    rows.push_back(generate_next_row(rows[i - 1]));
  }

  ...
}
</code></pre>
<p>One reviewer remarked that putting the inner loop in another function would be
inefficient because of copying. Fortunately <a href="https://en.cppreference.com/w/cpp/language/copy_elision">C++ has our back here</a>. It's able
to write the result from <code>generate_next_row</code> directly into the storage reserved
by the calling function (either the stack or perhaps registers).
<code>std::vector::push_back</code> then takes that temporary vector and moves it
efficiently into the <code>rows</code> vector.</p>
<p>Despite all that care, <a href="./solutions/LordVader.html">LordVader</a> for some reason
does not perform as well as <a href="./solutions/GroovyZone.html">GroovyZone</a>. In fact, at
1024 rows, it's almost <strong>7 times</strong> slower than <a href="./solutions/Baseline.html">Baseline</a>.
Why is that?</p>
<p>The clue is in the use of <code>std::back_inserter</code> for filling rows with elements:</p>
<pre><code class="language-c++"><!--
-->// Find the pairwise sums of the elements in the last row and add to the new row.
std::adjacent_difference(std::cbegin(last_row), std::cend(last_row),
                         <b>std::back_inserter(new_row)</b>, std::plus<>{});
</code></pre>
<p>Every time a value is assigned to a <a href="https://en.cppreference.com/w/cpp/iterator/back_insert_iterator"><code>back_insert_iterator</code></a>,
it calls <code>push_back</code> on the vector. And every time <code>push_back</code> is called, it
needs to check that the vector has adequate capacity to accommodate the new
element. Even though we've reserved enough space up-front, the code still has to
check the condition on every loop iteration. In <em>some</em> cases the optimiser is
able to see that the condition check is unnecessary and compile it away, but
it's certainly not guaranteed<sup class="footnote-reference"><a href="#3">3</a></sup>. And it doesn't happen in this case.</p>
<p>To test this hypothesis, I made a modified version of the
<a href="./solutions/LordVader.html">LordVader</a> solution, the imaginatively named
<a href="./solutions/LordVader2_arh.html">LordVader2_arh</a>. Here's the original
<code>generate_next_row</code> function using <code>std::back_inserter</code>:</p>
<h4><a class="header" href="#lordvader" id="lordvader">Lordvader</a></h4>
<pre><code class="language-c++"><!--
-->auto generate_next_row(std::vector<uint64_t> const& last_row)
    -> std::vector<uint64_t> {
  std::vector<uint64_t> new_row;
  new_row.reserve(last_row.size() + 1);

  // Find the pairwise sums of the elements in the last row and add to the new row.
  std::adjacent_difference(std::cbegin(last_row), std::cend(last_row),
                           <b>std::back_inserter(new_row)</b>, std::plus<>{});
  new_row.push_back(1);  // Add final 1.

  return new_row;
};
</code></pre>
<p>In <a href="./solutions/LordVader2_arh.html">LordVader2_arh</a>, <code>new_row</code> has all of its
elements initialised in the constructor and <code>std::adjacent_difference</code> just
dumps its results straight in to the vector, without using a <code>back_inserter</code>:</p>
<h4><a class="header" href="#lordvader2_arh" id="lordvader2_arh">LordVader2_arh</a></h4>
<pre><code class="language-c++"><!--
-->auto generate_next_row(std::vector<uint64_t> const& last_row)
    -> std::vector<uint64_t> {
  std::vector<uint64_t> new_row(last_row.size() + 1);

  // Find the pairwise sums of the elements in the last row and add to the new row.
  std::adjacent_difference(std::cbegin(last_row), std::cend(last_row),
                           std::begin(new_row), std::plus<>{});
  new_row.back() = 1; // Add final 1

  return new_row;
};
</code></pre>
<p>Here are the new benchmarks:</p>
<h4><a class="header" href="#time-to-generate-a-triangle-1" id="time-to-generate-a-triangle-1">Time to generate a triangle</a></h4>
<p><a href="./images/generated/stl_algorithms_improved_generate_cpu_bench.svg"><img src="./images/generated/stl_algorithms_improved_generate_cpu_bench.svg" alt="" /></a></p>
<h4><a class="header" href="#element-throughput-2" id="element-throughput-2">Element throughput</a></h4>
<p><a href="./images/generated/stl_algorithms_improved_generate_throughput_log_scale_bench.svg"><img src="./images/generated/stl_algorithms_improved_generate_throughput_log_scale_bench.svg" alt="" /></a></p>
<p><a href="./images/generated/stl_algorithms_improved_generate_throughput_linear_scale_bench.svg"><img src="./images/generated/stl_algorithms_improved_generate_throughput_linear_scale_bench.svg" alt="" /></a></p>
<p><a href="./solutions/LordVader2_arh.html">LordVader2_arh</a>'s performance is now right up
there with <a href="./solutions/Baseline.html">Baseline</a> and
<a href="./solutions/GroovyZone.html">GroovyZone</a>. Hurrah!</p>
<p>maybe the overall order needs tweaking once bits have moved around...</p>
<h2><a class="header" href="#groovyzone" id="groovyzone">Groovyzone</a></h2>
<p>The author of <a href="./solutions/GroovyZone.html">GroovyZone</a> could not find an existing
STL algorithm that did quite what they wanted, so they chose to implement their
own <code>adjacent_pair</code> algorithm. This was excellent.</p>
<p>By pulling that algorithm out into a named function, it has been made reusable
and (vitally) separately testable. Rather than having to indirectly test the
loop through the lens of a Pascal's triangle implementation, it can be tested
as an algorithm that applies a transformation to adjacent pairs of a collection.
Then it can be used in the Pascal's Triangle code with high confidence that it
is correct. To quote a well-known roboticist: &quot;This is Huge!&quot;.</p>
<p><a href="./solutions/GroovyZone.html">GroovyZone</a> is careful to allocate all its memory
up-front and avoids needlessly copying any rows. When looking at the benchmark
results it's no surprise that it almost exactly matches the performance of the
<a href="./solutions/Baseline.html">Baseline</a> solution introduced in the
<a href="./loops/loops.html">loop-based solutions</a> section.</p>
<h2><a class="header" href="#whats-in-a-name" id="whats-in-a-name">What's in a name?</a></h2>
<p>I don't know about you, but I find using a function called <code>adjacent_difference</code>
to compute sums of adjacent elements... perverse. Code using
<code>adjacent_difference</code> to compute something <em>other</em> than differences, is going to
suffer in readability. In my opinion it's a poorly named function and should
probably have been called something like <code>transform_adjacent_pairs</code>. I would
have no qualms about implementing my own <code>transform_adjacent_pairs</code> algorithm
and using it in preference to <code>adjacent_difference</code>.</p>
<h2><a class="header" href="#tldr" id="tldr">TL;DR</a></h2>
<ul>
<li>Using STL algorithms effectively can help us to write fewer bugs.</li>
<li>Use of well-named algorithms conveys important semantic information to readers
of our code and helps them reason about what it is doing.</li>
<li>Remember that <code>vector::push_back</code> has to do capacity checks, which could fill
your hot path with conditionals. For trivial types it <em>might</em> be cheaper to
initialise all of the elements up-front and then overwrite with new values,
thus avoiding <code>push_back</code>. But <strong>profile</strong> before making this decision.</li>
</ul>
<h2><a class="header" href="#further-references" id="further-references">Further references</a></h2>
<ul>
<li><a href="https://www.oreilly.com/library/view/effective-stl/9780321545183/">Scott Meyers, Effective STL</a> is fairly old now, but gives an excellent grounding in how to think and program using the STL algorithms.</li>
</ul>
<h2><a class="header" href="#submissions-in-this-category-1" id="submissions-in-this-category-1">Submissions in this category</a></h2>
<ul>
<li><a href="./solutions/GroovyZone.html">GroovyZone</a></li>
<li><a href="./solutions/LordVader.html">LordVader</a></li>
</ul>
<h3><a class="header" href="#created-by-arh" id="created-by-arh">Created by arh</a></h3>
<ul>
<li><a href="./solutions/LordVader2_arh.html">LordVader2_arh</a> An improved version of LordVader</li>
</ul>
<div class="footnote-definition" id="1"><sup class="footnote-definition-label">1</sup>
<p>May the great Stepanov forgive my blasphemy.</p>
</div>
<div class="footnote-definition" id="2"><sup class="footnote-definition-label">2</sup>
<p>OK yes, I did cheat a bit. You'd need to use <code>namespace ranges = std::ranges;</code>
to make this code compile.</p>
</div>
<div class="footnote-definition" id="3"><sup class="footnote-definition-label">3</sup>
<p>My suspicion is that the requirement to check the vector size before every
element insertion is actually inhibiting some SIMD optimisations that
would otherwise happen. Looking at the generated assembly code appears to
support this hypothesis.</p>
</div>
<h1><a class="header" href="#threads-to-the-rescue" id="threads-to-the-rescue">Threads to the rescue!</a></h1>
<p style="color:red;font-size:30px;">Section not complete</p>
<h2><a class="header" href="#submissions-in-this-category-2" id="submissions-in-this-category-2">Submissions in this category</a></h2>
<ul>
<li><a href="threads/../solutions/Pixelf.html">Pixelf</a></li>
</ul>
<h3><a class="header" href="#created-by-arh-1" id="created-by-arh-1">Created by arh</a></h3>
<ul>
<li><a href="threads/../solutions/Pixelf_TBB_arh.html">Pixelf_TBB_arh</a></li>
<li><a href="threads/../solutions/Pixelf_TBB_scalable_alloc_arh.html">Pixelf_TBB_scalable_alloc_arh</a></li>
<li><a href="threads/../solutions/Pixelf_TBB_spans_arh.html">Pixelf_TBB_spans_arh</a></li>
</ul>
<h2><a class="header" href="#discussion" id="discussion">Discussion</a></h2>
<p>Whenever an algorithm isn't performing well, someone usually comes along and
suggests multi-threading as a solution. They should be met with a hard
stare and challenged to provide evidence that there are no further gains to be
had from improving the existing single-threaded solution. If you multi-thread
a poorly implemented algorithm then you're magnifying the impact of that poor
design and wasting limited resources.</p>
<p>On an 8 core machine, the <em>best case</em> speed-up from multi-threading an algorithm
is 8x. We've seen in other sections of this writeup that careful
changes to a single-threaded algorithm can yield <em>orders of magnitude</em>
improvements. In case it's not obvious, 'orders of magnitude' is usually a bigger number
than 8.</p>
<p>But writing multi-threaded code makes you look cool. So there's that.</p>
<h2><a class="header" href="#benchmarks-1" id="benchmarks-1">Benchmarks</a></h2>
<p>show one plot (probs log throughput with annotation), then the &quot;Embarrassing&quot; section</p>
<p><em>NOTE: The vertical red line marks the point where integer overflow occurs in the
row values. Generating triangles larger than this is pointless. We're only doing
it to see how the algorithms scale.</em></p>
<p>The vertical blue line marks the point where the triangle has 5000 rows.</p>
<h4><a class="header" href="#time-to-generate-a-triangle-2" id="time-to-generate-a-triangle-2">Time to generate a triangle</a></h4>
<p><a href="threads/../images/generated/threads_generate_cpu_bench.svg"><img src="threads/../images/generated/threads_generate_cpu_bench.svg" alt="" /></a></p>
<h4><a class="header" href="#element-throughput-3" id="element-throughput-3">Element throughput</a></h4>
<p><a href="threads/../images/generated/threads_generate_throughput_log_scale_bench.svg"><img src="threads/../images/generated/threads_generate_throughput_log_scale_bench.svg" alt="" /></a></p>
<p><a href="threads/../images/generated/threads_generate_throughput_linear_scale_bench.svg"><img src="threads/../images/generated/threads_generate_throughput_linear_scale_bench.svg" alt="" /></a></p>
<h2><a class="header" href="#how-embarrassing" id="how-embarrassing">How embarrassing</a></h2>
<p>Computing Pascal's Triangle is what's known as an 'embarrassingly parallel'
problem. It requires absolutely no effort to separate it into parallel tasks -
all of the rows can be computed completely independently. That's what <a href="threads/../solutions/Pixelf.html">Pixelf</a>
does. It computes each row on a different thread. On paper this ought to result
in an immediate 8x speed-up and congratulatory back-slaps all round.</p>
<p>You've probably already noticed from the benchmarks that the performance isn't
great. In fact, <a href="threads/../solutions/Pixelf.html">Pixelf</a> is hands-down <strong>the worst-performing solution that was
submitted</strong>. All the way up to 64 rows, <a href="threads/../solutions/Pixelf.html">Pixelf</a> is consistently about 120 times
slower than the baseline nested-loops solution. It's only when you get up to
around 12,000 rows (~72M elements) that <a href="threads/../solutions/Pixelf.html">Pixelf</a> finally begins to pull <em>slightly</em>
ahead.</p>
<p>How can this happen when we're spreading the work over multiple cores and
there is no shared state or locks to hold us up?</p>
<p>It turns out that there are many reasons. Let's dive into some of them...</p>
<h1><a class="header" href="#making-a-stink-about-stdasync" id="making-a-stink-about-stdasync">Making a stink about std::async</a></h1>
<p style="color:red;font-size:30px;">Section not complete</p>
<h3><a class="header" href="#what-does-stdasync-do-for-us" id="what-does-stdasync-do-for-us">What does <code>std::async</code> do for us?</a></h3>
<p><a href="threads/../solutions/Pixelf.html">Pixelf</a> uses <code>std::async</code> to launch its worker threads.
According to <a href="https://en.cppreference.com/w/cpp/thread/async">cppreference</a>:</p>
<blockquote>
<p>The function template <code>async</code> runs the function <code>f</code> asynchronously (potentially in a separate thread which may be part of a thread pool) and returns a <code>std::future</code> that will eventually hold the result of that function call.</p>
</blockquote>
<p>The wording here is interesting. &quot;<em>potentially</em> in a separate thread&quot; and &quot;<em>may
be</em> part of a thread pool&quot; should raise some eyebrows.</p>
<p>So we've got some expensive piece of work that needs doing. We wrap
it in a function object (could simply be a lambda) which we pass to <code>std::async</code>:</p>
<pre><code class="language-c++">auto some_expensive_computation = [](Arg1 a1, Arg2 a2) -&gt; int {
  ... costly things ...
}

std::future&lt;int&gt; result =
  std::async(some_expensive_computation, arg1, arg2);

...

// Some time later
std::cout &lt;&lt; &quot;The result was: &quot; &lt;&lt; result.get() &lt;&lt; '\n';
</code></pre>
<p>In return we get handed a <code>std::future</code> object which has a <code>get()</code> method on it.
If we call <code>get()</code> it will block until the result of our computation is ready.</p>
<p>In theory we can call <code>std::async</code> and have it run our function on some other
thread, while we get on with doing other work. Once we get to a point where we
absolutely cannot proceed without the result of the function, we call <code>get</code> and
hopefully don't have to wait too long for the result. If the result is already
available then <code>get()</code> will return immediately.</p>
<p><code>std::async</code> has two different 'launch' policies. When you call it, you can
request the <code>std::launch::async</code> policy which causes the function to be invoked
on a different thread, or you can request <code>std::launch::deferred</code> which causes
the function to be invoked <em>on your own thread</em>, but only when you call <code>get()</code>.
If you don't specify a launch policy at all, then <code>std::async</code> gets to choose
for you. Exciting!</p>
<p><a href="threads/../solutions/Pixelf.html">Pixelf</a> does not specify a launch policy, opting instead
to leave the performance choices up to the compiler vendor. Under Clang 10, the
default policy appears to always launch a new thread. I've seen no evidence of a
thread pool.</p>
<h3><a class="header" href="#always-launch-a-new-thread-you-say" id="always-launch-a-new-thread-you-say">Always launch a new thread, you say?</a></h3>
<p>Here's the code that launches the row-filling tasks:</p>
<pre><code class="language-c++">std::vector&lt;std::future&lt;void&gt;&gt; futures;
for (uint32_t i = 0; i &lt; n_rows; ++i) {
  futures.emplace_back(std::async(FillRowN, std::ref(rows[i]), i + 1));
}
</code></pre>
<p>If we ask for a Pascal's Triangle with 12 rows, this loop will launch 12 new threads,
make 12 allocations to hold function results and construct 12 mutexes, 12
condition variables and 12 <code>std::future</code> objects.</p>
<p>If we ask for a Pascal's Triangle with 65,000 rows, this loop will launch 65,000 new
threads, make 65,000 allocations to hold function results and construct 65,000
mutexes, 65,000 condition variables and 65,000 <code>std::future</code> objects.</p>
<p>I think that's a slightly-too-large hammer to be applying here.</p>
<h3><a class="header" href="#ok-fine-thats-a-lot-of-threads-so-what" id="ok-fine-thats-a-lot-of-threads-so-what">OK fine. That's a lot of threads. So what?</a></h3>
<p>Let's fire up the frame profiler and take a look at what's going on when <a href="threads/../solutions/Pixelf.html">Pixelf</a>
generates a triangle with 5000 rows (~12.5M elements). We're going to be looking
at times as reported by Tracy. For Pixelf, using Tracy has just under a 2x speed
penalty. These times won't correspond directly to what we see in the benchmarks.</p>
<p><a href="threads/../images/pixelf_small_rows.png"><img src="threads/../images/pixelf_small_rows.png" alt="" /></a></p>
<p>This is just the first 500us or so of the program's execution. The x-axis
represents time. Every horizontal lane (labelled with numbers like <code>668661905</code>)
represents a different thread. There are just under 5000 more of these spilling
off the bottom of the display; one for every thread that got launched. The top
lane is the main thread. The filled purple boxes represent zones in the
code that I have explicitly instrumented. You can see the main thread repeatedly
entering the 'Launch Job' zone, which corresponds to where <a href="threads/../solutions/Pixelf.html">Pixelf</a>
calls <code>std::async</code>.</p>
<p>Each of the 5000 threads has a zone labelled &quot;FillRowN&quot;, which is where the
thread does the work of filling the Nth row of the triangle. But you can't see
the labels without zooming in a long way. At this stage in the execution, those
jobs are taking less than 500ns.</p>
<p>The glaringly obvious fact here is that none of those job tasks on the other
threads are actually running simultaneously. The reality is that <code>std::async</code>
is taking an average of 40us to launch each job and return to its caller, and
then the job itself (computing a handful of pascal's triangle elements) is
taking just 500ns. Far from getting a benefit through threading, we're paying a
surcharge of 39.5us per row for the coolness factor. The CPU cores are starved
of work because <code>std::async</code> simply can't launch threads fast enough.</p>
<p>OK, that's what happens when the rows are very small. What about the rows at the
bottom end of the triangle? The ones with thousands of elements.</p>
<p><a href="threads/../images/pixelf_large_rows.png"><img src="threads/../images/pixelf_large_rows.png" alt="" /></a></p>
<p>That's a bit better. For one glorious instant, there are 9 threads working
simultaneously. But throughput is still limited by the rate at which <code>std::async</code>
can launch new threads.</p>
<p>Overall for a 5000 row triangle, the main thread takes a mean of 40us to launch
a job, and the jobs last for a mean of 56us. As a result, for much of the time
the CPU cores are sitting idle and work rarely happens in parallel. </p>
<h2><a class="header" href="#and-theres-more" id="and-theres-more">And there's more!</a></h2>
<p>Now let's point the frame profiler at the final loop - the one that waits for
all of the futures to complete:</p>
<pre><code class="language-c++">for (auto&amp; f : futures) {
  f.get();
}
</code></pre>
<p>You'd think that <code>get()</code> ought to return immediately for all but the last few
threads. But that's not all that's happening here. In fact, when you call <code>get()</code>
on a future, not only does it have to lock and unlock a mutex (~37ns), it also
takes the opportunity to deallocate the shared state that is used to communicate
the result from the task. That brings the time for every non-blocking call to <code>get()</code>
up to ~220ns. Multiply that by 5000 and you've got just over a millisecond.</p>
<p><a href="threads/../images/pixelf_future_destruction.png"><img src="threads/../images/pixelf_future_destruction.png" alt="" /></a></p>
<p>You can see the deallocation happening if you look at the yellow memory-usage
graph during the &quot;Waiting for job completion&quot; zone. Once all the jobs have finished,
<a href="threads/../solutions/Pixelf.html">Pixelf</a> still takes another 1ms just to wait for all the
threads and destroy the shared state. Admittedly that's only a small part of the
133ms overall time (as measured in Tracy).
(this last sentence ends the page a bit abruptly)</p>
<h1><a class="header" href="#when-stealing-is-a-virtue" id="when-stealing-is-a-virtue">When stealing is a virtue</a></h1>
<p style="color:red;font-size:30px;">Section not complete</p>
<h2><a class="header" href="#can-we-do-better" id="can-we-do-better">Can we do better?</a></h2>
<p>It should be clear by now that <code>std::async</code> is not the correct tool for this
job. It's much better suited to one-off long-running concurrent tasks, rather
than executing a series of repeated tasks. One reviewer suggested</p>
<blockquote>
<p>&quot;Could use a work-stealing setup with an atomic int for threads to grab the
next available row, and signal when there's no more work.&quot;</p>
</blockquote>
<p>That's a very insightful comment, but it does gloss over a fearsome amount of detail.</p>
<p>A 'work-stealing queue' is a scheduling technique where a pool of worker
threads each have their own job queue, with a scheduler to distribute work
between the queues. Typically the queues are implemented as
lock-free data structures, to avoid the performance horrors associated with
waiting on mutexes. If a worker thread runs out of tasks on its own queue, it's
allowed to poll the queues of other workers and 'steal' work from them. That
ensures you don't have threads sitting around idle while others are still
working.</p>
<p>Writing a good lock-free queue implementation is extremely difficult. Debugging
it is even harder. Fortunately there are some high quality implementations of
these concepts freely available from trusted vendors. None of them were within
the rules of this coding challenge, but I want to give a glimpse of what's
possible with a good concurrency library. In particular, let's experiment a little
with Intel's <a href="https://github.com/oneapi-src/oneTBB">Threading Building Blocks (TBB)</a>.</p>
<p>Before we go on, I want to reiterate the point that trying to optimise the
Pascal's Triangle algorithm is a <!-- [Bad Idea](../benchmark_caveats.md) --> Bad Idea. Using threads
to optimise it is a Really Bad Idea. For any reasonable row count (i.e. smaller
than 64 rows which is the size where integer overflow happens), the cost of
launching a thread is <em>always</em> going to be greater than just getting on and 
computing the values on the current thread. We're <em>only</em> doing this because it's
fun and instructive to see the effects of different design decisions.</p>
<h3><a class="header" href="#using-tbbparallel_for-to-make-the-cpu-work-harder-pixelf_tbb_arh" id="using-tbbparallel_for-to-make-the-cpu-work-harder-pixelf_tbb_arh">Using <code>tbb::parallel_for</code> to make the CPU work harder (Pixelf_TBB_arh)</a></h3>
<p><a href="https://github.com/oneapi-src/oneTBB">TBB</a> supports a
number of different threading models. One of the highest-level abstractions it
offers is the <code>parallel_for</code> command. You pass it a function object and an input
range and it will do the hard work of dividing the work up into batches and
dispatching it to a thread pool via work-stealing queues.</p>
<p><a href="threads/../solutions/Pixelf.html">Pixelf's</a> <code>FillRowsInParallel</code> function becomes <code>FillRowBlock</code>:</p>
<pre><code class="language-c++"><!--
-->void FillRowBlock(vector&lt;vector&lt;uint64_t&gt;&gt;& rows,
                  const <b>tbb::blocked_range&lt;uint32_t&gt;</b>& r) {
  for (auto i = r.begin(); i < r.end(); ++i) {
    FillRowN(rows[i], i + 1);
  }
}
</code></pre>
<p>The <code>blocked_range</code> type gets passed in by TBB with a list of row indices.
<code>FillRowBlock</code> simply iterates through them all and generates the values.</p>
<p>In the outer <code>generate_rows</code> function, we launch the tasks with a call to
<code>parallel_for</code>:</p>
<pre><code class="language-c++">tbb::parallel_for(tbb::blocked_range&lt;uint32_t&gt;(0, num_rows),
                  [&amp;rows](auto&amp; r) { FillRowBlock(rows, r); });
</code></pre>
<p>The first argument here specifies a range containing <em>all</em> of the rows that need
filling, and the lambda function needs to accept subsets of that range.</p>
<p>That's literally it. TBB handles setting up of the task scheduler and thread pool
automatically.</p>
<p>You can find the full source on the <a href="threads/../solutions/Pixelf_TBB_arh.html">Pixelf_TBB_arh</a> page.</p>
<h3><a class="header" href="#how-does-it-do" id="how-does-it-do">How does it do?</a></h3>
<h4><a class="header" href="#time-to-generate-a-triangle-3" id="time-to-generate-a-triangle-3">Time to generate a triangle</a></h4>
<p><a href="threads/../images/generated/threads_TBB_generate_cpu_bench.svg"><img src="threads/../images/generated/threads_TBB_generate_cpu_bench.svg" alt="" /></a></p>
<h4><a class="header" href="#element-throughput-4" id="element-throughput-4">Element throughput</a></h4>
<p><a href="threads/../images/generated/threads_TBB_generate_throughput_log_scale_bench.svg"><img src="threads/../images/generated/threads_TBB_generate_throughput_log_scale_bench.svg" alt="" /></a>
<a href="threads/../images/generated/threads_TBB_generate_throughput_linear_scale_bench.svg"><img src="threads/../images/generated/threads_TBB_generate_throughput_linear_scale_bench.svg" alt="" /></a></p>
<p>OK, so performance isn't stellar against the single-threaded baseline solution,
but at least we've beaten the pants off <a href="threads/../solutions/Pixelf.html">Pixelf</a>.</p>
<p>What about CPU usage? Let's fire up the frame profiler again:</p>
<p><a href="threads/../images/pixelftbb_simple_zones.png"><img src="threads/../images/pixelftbb_simple_zones.png" alt="" /></a></p>
<p>Now we're talking! There are exactly 16 threads: one for each logical core<sup class="footnote-reference"><a href="#1">1</a></sup>.
Each of which is fully occupied with jobs. <em>Even the main thread which launched
the tasks is executing jobs!</em></p>
<p>That's the power of a good threading library.</p>
<div class="footnote-definition" id="1"><sup class="footnote-definition-label">1</sup>
<p>During benchmarking I disabled hyper-threading, so only the 8 physical
cores were available. But when I took the Tracy screenshot, hyper-threading
was enabled, so 16 logical cores were available.</p>
</div>
<h1><a class="header" href="#using-custom-memory-allocators" id="using-custom-memory-allocators">Using custom memory allocators</a></h1>
<p style="color:red;font-size:30px;">Section not complete</p>
<p>Let's drill down still further and add some instrumentation within the
<code>FillRowN</code> function in <a href="threads/../solutions/Pixelf_TBB_arh.html">Pixelf_TBB_arh</a>. Specifically let's look at how much time is spent resizing
the row vector versus how much time is spent computing elements.</p>
<p><a href="threads/../images/pixelftbb_detailed_zones.png"><img src="threads/../images/pixelftbb_detailed_zones.png" alt="" /></a></p>
<p>Every thread lane has three rows of zones in it now. <code>ResizeRow</code> and
<code>ComputeElements</code> are child zones of <code>FillRowN</code>, which is itself a child zone of
<code>FillRowBlock</code>.</p>
<p>The most startling thing here is that <code>FillRowN</code> spends more than half its time
resizing row vectors. Almost all of that time is going to be spent waiting for
memory allocation. We <em>thought</em> we'd achieved excellent CPU usage, but in fact
the threads are spending most of their time twiddling their thumbs, waiting on
memory. That's disastrous for performance.</p>
<p>On average, <code>ResizeRow</code> is taking 41us and <code>ComputeElements</code> is taking 17us.
Assuming that multi-threading is only helpful for the computation of
elements, then only 29% of our workload will benefit.
<a href="https://en.wikipedia.org/wiki/Amdahl%27s_law">Amdahl's Law</a> tells us
that the theoretical maximum speedup is therefore only ~1.4x, <em>even with 16
threads</em>.</p>
<p>Unless we can get rid of that memory allocation bottleneck a threaded solution
is always going to be hamstrung.</p>
<h3><a class="header" href="#does-a-faster-memory-allocator-help" id="does-a-faster-memory-allocator-help">Does a faster memory allocator help?</a></h3>
<p>One of the problems with having 16 threads all hungrily asking for memory is 
that the poor old memory allocator is getting hammered. Luckily for us, the
ever-thoughtful developers of TBB have thought of this, and provided some more
thread-friendly memory allocators.</p>
<p>In <a href="threads/../solutions/Pixelf_TBB_scalable_alloc_arh.html">Pixelf_TBB_scalable_alloc_arh</a>
I've switched out the row vectors' default memory allocator and replaced it with
the <a href="https://www.threadingbuildingblocks.org/docs/help/reference/memory_allocation/scalable_allocator_cls.html"><code>tbb::scalable_allocator</code></a>.
Using it does not do anything at all for the mean row-resize time. But it does
tighten up the distribution, knocking 18us off the mode. You can see the
difference in the latency histograms:</p>
<p><strong>WARNING: The x-axes have different scales!</strong>
lose these graphs??</p>
<h4><a class="header" href="#pixelf_tbb_arh-row-resize-latency" id="pixelf_tbb_arh-row-resize-latency">Pixelf_TBB_arh row resize latency</a></h4>
<p><a href="threads/../images/pixelftbb_resize_latency.png"><img src="threads/../images/pixelftbb_resize_latency.png" alt="" /></a></p>
<h4><a class="header" href="#pixelf_tbb_scalable_alloc_arh-row-resize-latency" id="pixelf_tbb_scalable_alloc_arh-row-resize-latency">Pixelf_TBB_scalable_alloc_arh row resize latency</a></h4>
<p><a href="threads/../images/pixelftbb2_resize_latency.png"><img src="threads/../images/pixelftbb2_resize_latency.png" alt="" /></a></p>
<h3><a class="header" href="#benchmarks-2" id="benchmarks-2">Benchmarks</a></h3>
<p>What about the benchmarks? Using the different allocator does make a modest
improvement, but it won't blow your socks off.</p>
<table><thead><tr><th>Solution</th><th>Time to generate a 5000 row triangle</th></tr></thead><tbody>
<tr><td>Baseline</td><td>32.3ms</td></tr>
<tr><td>Pixelf</td><td>65.9ms</td></tr>
<tr><td>Pixelf_TBB_arh</td><td>18.6ms</td></tr>
<tr><td>Pixelf_TBB_scalable_alloc_arh</td><td>11.3ms</td></tr>
</tbody></table>
<h4><a class="header" href="#time-to-generate-a-triangle-4" id="time-to-generate-a-triangle-4">Time to generate a triangle</a></h4>
<p><a href="threads/../images/generated/threads_TBB2_generate_cpu_bench.svg"><img src="threads/../images/generated/threads_TBB2_generate_cpu_bench.svg" alt="" /></a></p>
<h4><a class="header" href="#element-throughput-5" id="element-throughput-5">Element throughput</a></h4>
<p><a href="threads/../images/generated/threads_TBB2_generate_throughput_log_scale_bench.svg"><img src="threads/../images/generated/threads_TBB2_generate_throughput_log_scale_bench.svg" alt="" /></a>
<a href="threads/../images/generated/threads_TBB2_generate_throughput_linear_scale_bench.svg"><img src="threads/../images/generated/threads_TBB2_generate_throughput_linear_scale_bench.svg" alt="" /></a></p>
<p>Compared to the <a href="threads/../solutions/Baseline.html">Baseline</a> single-threaded solution,
using all of the machine's threads does to some extent stave-off the dramatic
performance drop-off that comes when Pascal's Triangle no-longer fits in the 
L3 cache. But I'd argue it's really not worth the extra resource usage.</p>
<style>
.center {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
</style>
<h1><a class="header" href="#use-moar-cores" id="use-moar-cores">Use Moar Cores!</a></h1>
<p style="color:red;font-size:30px;">Section not complete</p>
<p>I know what you're thinking. You're thinking:
&quot;8 cores is puny! Find a bigger computer!&quot;</p>
<p>Oh? You weren't thinking that? Well I was. Each to their own.</p>
<p>So anyway, I found a computer under colleague Luis' desk which has 32 physical
cores in it. I wrote a benchmark to see how the element throughput of the TBB
solutions changes as the number of threads available to the thread-pool is
increased from 1 to 32. In an ideal world, performance would scale directly
with the number of cores doing work.</p>
<img src="threads/../images/use_all_the_cores.jpg" alt="Use all of the cores" width="60%" class="center">
<h4><a class="header" href="#throughput-scaling-with-number-of-threads-32-core-machine" id="throughput-scaling-with-number-of-threads-32-core-machine">Throughput scaling with number of threads (32-core machine)</a></h4>
<p><a href="threads/../images/generated/amdahl_speedup.svg"><img src="threads/../images/generated/amdahl_speedup.svg" alt="" /></a></p>
<p>The black line shows the 'ideal' speedup that we should achieve if doubling the
number of threads would halve the time taken to compute the elements of Pascal's
Triangle.</p>
<p>Upsettingly the reality is nowhere near as good as that. Poor old
<a href="threads/../solutions/Pixelf_TBB_arh.html">Pixelf_TBB_arh</a> is struggling to hit even a 7.5x
speedup, even if we throw the full 32 cores at it. Looking at the way the graph
is levelling out, it looks like even if we could bring 2048 cores to bear at the
problem, we'd still not do better than an 8x speedup.</p>
<p><a href="threads/../solutions/Pixelf_TBB_scalable_alloc_arh.html">Pixelf_TBB_scalable_alloc_arh</a>
does a little better, but has pretty much given up once it's hit a 12x speedup.</p>
<h2><a class="header" href="#theres-a-law-for-that" id="theres-a-law-for-that">There's a law for that</a></h2>
<p>Consider an idealised model of the situation we've got. Every time we compute
Pascal's triangle there are three distinct phases. First we have a bit of setup
cost (initialising the thread pool and launching tasks), then we have the row
tasks that can all run in parallel, and finally we have a teardown phase
(deallocating memory, destroying threads etc...)</p>
<p><img src="threads/../images/concurrent_tasks.jpeg" alt="" /></p>
<p>Assume T<sub>1</sub> is the total amount that work that needs doing. It's equal
to the time taken to compute the whole triangle on a single core. Here it would
be:</p>
<p>need white backgrounds for this to work on dark mode
<img src="threads/../images/tasks_work.svg" alt="Equation for total work"></p>
<p>Then T<sub>∞</sub> is the time taken if we had an infinite number of cores
available. This is also known as the 'span' because it's equal to the length of
the critical path through the task graph. In our case,</p>
<img src="threads/../images/tasks_span.svg" alt="Equation for span">
<p>Given those two quantities, the speedup we can obtain through multi-threading
is then bounded above by:</p>
<img src="threads/../images/speedup_bound.svg" alt="Equation for span">
<p>For instance, if we had 100 units of work to do, and the critical path (span)
was 5 units of work, then the maximum speedup we could achieve would be 20x.</p>
<p>Another way of stating this is through
<a href="https://en.wikipedia.org/wiki/Amdahl%27s_law">Amdahl's law</a>:</p>
<img src="threads/../images/amdahls_law.svg" alt="Equation for Amdahl's law">
<p>Here f is the potion of the job which can be parallelised and p is the number of
cores to use. There's a lovely plot showing how an algorithm scales with CPUs for
various parallel portions on the <a href="https://en.wikipedia.org/wiki/Amdahl%27s_law">Wikipedia Page on Amdahl's Law</a><sup class="footnote-reference"><a href="#1">1</a></sup>:</p>
<p><a href="threads/../images/amdahls_law_graph.svg"><img src="threads/../images/amdahls_law_graph.svg" alt="" /></a></p>
<p>The take-home point is this:</p>
<blockquote>
<p>Even if you manage to get as much as 95% of your algorithm to be executed in
parallel, the maximum speedup you can <em>ever</em> achieve by increasing the number of
processors is 20x.</p>
</blockquote>
<h2><a class="header" href="#improving-the-scaling-of-the-tbb-solutions" id="improving-the-scaling-of-the-tbb-solutions">Improving the scaling of the TBB solutions</a></h2>
<p>Judging from the thread scaling benchmark results we saw,
<a href="threads/../solutions/Pixelf_TBB_arh.html">Pixelf_TBB_arh</a>'s 7.5x maximum speedup corresponds
to a parallelised portion of ~87%. <a href="threads/../solutions/Pixelf_TBB_scalable_alloc_arh.html">Pixelf_TBB_scalable_alloc_arh</a> saw an upper bound of ~12x, which corresponds
to ~92% of the algorithm running in parallel.</p>
<p>The obvious thing to do is to look at ways of reducing the portion of the algorithm
that must run in serial. We can't do anything about the TBB setup time, but we
can do something about our other big bottle-neck: memory allocation. When the
memory allocator is under high contention, some threads will be forced to wait
in line. That congestion reduces the amount of parallelism we can achieve.</p>
<p>As we did with <a href="threads/../solutions/FlyingDesitter_arh.html">FlyingDesitter_arh</a> in the
<a href="threads/../loops/span.html">When everything looks like a nail...</a> section we can do away
with almost all of the memory allocation and just do a single up-front
allocation that will hold the whole triangle. I won't go into details here
because it's very similar, but you can look at the code of <a href="threads/../solutions/Pixelf_TBB_spans_arh.html">Pixelf_TBB_spans_arh</a>
to see how it's done.</p>
<h2><a class="header" href="#benchmark-results" id="benchmark-results">Benchmark results</a></h2>
<h4><a class="header" href="#throughput-scaling-with-number-of-threads-32-core-machine-1" id="throughput-scaling-with-number-of-threads-32-core-machine-1">Throughput scaling with number of threads (32-core machine)</a></h4>
<p><a href="threads/../images/generated/amdahl2_speedup.svg"><img src="threads/../images/generated/amdahl2_speedup.svg" alt="" /></a></p>
<h4><a class="header" href="#time-to-generate-a-triangle-5" id="time-to-generate-a-triangle-5">Time to generate a triangle</a></h4>
<p><a href="threads/../images/generated/amdahl_generate_cpu_bench.svg"><img src="threads/../images/generated/amdahl_generate_cpu_bench.svg" alt="" /></a></p>
<h4><a class="header" href="#element-throughput-6" id="element-throughput-6">Element throughput</a></h4>
<p><a href="threads/../images/generated/amdahl_generate_throughput_log_scale_bench.svg"><img src="threads/../images/generated/amdahl_generate_throughput_log_scale_bench.svg" alt="" /></a></p>
<p><a href="threads/../images/generated/amdahl_generate_throughput_linear_scale_bench.svg"><img src="threads/../images/generated/amdahl_generate_throughput_linear_scale_bench.svg" alt="" /></a></p>
<h2><a class="header" href="#descaling-the-barrel-before-we-scrape-it-further" id="descaling-the-barrel-before-we-scrape-it-further">Descaling the barrel before we scrape it further</a></h2>
<p>Gratifyingly enough, we get much better CPU scaling from
<a href="threads/../solutions/Pixelf_TBB_spans_arh.html">Pixelf_TBB_spans_arh</a>. And of course the
algorithm runs a bit better when you bin all the memory allocation. But it's
<strong>still</strong> not even as good as the <a href="threads/../solutions/Baseline.html">Baseline</a>
raw loop solution, and <a href="threads/../solutions/FlyingDesitter_arh.html">FlyingDesitter_arh</a>
leaves them <em>all</em> grovelling in the dirt. By this point, I imagine you will have grimly
steeled yourself against the possibility that there's another whole section
coming up which finally uncovers the reason for the utter shabbiness of these
multi-threaded solutions. Click on, if you can bear it.</p>
<p><sup class="footnote-reference"><a href="#1">1</a></sup> Image by wikipedia user <a href="https://en.wikipedia.org/wiki/User:Daniels220">Daniels220</a>
and licensed under Creative Commons Attribution-Share Alike 2.0 Unported.
<a href="https://commons.wikimedia.org/wiki/File:AmdahlsLaw.svg">https://commons.wikimedia.org/wiki/File:AmdahlsLaw.svg</a></p>
<h1><a class="header" href="#data-dependencies" id="data-dependencies">Data dependencies</a></h1>
<p>(new title - TBC)</p>
<p style="color:red;font-size:30px;">Section not complete</p>
<p>Previous sections have hopefully convinced you that the overhead of multi-
threading makes it unsuitable for short-lived tasks. Even with all our extra efforts, the result is so much .....</p>
<p>But you may still be
wondering why <a href="threads/../solutions/Pixelf.html">Pixelf</a> and its derivatives are <strong>so
much slower</strong> than the simple nested for-loop in the
<a href="threads/../solutions/Baseline.html">Baseline</a> solution. The reason is quite
interesting, and one shrewd reviewer of <a href="threads/../solutions/Pixelf.html">Pixelf</a>
put their finger right on it. It comes down to the way that the row
values are computed, and how well the compiler can optimise it.</p>
<p>The single-threaded solutions generally chose to compute row elements by summing
pairs of elements from the <em>previous</em> row. <a href="threads/../solutions/Pixelf.html">Pixelf</a>
wasn't able to do that, because every row is computed on a different thread.
That means the order of computation is no longer deterministic. The previous
row may not even be <em>available</em> when you want to read its values. You could try
to add some synchronisation and ensure rows are computed in sequential order,
but then of course you've totally negated any benefit of using multiple threads.</p>
<p><a href="threads/../solutions/Pixelf.html">Pixelf's</a> author needed a way of computing rows
<em>completely independently of each other</em>. They used the fact that the elements
of Pascal's Triangle are all binomial coefficients, where the <em>k</em>th entry of the
<em>n</em>th row can be computed as &quot;n choose k&quot;, or</p>
<img src="threads/../images/n_choose_k.svg" alt="n choose k equation" height="70px">
<p>There's a nice recurrence relation that let's us compute the values of a single
row sequentially:</p>
<img src="threads/../images/binomial_recurrence.svg" alt="binomial recurrence relation" height="70px">
<p>We can see the two approaches in these code snippets:</p>
<h4><a class="header" href="#baseline" id="baseline">Baseline</a></h4>
<pre><code class="language-c++">for (uint32_t j = 1; j &lt; i; ++j) {
  // Computes row elements by summing values from previous rows
  row[j] = triangle[i - 1][j - 1] + triangle[i - 1][j];
}
</code></pre>
<h4><a class="header" href="#pixelf" id="pixelf">Pixelf</a></h4>
<pre><code class="language-c++">for (uint32_t k = 1; k &lt; n / 2 + 1; ++k) {
  // Recursively computes row elements
  row[k] = (row[k - 1] * (n - k)) / k;
}
// Copies elements from the first half into the second half (in reverse order)
std::copy(row.begin(), row.begin() + n / 2, row.rbegin());
</code></pre>
<p><em>Pixelf uses 1-based row indexing, so the recurrence relation is slightly
different to the equation stated above.</em></p>
<h2><a class="header" href="#how-to-prevent-the-compiler-from-helping-you" id="how-to-prevent-the-compiler-from-helping-you">How to prevent the compiler from helping you</a></h2>
<p>It's clear that <a href="threads/../solutions/Baseline.html">Baseline</a> requires a single addition
operation to compute new row elements. <a href="threads/../solutions/Pixelf.html">Pixelf</a> needs 1
subtraction, 1 multiplication and a division operation. But there's actually a bit
more to it than that.</p>
<p>Consider the following eerily familiar chunk of code. We'll call it <code>unicorn_loop</code>
because of its mysterious super-powers:</p>
<pre><code class="language-c++">void unicorn_loop(uint64_t const* prev_row, uint64_t* __restrict next_row) {
  for (int i = 0; i&lt;8; ++i) {
      next_row[i] = prev_row[i] + prev_row[i+1];
  }
}
</code></pre>
<p>The <code>__restrict</code> keyword is just there to tell the compiler that <code>next_row</code> and
<code>prev_row</code> are in different memory locations, so that it can optimise efficiently.</p>
<p>I compiled it with two different sets of flags on the gcc compiler:</p>
<ul>
<li><code>-O3 -mno-sse</code> (all optimisations, but no SIMD instructions allowed)</li>
<li><code>-O3 -mavx512f</code> (all optimisation, avx512 instructions allowed)</li>
</ul>
<p>As you can see, the difference is huge:</p>
<table>
<tr>
<th>
No vectorisation (-O3 -mno-sse)
</th>
<th>
avx512 instructions allowed (-O3 -mavx512f)
</th>
</tr>
<tr>
<td valign="top">
<pre><code class="language-c++"><!--
-->unicorn_loop(unsigned long const*, unsigned long*):
        mov     rdx, QWORD PTR [rdi]
        mov     rax, QWORD PTR [rdi+8]
        add     rdx, rax
        add     rax, QWORD PTR [rdi+16]
        mov     QWORD PTR [rsi+8], rax
        mov     rax, QWORD PTR [rdi+16]
        add     rax, QWORD PTR [rdi+24]
        mov     QWORD PTR [rsi], rdx
        mov     QWORD PTR [rsi+16], rax
        mov     rax, QWORD PTR [rdi+24]
        add     rax, QWORD PTR [rdi+32]
        mov     rdx, QWORD PTR [rdi+48]
        mov     QWORD PTR [rsi+24], rax
        mov     rax, QWORD PTR [rdi+32]
        add     rax, QWORD PTR [rdi+40]
        mov     QWORD PTR [rsi+32], rax
        mov     rax, QWORD PTR [rdi+40]
        add     rax, QWORD PTR [rdi+48]
        mov     QWORD PTR [rsi+40], rax
        mov     rax, QWORD PTR [rdi+56]
        add     rdx, rax
        add     rax, QWORD PTR [rdi+64]
        mov     QWORD PTR [rsi+48], rdx
        mov     QWORD PTR [rsi+56], rax
        ret</code></pre>
</td>
<td  valign="top">
<pre><code class="language-c++"><!--
-->unicorn_loop(unsigned long const*, unsigned long*):
        vmovdqu64       zmm1, ZMMWORD PTR [rdi+8]
        vpaddq  zmm0, zmm1, ZMMWORD PTR [rdi]
        vmovdqu64       ZMMWORD PTR [rsi], zmm0
        vzeroupper
        ret</code></pre>
</td>
</tr>
</table>
<p>On the left, the compiler has tried to be clever by unrolling the loop, so the
8 loop bodies are just listed out explicitly. Each element of <code>next_row</code> is
computed in turn.</p>
<p>On the right, the compiler has managed to replace 8 additions with a single
<code>vpaddd</code> instruction. This is a SIMD (Single instruction, multiple data)
instruction, which is able to perform all of the additions simultaneously. It
uses special vector registers that are 512 bits in length. Each one can hold
8 64-bit integers.</p>
<p>What we've seen here is known as <a href="https://llvm.org/docs/Vectorizers.html">'auto vectorization'</a>.
It's where the compiler is able to detect certain common code patterns, and
replace them with calls to specialised SIMD instructions. Not all code can take
advantage of this superpower, but simple loops that have the 'embarrasingly
parallel' property will often get some benefit.</p>
<p>Now consider a recurrence relation similar to that used by <a href="threads/../solutions/Pixelf.html">Pixelf</a>.
We'll call this one <code>heffalump_trap</code>, for reasons that will become obvious:</p>
<pre><code class="language-c++">void heffalump_trap(int n, uint64_t* next_row) {
  for (int k = 1; k &lt; 9; ++k) {
    next_row[k] = (next_row[k - 1] * (n - k)) / k;
  }
}
</code></pre>
<p>It's not possible to compute the <em>k+1</em>th element without first having computed
the <em>k</em>th element. There is simply no way for the CPU to do any of the work
simultaneously, so you end up with an unrolled loop with no magical SIMD
instructions, even despite the pathetically hopeful use of the <code>-mavx512f</code> flag:</p>
<pre><code class="language-c++">heffalump_trap(int, unsigned long*):
        movabs  r8, -6148914691236517205
        lea     ecx, [rdi-1]
        lea     eax, [rdi-2]
        movsx   rcx, ecx
        imul    rcx, QWORD PTR [rsi]
        movsx   rdx, eax
        lea     eax, [rdi-3]
        imul    rdx, rcx
        mov     QWORD PTR [rsi+8], rcx
        mov     rcx, rdx
        movsx   rdx, eax
        shr     rcx
        imul    rdx, rcx
        mov     QWORD PTR [rsi+16], rcx
        lea     ecx, [rdi-4]
        movsx   rcx, ecx
        mov     rax, rdx
        mul     r8
        lea     eax, [rdi-5]
        shr     rdx
        mov     QWORD PTR [rsi+24], rdx
        imul    rdx, rcx
        mov     rcx, rdx
        movsx   rdx, eax
        shr     rcx, 2
        imul    rdx, rcx
        mov     QWORD PTR [rsi+32], rcx
        movabs  rcx, -3689348814741910323
        mov     rax, rdx
        mul     rcx
        lea     eax, [rdi-6]
        mov     rcx, rdx
        movsx   rdx, eax
        shr     rcx, 2
        imul    rdx, rcx
        mov     QWORD PTR [rsi+40], rcx
        mov     rax, rdx
        mul     r8
        lea     eax, [rdi-7]
        movsx   rcx, eax
        shr     rdx, 2
        imul    rcx, rdx
        mov     QWORD PTR [rsi+48], rdx
        movabs  rdx, 2635249153387078803
        mov     rax, rcx
        mul     rdx
        lea     eax, [rdi-8]
        movsx   rdi, eax
        sub     rcx, rdx
        shr     rcx
        add     rdx, rcx
        shr     rdx, 2
        imul    rdi, rdx
        mov     QWORD PTR [rsi+56], rdx
        shr     rdi, 3
        mov     QWORD PTR [rsi+64], rdi
        ret
</code></pre>
<h2><a class="header" href="#data-dependencies-block-up-the-cpu-pipeline-too" id="data-dependencies-block-up-the-cpu-pipeline-too">Data dependencies block up the CPU pipeline, too!</a></h2>
<p>We can get a wonderfully visceral sense of the problem by using the <a href="https://llvm.org/docs/CommandGuide/llvm-mca.html">llvm-mca</a>
static analysis tool. Essentially it looks at a piece of code and simulates how
your CPU is likely to schedule it in the instruction pipeline. Using the
<code>-timeline</code> flag we can see how long each instruction spends in the pipeline.</p>
<p>Here's the key for the symbols:</p>
<pre><code>    D : Instruction dispatched.
    e : Instruction executing.
    E : Instruction executed.
    R : Instruction retired.
    = : Instruction already dispatched, waiting to be executed.
    - : Instruction executed, waiting to be retired.
</code></pre>
<p>Now here's the non-vectorised version of <code>unicorn_loop</code>:</p>
<pre><code>Timeline view:

                    0123456789          

Index     0123456789          0123456789

[0,0]     DeeeeeER  .    .    .    .       mov	rdx, qword ptr [rdi]
[0,1]     DeeeeeER  .    .    .    .       mov	rax, qword ptr [rdi + 8]
[0,2]     D=====eER .    .    .    .       add	rdx, rax
[0,3]     D=eeeeeeER.    .    .    .       add	rax, qword ptr [rdi + 16]
[0,4]     D=======eER    .    .    .       mov	qword ptr [rsi + 8], rax
[0,5]     .DeeeeeE--R    .    .    .       mov	rax, qword ptr [rdi + 16]
[0,6]     .D=eeeeeeER    .    .    .       add	rax, qword ptr [rdi + 24]
[0,7]     .D=======eER   .    .    .       mov	qword ptr [rsi], rdx
[0,8]     .D========eER  .    .    .       mov	qword ptr [rsi + 16], rax
[0,9]     .D=eeeeeE---R  .    .    .       mov	rax, qword ptr [rdi + 24]
[0,10]    . D=eeeeeeE-R  .    .    .       add	rax, qword ptr [rdi + 32]
[0,11]    . D=eeeeeE--R  .    .    .       mov	rdx, qword ptr [rdi + 48]
[0,12]    . D========eER .    .    .       mov	qword ptr [rsi + 24], rax
[0,13]    . D==eeeeeE--R .    .    .       mov	rax, qword ptr [rdi + 32]
[0,14]    .  D=eeeeeeE-R .    .    .       add	rax, qword ptr [rdi + 40]
[0,15]    .  D========eER.    .    .       mov	qword ptr [rsi + 32], rax
[0,16]    .  D==eeeeeE--R.    .    .       mov	rax, qword ptr [rdi + 40]
[0,17]    .  D==eeeeeeE-R.    .    .       add	rax, qword ptr [rdi + 48]
[0,18]    .   D========eER    .    .       mov	qword ptr [rsi + 40], rax
[0,19]    .   D==eeeeeE--R    .    .       mov	rax, qword ptr [rdi + 56]
[0,20]    .   D=======eE-R    .    .       add	rdx, rax
[0,21]    .   D==eeeeeeE-R    .    .       add	rax, qword ptr [rdi + 64]
[0,22]    .   D=========eER   .    .       mov	qword ptr [rsi + 48], rdx
[0,23]    .    D=========eER  .    .       mov	qword ptr [rsi + 56], rax
</code></pre>
<p>You can see that each of the instructions takes roughly the same amount of time
to work through the instruction pipeline. The data dependencies are very local. If
you look down the columns, you can see by the occurrences of the letter <code>e</code> that
many cycles have multiple instructions executing simultaneously.</p>
<p>Now look at the output for the <code>heffalump_trap</code> function:</p>
<pre><code class="language-Timelineview:">
                    0123456789          0123456789          0123456789          
Index     0123456789          0123456789          0123456789          0123456

[0,0]     DeER .    .    .    .    .    .    .    .    .    .    .    .    .   movabs	r8, -6148914691236517205
[0,1]     DeER .    .    .    .    .    .    .    .    .    .    .    .    .   lea	ecx, [rdi - 1]
[0,2]     DeER .    .    .    .    .    .    .    .    .    .    .    .    .   lea	eax, [rdi - 2]
[0,3]     D=eeeeeeeeER   .    .    .    .    .    .    .    .    .    .    .   imul	rcx, qword ptr [rsi]
[0,4]     D=eE-------R   .    .    .    .    .    .    .    .    .    .    .   lea	eax, [rdi - 3]
[0,5]     .D========eeeER.    .    .    .    .    .    .    .    .    .    .   imul	rdx, rcx
[0,6]     .D========eE--R.    .    .    .    .    .    .    .    .    .    .   mov	qword ptr [rsi + 8], rcx
[0,7]     .D===========eER    .    .    .    .    .    .    .    .    .    .   mov	rcx, rdx
[0,8]     .D============eER   .    .    .    .    .    .    .    .    .    .   shr	rcx
[0,9]     .D=============eeeER.    .    .    .    .    .    .    .    .    .   imul	rdx, rcx
[0,10]    .D=============eE--R.    .    .    .    .    .    .    .    .    .   mov	qword ptr [rsi + 16], rcx
[0,11]    . DeE--------------R.    .    .    .    .    .    .    .    .    .   lea	ecx, [rdi - 4]
[0,12]    . D===============eER    .    .    .    .    .    .    .    .    .   mov	rax, rdx
[0,13]    . D================eeeeER.    .    .    .    .    .    .    .    .   mul	r8
[0,14]    . DeE-------------------R.    .    .    .    .    .    .    .    .   lea	eax, [rdi - 5]
[0,15]    . D====================eER    .    .    .    .    .    .    .    .   shr	rdx
[0,16]    .  D====================eER   .    .    .    .    .    .    .    .   mov	qword ptr [rsi + 24], rdx
[0,17]    .  D====================eeeER .    .    .    .    .    .    .    .   imul	rdx, rcx
[0,18]    .  D=======================eER.    .    .    .    .    .    .    .   mov	rcx, rdx
[0,19]    .  D========================eER    .    .    .    .    .    .    .   shr	rcx, 2
[0,20]    .  D=========================eeeER .    .    .    .    .    .    .   imul	rdx, rcx
[0,21]    .  D=========================eE--R .    .    .    .    .    .    .   mov	qword ptr [rsi + 32], rcx
[0,22]    .   DeE--------------------------R .    .    .    .    .    .    .   movabs	rcx, -3689348814741910323
[0,23]    .   D===========================eER.    .    .    .    .    .    .   mov	rax, rdx
[0,24]    .   D============================eeeeER .    .    .    .    .    .   mul	rcx
[0,25]    .   DeE-------------------------------R .    .    .    .    .    .   lea	eax, [rdi - 6]
[0,26]    .   D================================eER.    .    .    .    .    .   mov	rcx, rdx
[0,27]    .    D================================eER    .    .    .    .    .   shr	rcx, 2
[0,28]    .    D=================================eeeER .    .    .    .    .   imul	rdx, rcx
[0,29]    .    D=================================eE--R .    .    .    .    .   mov	qword ptr [rsi + 40], rcx
[0,30]    .    D====================================eER.    .    .    .    .   mov	rax, rdx
[0,31]    .    D=====================================eeeeER .    .    .    .   mul	r8
[0,32]    .    .DeE---------------------------------------R .    .    .    .   lea	eax, [rdi - 7]
[0,33]    .    .D========================================eER.    .    .    .   shr	rdx, 2
[0,34]    .    .D=========================================eeeER  .    .    .   imul	rcx, rdx
[0,35]    .    .D=========================================eE--R  .    .    .   mov	qword ptr [rsi + 48], rdx
[0,36]    .    .DeE-------------------------------------------R  .    .    .   movabs	rdx, 2635249153387078803
[0,37]    .    .D============================================eER .    .    .   mov	rax, rcx
[0,38]    .    . D============================================eeeeER  .    .   mul	rdx
[0,39]    .    . DeE-----------------------------------------------R  .    .   lea	eax, [rdi - 8]
[0,40]    .    . D================================================eER .    .   sub	rcx, rdx
[0,41]    .    . D=================================================eER.    .   shr	rcx
[0,42]    .    . D==================================================eER    .   add	rdx, rcx
[0,43]    .    .  D==================================================eER   .   shr	rdx, 2
[0,44]    .    .  D===================================================eeeER.   imul	rdi, rdx
[0,45]    .    .  D===================================================eE--R.   mov	qword ptr [rsi + 56], rdx
[0,46]    .    .  D======================================================eER   shr	rdi, 3
[0,47]    .    .  D=======================================================eER  mov	qword ptr [rsi + 64], rdi
</code></pre>
<p>The CPU dispatches lots of instructions in the first few cycles, but because the
inputs to those instructions depend on the results from previous instructions,
they can't do any work until those previous instructions have been executed. The
result is that later instructions have to sit idle in the pipeline until it's
their turn. There are very few cycles that have more than one instruction
actively executing at a time. Bleurgh!</p>
<p>Given the cost of computing elements with the recurrence relation,
<a href="threads/../solutions/Pixelf.html">Pixelf's</a> author made a wise decision to compute only
half of them, then copy those backwards into the other half of the row.</p>
<h2><a class="header" href="#tldr-1" id="tldr-1">TL;DR</a></h2>
<p style="color:red;font-size:30px;">Section not complete</p>
<p><a href="threads/../images/one_does_not_simply.jpg"><img src="threads/../images/one_does_not_simply.jpg" alt="" /></a></p>
<p>Writing multi-threaded code is easy! But writing <em>good</em> multi-threaded code
takes significant effort.</p>
<p>We've just scratched the surface of the complexities that working
effectively with multi-threaded code brings. But for some rough rules of thumb:</p>
<ul>
<li>Don't think about moving to multiple threads until you've exhausted your
optimisation opportunities on a single thread.</li>
<li>Profile!</li>
<li>If you use <code>std::async</code>, make sure you always specify a launch policy, or you
may be disappointed.</li>
<li>Use <code>std::async</code> for one-off concurrent tasks. For repeated tasks, prefer a
worker thread and job queue model. Don't roll your own<sup class="footnote-reference"><a href="#1">1</a></sup>; use a decent
concurrency library.</li>
<li>Just because your task is actively running on another thread doesn't mean it's
making good use of the CPU. Minimising memory allocations and cache misses is
even more important when you're trying to maximise multi-threaded throughput.</li>
<li>The compiler is desperate to make your code faster by emitting fancy SIMD
instructions. It can't do that if your algorithms have complicated data
dependencies. Tools like <a href="https://godbolt.org/">Compiler Explorer</a> really help
for learning what works well.</li>
</ul>
<p>After all this, I think we can come to the conclusion that the Pascal's Triangle
workload is <em>not</em> well-suited to a multi-threaded solution.</p>
<h2><a class="header" href="#related-links" id="related-links">Related links</a></h2>
<ul>
<li><a href="https://www.youtube.com/watch?v=QIHy8pXbneI">code::dive 2016 conference – Sean Parent – Better Code: Concurrency</a></li>
<li><a href="https://accu.org/index.php/journals/2795">Refocusing Amdahl's Law</a> by Lucian Radu Teodorescu</li>
</ul>
<div class="footnote-definition" id="1"><sup class="footnote-definition-label">1</sup>
<p>By all means roll your own for your toy project. But please don't use it
in production code.</p>
</div>
<h1><a class="header" href="#all-your-tests-are-terrible" id="all-your-tests-are-terrible">All your tests are terrible</a></h1>
<p style="color:red;font-size:30px;">Section not complete</p>
<h2><a class="header" href="#submissions-in-this-category-3" id="submissions-in-this-category-3">Submissions in this category</a></h2>
<ul>
<li><a href="./solutions/DigitalGerbil.html">DigitalGerbil</a></li>
<li><a href="./solutions/TerrificPhantom.html">TerrificPhantom</a></li>
</ul>
<h2><a class="header" href="#benchmarks-3" id="benchmarks-3">Benchmarks</a></h2>
<p><em>NOTE: The vertical red line marks the point where integer overflow occurs in the
row values. Generating triangles larger than this is pointless. We're only doing
it to see how the algorithms scale.</em></p>
<p>As before, I'm using a canonical nested-loop algorithm to act as a
<a href="./solutions/Baseline.html">Baseline</a> against which we can compare the other
solutions.</p>
<h4><a class="header" href="#time-to-generate-a-triangle-6" id="time-to-generate-a-triangle-6">Time to generate a triangle</a></h4>
<p><a href="./images/generated/terrible_tests_generate_cpu_bench.svg"><img src="./images/generated/terrible_tests_generate_cpu_bench.svg" alt="" /></a></p>
<h4><a class="header" href="#element-throughput-7" id="element-throughput-7">Element throughput</a></h4>
<p><a href="./images/generated/terrible_tests_generate_throughput_log_scale_bench.svg"><img src="./images/generated/terrible_tests_generate_throughput_log_scale_bench.svg" alt="" /></a></p>
<h2><a class="header" href="#discussion-1" id="discussion-1">Discussion</a></h2>
<p>Some people like to point out that the test cases for a piece of code are
effectively a formal specification for how it should behave.</p>
<p>The <a href="https://github.com/aharrison24/pascals_triangle/blob/master/pascals_triangle_tests.cpp#L47">test cases that I provided for the pascal's triangle problem</a> were not very high
quality. I simply picked cases for 0,1,2,3,4,7,8 and 10 rows and hard-coded the
output.</p>
<p>That's all well and good, but the authors of <a href="./solutions/DigitalGerbil.html">DigitalGerbil</a> and
<a href="./solutions/TerrificPhantom.html">TerrificPhantom</a> exploited the poor tests to provide solutions that passed
<em>only</em> the test cases provided. The solutions do not generalise well.</p>
<h2><a class="header" href="#performance" id="performance">Performance</a></h2>
<p>First thing to note is that despite some reviewers believing that these
hard-coded solutions would be <em>faster</em> than a nested-loop implementation,
neither of them are able to out-perform the baseline. Why?</p>
<p>Because the limiting factor for small triangles is the cost of allocating the
memory for the vectors in the Pascal's Triangle data structure. It doesn't
really matter if you save a few nanoseconds in generating the values if the cost
of allocating the memory is orders of magnitude greater.</p>
<p>So <a href="./solutions/TerrificPhantom.html">TerrificPhantom</a> essentially matches the performance of the raw-loop baseline
solution, which is as we expected. But why does <a href="./solutions/DigitalGerbil.html">DigitalGerbil</a> lag behind so much
when its implementation is so similar?</p>
<p>That's down to the way that <a href="./solutions/DigitalGerbil.html">DigitalGerbil</a> initialises the nested vector data
structures. It's using the wonderfully terse braced initialisation syntax, which
is bringing with it a rather surprising performance hit.</p>
<h3><a class="header" href="#initializer_list-is-not-move-friendly" id="initializer_list-is-not-move-friendly">initializer_list is not move-friendly</a></h3>
<p>When you write:</p>
<pre><code class="language-c++">std::vector&lt;int&gt; v{1,2,3,4,5};
</code></pre>
<p>the compiler is sneakily creating a temporary <a href="https://en.cppreference.com/w/cpp/utility/initializer_list/begin"><code>std::initializer_list&lt;int&gt;</code></a>
data structure with the values <code>{1,2,3,4,5}</code> and then passing <em>that</em> to the
<a href="https://en.cppreference.com/w/cpp/container/vector/vector">constructor</a> of
<code>std::vector</code>.</p>
<p>The de-sugared version works something like this:</p>
<pre><code class="language-c++">std::initializer_list&lt;int&gt; __temp{1,2,3,4,5};
std::vector&lt;int&gt; v{__temp};
</code></pre>
<p>Vector's constructor then copies the contents out of the <code>initializer_list</code> and
into its own storage. Note that I said 'copies' rather than 'moves'. That's
because <code>initializer_list</code> <a href="https://en.cppreference.com/w/cpp/utility/initializer_list/begin">only provides <code>const</code> access to its elements</a>, and you can't move from <code>const</code> objects.</p>
<p>That's not a problem for trivially copyable types like <code>int</code>, because they'd be
copied anyway. But it <em>is</em> a problem for more complex types. Consider this:</p>
<pre><code class="language-c++">// What we type
std::vector&lt;std::vector&lt;int&gt;&gt; nested_vec{{1,2,3}, {4,5,6}};

// What the compiler has to do
std::initializer_list&lt;int&gt; __temp1{1,2,3};
std::initializer_list&lt;int&gt; __temp2{4,5,6};
std::initializer_list&lt;std::vector&lt;int&gt;&gt; __temp3{
  std::vector&lt;int&gt;{__temp1}, std::vector&lt;int&gt;{__temp2}
};
std::vector&lt;std::vector&lt;int&gt;&gt; v{__temp3}; // &lt;-- Copies out of __temp3
</code></pre>
<p>First the compiler has to construct the two inner vectors from
<code>initializer_list&lt;int&gt;</code> types, just as in our previous example. It constructs
those <code>std::vector&lt;int&gt;</code> instances directly into another <code>std::initializer_list&lt;std::vector&gt;</code>.
It then uses <em>that</em> <code>initializer_list</code> to construct the outer <code>vector</code>. But it
can't move the inner vectors from the <code>initializer_list</code>, so it has to <em>copy</em> them
instead. That costs extra memory allocations, and we've already discovered how
expensive those can be.</p>
<p><a href="./solutions/DigitalGerbil.html">DigitalGerbil</a> is hitting this problem head-on and paying the price. It's seeing
an almost 2x performance hit in element throughput for the triangle sizes it
produces.</p>
<h2><a class="header" href="#tldr-2" id="tldr-2">TL;DR</a></h2>
<ul>
<li><a href="https://www.youtube.com/watch?v=sSlmmZMFsXQ"><code>std::initializer_list</code> is a bit broken</a>.
It gives lovely terse initialization syntax, but you might want to avoid
using it for non-trivial initialisation in hot loops.</li>
</ul>
<h2><a class="header" href="#related-links-1" id="related-links-1">Related links</a></h2>
<p><a href="https://www.youtube.com/watch?v=u5senBJUkPc">CppCon 2015: T. Winters &amp; H. Wright “All Your Tests are Terrible...&quot;</a></p>
<h1><a class="header" href="#laziness-is-the-first-step-towards-efficiency" id="laziness-is-the-first-step-towards-efficiency">Laziness is the first step towards efficiency</a></h1>
<p style="color:red;font-size:30px;">Section not complete</p>
<h2><a class="header" href="#submissions-in-this-category-4" id="submissions-in-this-category-4">Submissions in this category</a></h2>
<ul>
<li><a href="./solutions/Porpoison.html">Porpoison</a></li>
</ul>
<h2><a class="header" href="#discussion-2" id="discussion-2">Discussion</a></h2>
<p>Before we continue, I would urge you go and <a href="./solutions/Porpoison.html">have a glance at the code for Porpoison</a>.</p>
<p>Did you like what you saw? No? Didn't think so. Neither did any of the reviewers.
They all thought it was horrible.</p>
<p>So why have I devoted a whole section to this overcomplicated mess of a solution?
Well, because it has some remarkable properties. And remark upon them we shall.</p>
<p>The most noteworthy property of <a href="./solutions/Porpoison.html">Porpoison</a> is that
the <code>generate_rows</code> function does virtually no work, other than instantiating a
few classes. All the work of computing element values is deferred until the
caller actually tries to iterate over them.</p>
<p>For that reason, the way we've been plotting benchmarks up until this point is
no longer valid, because <code>generate_rows</code> takes the same amount of time to execute
<em>no matter how many rows are requested</em>. So from this point onwards, the
benchmarks are changing to include both calling <code>generate_rows</code> <em>and</em> looping
once over all of the elements in the triangle, to ensure that the code computing
row elements gets exercised by the benchmarks.</p>
<p>Yes, it's unfair because real-world uses might well need to iterate over the
triangle multiple times, which would potentially make lazy solutions less
viable. But I'm in charge here, and I choose to benchmark only a single iteration.</p>
<h2><a class="header" href="#benchmarks-4" id="benchmarks-4">Benchmarks</a></h2>
<p><em>The vertical red line marks the point where integer overflow occurs in the
row values. Generating triangles larger than this is pointless. We're only doing
it to see how the algorithms scale.</em></p>
<h4><a class="header" href="#time-to-generate-a-triangle-7" id="time-to-generate-a-triangle-7">Time to generate a triangle</a></h4>
<p><a href="images/generated/laziness_total_cpu_bench.svg"><img src="images/generated/laziness_total_cpu_bench.svg" alt="" /></a></p>
<h4><a class="header" href="#element-throughput-8" id="element-throughput-8">Element throughput</a></h4>
<p><a href="images/generated/laziness_total_throughput_log_scale_bench.svg"><img src="images/generated/laziness_total_throughput_log_scale_bench.svg" alt="" /></a></p>
<h2><a class="header" href="#avoiding-memory-allocation-for-fun-and-profit" id="avoiding-memory-allocation-for-fun-and-profit">Avoiding memory allocation for fun and profit</a></h2>
<p>Back in the <a href="loops/be_kind_to_your_cache.html">chapter about raw loops</a>, we saw
how performance took a nose-dive when the data structure holding pascal's
triangle spilled out of the cache. Looking at the <a href="images/generated/laziness_total_throughput_log_scale_bench.svg">throughput benchmark graph</a>
for <a href="./solutions/Porpoison.html">Porpoison</a> there is no characteristic performance
plunge. In fact the throughput remains remarkably stable as the triangle size
grows.</p>
<p>To get an insight into this, let's look at <a href="./solutions/Porpoison.html">Porpoison's</a>
memory usage as the triangle grows in size:</p>
<h4><a class="header" href="#memory-usage" id="memory-usage">Memory usage</a></h4>
<p><a href="images/laziness_memory_usage.svg"><img src="images/laziness_memory_usage.svg" alt="" /></a></p>
<p>While the raw-loop based <a href="solutions/Baseline.html">Baseline's</a> memory usage
soars quadratically into the stratosphere, <a href="./solutions/Porpoison.html">Porpoison</a>
allocates no memory. By 20,000 rows, <a href="solutions/Baseline.html">Baseline</a> is
allocating 1.6Gb of memory. At 65,536 rows it has allocated an hilarious 16Gb of
memory. But <a href="./solutions/Porpoison.html">Porpoison</a> is still sat stubbornly (and
somewhat smugly) at 0 bytes.</p>
<p>The more impatient amongst you will no doubt be frantically gesticulating at your
screens and pointing out that the raw-loop solution is still quite a bit faster
for many triangle sizes. Don't worry, soon we'll look at some solutions that 
leave all of them in the dust. But <a href="./solutions/Porpoison.html">Porpoison</a> still
has some interesting things to show us.</p>
<h2><a class="header" href="#a-win-for-the-sneaky-types" id="a-win-for-the-sneaky-types">A win for the sneaky types</a></h2>
<p>The original problem statement for the Pascal's Triangle challenge had this
function signature:</p>
<pre><code class="language-c++">auto generate_rows(uint32_t num_rows) -&gt; std::vector&lt;std::vector&lt;uint64_t&gt;&gt;;
</code></pre>
<p>That nested vector return type is a treacle-covered straitjacket of a performance
killer. If you commit to returning a nested vector type then you are <em>forced</em> to
allocate enough memory to hold the whole triangle, and you are <em>forced</em> to
eagerly compute all of the elements up-front.</p>
<p>Some solution authors realised that you don't actually need to return a nested
vector to pass the unit tests. You 'just' need to return a type which can be
iterated over using a loop like this:</p>
<pre><code class="language-c++">auto triangle = generate_rows(num_rows);

for (auto&amp;&amp; row : triangle) {
  for (auto elem : row) {
    ...
  }
}
</code></pre>
<p>In practice, that means you need to return a type that has <code>begin()</code> and <code>end()</code>
methods that allow the caller to iterate over the row sequence.</p>
<h2><a class="header" href="#iterators-ate-my-hamster" id="iterators-ate-my-hamster">Iterators ate my hamster</a></h2>
<p>In C++, iterators are something we use whenever we interact with STL containers
such as <code>std::vector</code>, <code>std::array</code>, <code>std::map</code> etc... We <em>use</em> them extremely
often, but it's rare that we need to implement our own. That's part of the magic
of Stepanov's design of the STL -- much of the complexity is abstracted away so
that consumers of the library can just loop over a collection without needing to
know <em>how</em> the traversal is implemented.</p>
<p>It's unfortunate that implementing a conformant C++ iterator is actually a
non-trivial affair. To make the simplest 'input' iterator (i.e. one that allows
a caller to retrieve read-only values from a container or stream) requires
at a minimum the creation of a type with <a href="https://en.cppreference.com/w/cpp/named_req/InputIterator">5 type aliases and 6 operators</a>. And it's not easy to check you got it right.</p>
<p><a href="./solutions/Porpoison.html">Porpoison</a> actually needs something a bit more
complicated: an iterator over iterators. The first one iterates over rows, and
the second over the elements in a row.</p>
<p>I'm not going to say much about the specific iterator implementation in
<a href="./solutions/Porpoison.html">Porpoison</a>, other than that it is sadly about as
minimal as you can get if you're going to roll your own. It's worth noting that
the <a href="https://ericniebler.github.io/range-v3/index.html">range-v3</a>
library provides an abstraction called 'cursors' which greatly ease the burden
of writing STL-conformant iterators. That's outside the scope of this writeup
though.</p>
<h2><a class="header" href="#the-hamster-wasnt-tasty-but-the-codegen-was-new-title-pls" id="the-hamster-wasnt-tasty-but-the-codegen-was-new-title-pls">The hamster wasn't tasty, but the codegen was (new title pls)</a></h2>
<p>To a human, <a href="./solutions/Porpoison.html">Porpoison's</a> implementation may be a mess,
but the compiler can see right through it, because most of it just gets inlined
away.</p>
<p>Using <a href="https://godbolt.org">Compiler Explorer</a> we can inspect the
machine code that <a href="./solutions/Porpoison.html">Porpoison</a> compiles to. We'll use a
test function that sums up all the elements in a 9-row triangle:</p>
<pre><code class="language-c++">int sum_up_elements() {
  auto result = porpoison::generate_rows(9);
  uint64_t sum = 0;

  for (auto&amp;&amp; row : result) {
    for (auto elem : row) {
      sum += elem;
    }
  }

  return sum;
}
</code></pre>
<p>You can see the full example in Compiler Explorer at
<a href="https://godbolt.org/z/xn9Pah">https://godbolt.org/z/xn9Pah</a></p>
<p>Remarkably, the whole 200+ line program compiles down to just 3 lines:</p>
<pre><code class="language-c++">sum_up_elements(): # @sum_up_elements()
        mov     eax, 511
        ret
</code></pre>
<p>The compiler has seen right through the implementation, generated a 9-row
pascal's triangle, and summed up its elements <em>all at compile time</em>. It has then
just dumped the result 511 into the body of the function.</p>
<p>It is hard to imagine a faster computer program than that.</p>
<h2><a class="header" href="#lies-damned-lies-and-carefully-chosen-example-cases" id="lies-damned-lies-and-carefully-chosen-example-cases">Lies, damned lies and carefully chosen example cases</a></h2>
<p>OK, that last example was a flashy magic trick. And... I conveniently forgot to mention
that everything falls apart when there are more than 9 rows.</p>
<p>When the number of rows to sum up is not known at run-time,
<a href="./solutions/Porpoison.html">Porpoison</a> generates 89 lines of assembly:
<a href="">https://godbolt.org/z/Pz8K5a</a></p>
<p>In comparison, the eager raw-loop <a href="./solutions/Baseline.html">Baseline</a> generates
451 lines of assembly to do the same thing:
<a href="">https://godbolt.org/z/hxY183</a></p>
<p>Functions that compile down to fewer instructions are friendlier to the
instruction cache. We already know that <a href="./solutions/Porpoison.html">Porpoison</a>
<em>doesn't allocate any heap memory at all</em>, so it's friendly to the CPU cache too.
How affable.</p>
<h2><a class="header" href="#why-does-it-not-outperform-the-raw-loop-solutions" id="why-does-it-not-outperform-the-raw-loop-solutions">Why does it not outperform the raw-loop solutions?</a></h2>
<p>Because <a href="./solutions/Porpoison.html">Porpoison</a> is as lazy as possible, it computes
elements only when they are requested. That <em>may</em> preclude the use of SIMD
instructions<sup class="footnote-reference"><a href="#1">1</a></sup> which by definition would need to compute multiple values at a
time. It would be easy to keep a small static buffer around and compute new values
in batches, but there's actually another more serious problem.</p>
<p><a href="./solutions/Porpoison.html">Porpoison</a> computes elements using the same
recurrence relation that we saw in the <a href="./threads/cleverness.html">discussion about why Pixelf is slow</a>.
Data dependencies prevent the compiler from using SIMD instructions or
benefitting from instruction pipeline efficiencies, so throughput is limited by the cost
of doing serial arithmetic operations. To avoid that, <a href="./solutions/Porpoison.html">Porpoison</a>
would need to cache a copy of the previous row somewhere, so that elements of
the new row only have data dependencies on the previous row. Totally doable, but
I think the implementation is quite complicated enough already.</p>
<p>The performance of <a href="./solutions/Porpoison.html">Porpoison</a> is at least highly
predictable, with throughput remaining more-or-less constant for any size of
pascal's triangle. Sometimes predictability is more important than peak
throughput, especially in safety-critical / real-time settings.</p>
<h2><a class="header" href="#can-we-get-laziness-without-writing-custom-iterators" id="can-we-get-laziness-without-writing-custom-iterators">Can we get laziness without writing custom iterators?</a></h2>
<p>The good news is that yes, we can. This is exactly what the 'view adaptors' in
the <a href="https://ericniebler.github.io/range-v3/index.html">range-v3</a> library can do
for us (and they're coming in C++20 too). They offer an extremely expressive way to create lazy iterators with a minimum of boilerplate. We'll talk about that in the
<a href="./ranges.html">next section</a>.</p>
<h2><a class="header" href="#summary" id="summary">Summary</a></h2>
<ul>
<li>Lazy solutions have the potential for vastly lower heap memory consumption
than eager solutions.</li>
<li>The only way to create lazy solutions that interact well with range-for loops
and the STL is to implement custom iterators.</li>
<li>Writing (correct) custom iterators is ugly and hard. Your colleagues may not
thank you.</li>
<li>Too much laziness may prevent the compiler from generating good assembly. You
might need to introduce limited eagerness or caching.</li>
<li>Much of the complexity of custom iterators can be hidden by using
<a href="./ranges.html">view adaptors</a>.</li>
</ul>
<div class="footnote-definition" id="1"><sup class="footnote-definition-label">1</sup>
<p>Depending on if and how the implementation gets inlined by the compiler.</p>
</div>
<h1><a class="header" href="#a-range-of-techniques-to-vex-your-compiler" id="a-range-of-techniques-to-vex-your-compiler">A Range of techniques to vex your compiler</a></h1>
<p style="color:red;font-size:30px;">Section not complete</p>
<h2><a class="header" href="#submissions-in-this-category-5" id="submissions-in-this-category-5">Submissions in this category</a></h2>
<ul>
<li><a href="./solutions/ArchBanana.html">ArchBanana</a></li>
<li><a href="./solutions/Proteus.html">Proteus</a></li>
<li><a href="./solutions/EvilDoughnut.html">EvilDoughnut</a></li>
</ul>
<h4><a class="header" href="#created-by-arh-2" id="created-by-arh-2">Created by arh</a></h4>
<ul>
<li><a href="./solutions/ArchBanana2_arh.html">ArchBanana2_arh</a> An improved version of
<a href="./solutions/ArchBanana.html">ArchBanana</a> that minimizes memory allocations.</li>
</ul>
<h2><a class="header" href="#benchmarks-5" id="benchmarks-5">Benchmarks</a></h2>
<p><em>NOTE: The vertical red line marks the point where integer overflow occurs in the
row values. Generating triangles larger than this is pointless. We're only doing
it to see how the algorithms scale.</em></p>
<p>The vertical blue line marks the point where the triangle has 5000 rows.</p>
<h4><a class="header" href="#time-to-generate-a-triangle-8" id="time-to-generate-a-triangle-8">Time to generate a triangle</a></h4>
<p><a href="./images/generated/ranges_total_cpu_bench.svg"><img src="./images/generated/ranges_total_cpu_bench.svg" alt="" /></a></p>
<h4><a class="header" href="#element-throughput-9" id="element-throughput-9">Element throughput</a></h4>
<p><a href="./images/generated/ranges_total_throughput_log_scale_bench.svg"><img src="./images/generated/ranges_total_throughput_log_scale_bench.svg" alt="" /></a>
<a href="./images/generated/ranges_total_throughput_linear_scale_bench.svg"><img src="./images/generated/ranges_total_throughput_linear_scale_bench.svg" alt="" /></a></p>
<h4><a class="header" href="#memory-usage-1" id="memory-usage-1">Memory usage</a></h4>
<p><a href="images/ranges_memory_usage.svg"><img src="images/ranges_memory_usage.svg" alt="" /></a></p>
<h2><a class="header" href="#further-references-1" id="further-references-1">Further references</a></h2>
<ul>
<li><a href="https://pragprog.com/book/tpp20/the-pragmatic-programmer-20th-anniversary-edition">The Pragmatic Programmer</a> is a book full of programming gems. It has a section entitled
&quot;Transforming Programming&quot; that urges us to view our programs as being a series
of transformations on data, rather than as a series of imperative operations.
They argue that it takes a while to get used to, but leads to cleaner code,
shorter functions and flatter designs. STL algorithms </li>
</ul>
<h1><a class="header" href="#have-your-constexpr-cake-and-eat-it" id="have-your-constexpr-cake-and-eat-it">Have your constexpr cake and eat it</a></h1>
<p style="color:red;font-size:30px;">Section not complete</p>
<ul>
<li>
<p><a href="./solutions/Erwin.html">Erwin</a></p>
</li>
<li>
<p><a href="./solutions/FireFly.html">FireFly</a></p>
</li>
<li>
<p><a href="./solutions/LightningHippo_arh.html">LightningHippo_arh</a></p>
</li>
<li>
<p>Benchmarks are very fragile/unstable for these solutions. Slightest changes can wallop perf.</p>
<ul>
<li>Switching from subrange to span</li>
<li>Changing size of row counter type. uint64_t -&gt; uint32_t</li>
<li>Moving generate_rows into cpp file prevents inlining, which has a substantial
impact at these row sizes.</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#computing-the-lookup-table-at-compile-time" id="computing-the-lookup-table-at-compile-time">Computing the lookup table at compile time</a></h2>
<p>https://godbolt.org/z/9ZRkx7</p>
<h1><a class="header" href="#the-optimizer-is-magic" id="the-optimizer-is-magic">The optimizer is magic</a></h1>
<p style="color:red;font-size:30px;">Section not complete</p>
<h1><a class="header" href="#a-surprise-win-for-property-based-testing" id="a-surprise-win-for-property-based-testing">A surprise win for property based testing</a></h1>
<p style="color:red;font-size:30px;">Section not complete</p>
<h2><a class="header" href="#can-we-write-better-tests" id="can-we-write-better-tests">Can we write better tests?</a></h2>
<p>Writing good tests for Pascal's Triangle seems pretty tricky at first sight. If
we want to avoid hard-coding results then don't we effectively need to
reimplement the algorithm that we're trying to test?</p>
<p>I decided to investigate how property-based testing could help out. And in the
process I discovered a bona-fide bug in one of the submissions.</p>
<h3><a class="header" href="#how-can-property-based-testing-help-us-to-do-better" id="how-can-property-based-testing-help-us-to-do-better">How can property-based testing help us to do better?</a></h3>
<p>Fortunately, Pascal's Triangle has many beautiful mathematical properties that
might be able to help us. Here are just a few (assuming a zero-based row index):</p>
<ul>
<li>Row n of the triangle should contain n+1 elements</li>
<li>Every row is symmetrical</li>
<li>The gradient of the values in each row is strictly decreasing</li>
<li>The sum of all the elements in row n is 2^n</li>
<li>The second and penultimate elements of row n (for n&gt;1) are equal to n</li>
</ul>
<p>Properties such as these are easy to code and can be used to check the validity
of a triangle of <em>any</em> size. The properties I've listed do not guarantee the
correctness of pascal's triangle, but they do act as a check that can quickly
detect certain errors.</p>
<p>In addition to the existing hard-coded tests, what we'd really like to do is
have the test suite generate triangles of random sizes and then check that they
satisfy a series of simple properties.</p>
<p>It's normally deeply frowned-upon to use random data in unit tests. The
principal issue is the lack of repeatability, which leads to the deadly sin
of flaky tests. These are tests that fail only <em>some of the time</em>, which makes
them a nightmare to debug. Unit tests are supposed to run quickly, so it's also
important to put reasonable bounds on the number of random tests that you run.</p>
<p>That's where property-based testing frameworks come in. They give us a rigorous
framework for supplying random inputs to test cases, and strive to make failing
test cases be repeatable.</p>
<h3><a class="header" href="#how-can-we-do-property-based-testing-in-practice" id="how-can-we-do-property-based-testing-in-practice">How can we do property based testing in practice?</a></h3>
<p>Functional programming languages like Haskell have been doing property based
testing for a long time, with the <a href="https://hackage.haskell.org/package/QuickCheck">QuickCheck</a>
library being the most well known.</p>
<p>Functional programming ideas are gradually making their way into more
mainstream languages and Python's <a href="https://hypothesis.readthedocs.io/en/latest/quickstart.html">Hypothesis</a> library is generally regarded as the best-in-class framework for property based
testing in any language.</p>
<p>When you run your test suite, the Hypothesis library will generate a number of
random inputs for each of your test cases (~100 normally). In the case of
pascal's triangle the random input might control the number of rows in the
triangle. For more complex examples the random inputs could be multi-byte strings or whole
classes.</p>
<p>When a test fails, Hypothesis will try to shrink the inputs down to the smallest
possible case that still triggers the error. It will then cache the failing
input in a local database and make sure that all future invocations of the test
suite get given the problematic input. Effectively it acts as an automatically
generated regression test. I wish I had space to say more about this,
because it is a transformative capability.</p>
<p>The C++ community has traditionally been more resistant to the arrival of
functional paradigms, but there have been some recent attempts to bring the
ideas of property-based testing to the language. One example is the
<a href="https://github.com/emil-e/rapidcheck">RapidCheck</a> framework, that came out of
Spotify.</p>
<p>I decided to try using Rapidcheck to write some tests for Pascal's Triangle. </p>
<h2><a class="header" href="#generating-random-triangles" id="generating-random-triangles">Generating random triangles</a></h2>
<p>I began with a helper function to generate random triangles:</p>
<pre><code class="language-c++">auto generate_random_triangle() {
  // Generate a random number between 1 and 64
  auto const num_rows = *rc::gen::inRange(1U, max_rows);
  
  // Use it to build a pascal's triangle
  return std::pair(num_rows, SOLUTION_NAMESPACE::generate_rows(num_rows));
};
</code></pre>
<p>Rapidcheck offers a series of <a href="https://github.com/emil-e/rapidcheck/blob/master/doc/generators.md">generator functions</a> for producing random data of various types (including vectors and
strings). <code>generate_random_triangle</code> uses <code>rc::gen::inRange</code> to generate
uniformly distributed integers.</p>
<h2><a class="header" href="#writing-the-property-based-tests" id="writing-the-property-based-tests">Writing the property-based tests</a></h2>
<p>I chose to implement the first three properties:</p>
<ul>
<li>Row n of the triangle should contain n+1 elements</li>
<li>Every row is symmetrical</li>
<li>The gradient of the values in each row is strictly decreasing</li>
</ul>
<p>For simplicity, rather than checking the gradients along every row (which would
require subtraction of unsigned values; a recipe for extreme sadness), I opted
instead to make sure that the first half of every row was sorted in ascending
order. It's a weaker property, but easier to write an obviously-correct
implementation.</p>
<p>Each property test is implemented as a lambda function wrapped in a call to
the <code>rc::prop</code> function. Since each test needs to be called multiple times by
Rapidcheck, we can't use the usual Doctest <code>REQUIRE</code> assertion macro. Instead we
use the <code>RC_ASSERT</code> macro provided by Rapidcheck that only prints output once
test-case shrinking has occurred.</p>
<pre><code class="language-c++">TEST_CASE(&quot;Property based tests&quot;) {

  rc::prop(&quot;The nth row has n+1 elements&quot;, [] {
    // GIVEN: A triangle of size num_rows
    auto const [num_rows, triangle] = generate_random_triangle();

    // WHEN: We take the length of every row
    auto const row_lengths = triangle | rv::transform(ranges::size);

    // THEN: Then the row lengths form the sequence [1..num_rows]
    auto const expected_row_lengths =
        rv::closed_iota(1UL, std::size_t(num_rows));

    RC_ASSERT(ranges::to_vector(row_lengths) ==
              ranges::to_vector(expected_row_lengths));
  });

  rc::prop(&quot;Every row is symmetrical&quot;, [] {
    // GIVEN: A triangle of size num_rows
    auto const [num_rows, triangle] = generate_random_triangle();

    // WHEN: Every row is reversed
    auto const triangle_with_reversed_rows =
        triangle | rv::transform(rv::reverse);

    // THEN: The triangle remains unchanged
    RC_ASSERT(to_vec_of_vec(triangle_with_reversed_rows) == triangle);
  });

  rc::prop(
      &quot;First half of every row has values sorted in strictly ascending order&quot;,
      [] {
        // GIVEN: A triangle of size num_rows
        auto const [num_rows, triangle] = generate_random_triangle();

        // THEN: for every row...
        for (uint32_t i = 0; i &lt; num_rows; ++i) {
          auto const&amp; row = triangle[i];
          auto first_half = row | rv::take((row.size() + 1) / 2);

          // ... the first half of the row is sorted in ascending order
          if (!pt::is_strictly_ascending(first_half)) {
            std::string const not_strictly_sorted_msg = fmt::format(
                &quot;Row index: {}. First half of row is not sorted in strictly &quot;
                &quot;ascending order:\n{}&quot;,
                i, print_vec(ranges::to_vector(first_half)));
            RC_FAIL(not_strictly_sorted_msg);
          }
        }
      });
}
</code></pre>
<h2><a class="header" href="#heres-what-happened-next" id="heres-what-happened-next">Here's what happened next...</a></h2>
<p>Having written these three simple property tests I ran them on all of the
solutions, expecting everything to pass. And straight away it went <strong>Kaboom</strong>:</p>
<pre><code class="language-markdown">[doctest] doctest version is &quot;2.3.7&quot;
[doctest] run with &quot;--help&quot; for options
Using configuration: seed=4206418198193332509
===============================================================================
tests/ArchBanana_property_tests.cpp:62:
TEST SUITE: ArchBanana
TEST CASE:  Property based tests
  First half of every row has values sorted in strictly ascending order

/Users/arh/code/personal/pascals_triangle/src/external/rapidcheck_doctest/include/rapidcheck/rapidcheck_for_doctest.h:39: FATAL ERROR: Falsifiable after 60 tests and 1 shrink

unsigned int:
36

tests/ArchBanana_property_tests.cpp:108:
RC_FAIL(not_strictly_sorted_msg)

Row index: 35. First half of row is not sorted in strictly ascending order:
{1, 35, 595, 6545, 52360, 324632, 1623160, 6724520, 23535820, 70607460, 183579396, 417225900, 834451800, 1476337800, 18446744071734543720, 18446744072662527480, 18446744073474513270, 242600354}


===============================================================================
[doctest] test cases:    279 |    278 passed |      1 failed |      0 skipped
[doctest] assertions:    249 |    248 passed |      1 failed |
[doctest] Status: FAILURE!
</code></pre>
<h3><a class="header" href="#nice-things-that-rapidcheck-does-for-us" id="nice-things-that-rapidcheck-does-for-us">Nice things that RapidCheck does for us</a></h3>
<p>First thing to note is the line that says:</p>
<pre><code class="language-markdown">Using configuration: seed=4206418198193332509
</code></pre>
<p>By setting the <code>RC_PARAMS</code> environment variable to <code>seed=4206418198193332509</code>,
and re-running the test suite we can exactly reproduce the failing test run.
That's one massive advantage of using a good property-based testing framework.</p>
<p>The second thing to note is the line that says <code>FATAL ERROR: Falsifiable after 60 tests and 1 shrink</code>. Once RapidCheck had found a failing case, it then went
about finding the smallest number of rows in the triangle that would reproduce
the failure. For pascal's triangle, that's not so important, but it's enormously
helpful in more complex situations. But at least we know that row 36 was the
first row that exhibited the problem.</p>
<h3><a class="header" href="#so-what-happened" id="so-what-happened">So what happened?</a></h3>
<p>Taking a look at the test output, we can see that the failure occurred on the
36th row of a triangle generated by the <a href="./solutions/ArchBanana.html">ArchBanana</a>
solution. The values increase as expected, and then suddenly blow up. This looks
very much like an integer overflow problem.</p>
<p>I tracked it down to the implementation of this function, which sums the
values in a range (where a 'range' is some iterable object).</p>
<pre><code class="language-c++">static auto sum = [](auto&amp;&amp; range) { return ranges::accumulate(range, 0); };
</code></pre>
<p>Can you see the bug?</p>
<p>No? How about if I show you what the line should have read<sup class="footnote-reference"><a href="#1">1</a></sup>:</p>
<pre><code class="language-c++">static auto sum = [](auto&amp;&amp; range) { return ranges::accumulate(range, uint64_t(0)); };
</code></pre>
<p>Without the cast, the compiler is selecting a 32-bit signed integer as the
accumulation variable. It's overflowing when trying to sum all the values on the
36th row of pascal's triangle, and flipping to a negative number. That's
'undefined behaviour' and subject to the usual nasal demons. Later on, the
negative 32-bit integer returned by the <code>sum</code> function is implicitly converted
into an unsigned 64-bit integer, which results in a Very Big Number™ appearing in
our triangle row.</p>
<h3><a class="header" href="#thats-a-win-in-my-book" id="thats-a-win-in-my-book">That's a win in my book</a></h3>
<p>The author of <a href="./solutions/ArchBanana.html">ArchBanana</a> didn't spot this problem.
None of the <strong>five</strong> people who reviewed the submission spotted the problem.
Unit-testing of a few carefully chosen cases didn't spot the problem. But
property-based testing found it in 100ms. That's food for thought.</p>
<h3><a class="header" href="#and-thats-not-all" id="and-thats-not-all">And that's not all</a></h3>
<p>Later on, when I was refactoring the <a href="./solutions/LightningHippo_arh.html">LightningHippo_arh</a>
solution, the property-based tests picked up an off-by-one error that only
manifested for triangles of a particular size. Writing explicit unit tests to
catch that wouldn't have been feasible.</p>
<h2><a class="header" href="#tldr-3" id="tldr-3">TL;DR</a></h2>
<ul>
<li>If your test suite allows for implementations that don't generalise well then
consider what more general properties you can be testing for.</li>
<li>A good property-based testing framework can change the way you think about
tests.</li>
<li>Property-based tests often surprise you.</li>
</ul>
<div class="footnote-definition" id="1"><sup class="footnote-definition-label">1</sup>
<p>Yes, to be truly generic we should use <code>ranges::range_value_t&lt;decltype(range)&gt;(0)</code>,
but that doesn't really sell the &quot;ranges lead to readable declarative code&quot; message
that we Koolaid drinkers would have you all believe.</p>
</div>
<h2><a class="header" href="#how-to-get-a-free-50-speed-boost-randomly" id="how-to-get-a-free-50-speed-boost-randomly">How to get a free 50% speed boost. Randomly.</a></h2>
<p style="color:red;font-size:30px;">Section not complete</p>
<p>While working on the benchmarks, I became aware of a
<a href="https://www.intel.com/content/dam/support/us/en/documents/processors/mitigations-jump-conditional-code-erratum.pdf">bug in recent Intel chips</a><sup class="footnote-reference"><a href="#1">1</a></sup>
that occurs when jump instructions in the assembly cross instruction cache
boundaries. The devastatingly exciting effect of this is that completely
irrelevant code changes can alter the instruction alignment of your benchmark
loop and totally hose its performance. That was a week of my life that I'll
never get back.</p>
<p>Very recent compilers have flags to align jump instructions to cache lines and
hopefully mitigate the problem to some degree. As such, all of the benchmarks
published here are built with Clang's <code>-mbranches-within-32B-boundaries</code> flag.
With that applied, I saw 30-40% speed boosts to <em>some</em> of the algorithms tested
here, in <em>some</em> circumstances. Did I mention that you should never trust
benchmarks?</p>
<p>https://easyperf.net/blog/2018/01/18/Code_alignment_issues</p>
<p>give a code example (diff without much context) where everything changed unexpectedly.</p>
<p>could later give an example where prompt changes everything</p>
<h2><a class="header" href="#issues-with-benchmarks" id="issues-with-benchmarks">Issues with benchmarks</a></h2>
<ul>
<li>It's hard to prevent the compiler from optimising away large parts of
your algorithm if you're not <strong>very</strong> careful.</li>
<li>The techniques employed to stop the compiler optimising away parts of the
algorithm will have an impact on the performance of the algorithm.</li>
<li>Micro-benchmarks are often run thousands of times, so the CPU caches are
(almost) always hot.</li>
<li>It doesn't matter how fast your algorithm goes if the consumer of the
results is doing orders of magnitude more work with the results that come out
of it. Optimisation efforts should be focused on the parts of a codebase that
are taking the most time.</li>
<li>Benchmarks are usually run on an otherwise idling machine, with access to all
of the machine's resources. Real life applications may need to run the
algorithm with greatly constrained resources, because other processes will
be running concurrently.</li>
<li>When working with very tight loops, code alignment issues can cause
performance fluctuations that will utterly dwarf any improvements you can
make by 'traditional' techniques. This was a big surprise to me, so I've
<a href="./code_alignment_issues.html">written about it separately</a>.</li>
</ul>
<div class="footnote-definition" id="1"><sup class="footnote-definition-label">1</sup>
<p>Thanks to Arnaud Desitter for telling me about this, right when I was
trying to work out why my benchmark results were fluctuating so much.</p>
</div>
<h1><a class="header" href="#conclusion" id="conclusion">Conclusion</a></h1>
<p style="color:red;font-size:30px;">Section not complete</p>
<ul>
<li>
<p>What is the domain of your function?</p>
</li>
<li>
<p>What are the typical use cases?</p>
</li>
<li>
<p>Does it get called in a hot loop?</p>
</li>
<li>
<p>Is it worth speeding up?</p>
</li>
<li>
<p>Equally, are you inadvertently pessimizing?</p>
</li>
<li>
<p>Measure / profile for those use cases</p>
</li>
<li>
<p>Ranges is coming in C++20. Jury is still out on compile times until we have
first-class support for concepts. But we should stay abreast of what capabilities
these approaches offers us.</p>
</li>
<li>
<p>Robert Martin - &quot;The ultimate goal of code is to be boring, not interesting.&quot;</p>
</li>
</ul>
<p>(Put the big smiley face table in an appendix)</p>
<style type="text/css">
.tg  {border-collapse:collapse;border-color:#9ABAD9;border-spacing:0;}
.tg td{background-color:#EBF5FF;border-color:#9ABAD9;border-style:solid;border-width:1px;color:#444;
  font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{background-color:#409cff;border-color:#9ABAD9;border-style:solid;border-width:1px;color:#fff;
  font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg img{width: 40px;}
.tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:center}
.tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}
.tg .tg-subhead{border-color:inherit;text-align:center;font-weight: bold;background-color:#EBF5FF;column-span:5;color:#444}
</style>
<table class="tg">
<tbody>
  <tr>
    <th class="tg-0pky">Name</th>
    <th class="tg-0pky">Run time</th>
    <th class="tg-0pky">Memory allocation</th>
    <th class="tg-0pky">Maintainability</th>
    <th class="tg-0pky">Compile Time</th>
  </tr>
  <tr>
    <th class="tg-subhead" colspan="5">Raw loops</th>
  </tr>
  <tr>
    <td class="tg-0pky"><a href="solutions/Baseline.html">Baseline</a></td>
    <td class="tg-c3ow"><img src="images/amber_face.png"></td>
    <td class="tg-c3ow"><img src="images/red_face.png"></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
  </tr>
  <tr>
    <td class="tg-0pky"><a href="solutions/AskingCrow.html">AskingCrow</a></td>
    <td class="tg-c3ow"><img src="images/amber_face.png"></td>
    <td class="tg-c3ow"><img src="images/red_face.png"></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
  </tr>
  <tr>
    <td class="tg-0pky"><a href="solutions/BumbleBeetle.html">BumbleBeetle</a></td>
    <td class="tg-c3ow"><img src="images/amber_face.png"></td>
    <td class="tg-c3ow"><img src="images/red_face.png"></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
  </tr>
  <tr>
    <td class="tg-0pky"><a href="solutions/CluelessWolverine.html">CluelessWolverine</a></td>
    <td class="tg-c3ow"><img src="images/amber_face.png"></td>
    <td class="tg-c3ow"><img src="images/red_face.png"></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
  </tr>
  <tr>
    <td class="tg-0pky"><a href="solutions/CluelessWolverine2.html">CluelessWolverine2</a></td>
    <td class="tg-c3ow"><img src="images/amber_face.png"></td>
    <td class="tg-c3ow"><img src="images/red_face.png"></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
  </tr>
  <tr>
    <td class="tg-0pky"><a href="solutions/Fortran4Ever.html">Fortran4Ever</a></td>
    <td class="tg-c3ow"><img src="images/amber_face.png"></td>
    <td class="tg-c3ow"><img src="images/red_face.png"></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
  </tr>
  <tr>
    <td class="tg-0pky"><a href="solutions/simple_basic_solution.html">simple_basic_solution</a></td>
    <td class="tg-c3ow"><img src="images/amber_face.png"></td>
    <td class="tg-c3ow"><img src="images/red_face.png"></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
  </tr>
  <tr>
    <td class="tg-0pky"><a href="solutions/user_usery.html">user_usery</a></td>
    <td class="tg-c3ow"><img src="images/amber_face.png"></td>
    <td class="tg-c3ow"><img src="images/red_face.png"></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
  </tr>
  <tr>
    <td class="tg-0pky"><a href="solutions/FlyingDesitter_arh.html">FlyingDesitter_arh</a></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
    <td class="tg-c3ow"><img src="images/red_face.png"></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
  </tr>
  <tr>
    <th class="tg-0pky">Name</th>
    <th class="tg-0pky">Run time</th>
    <th class="tg-0pky">Memory allocation</th>
    <th class="tg-0pky">Maintainability</th>
    <th class="tg-0pky">Compile Time</th>
  </tr>
  <tr>
    <th class="tg-subhead" colspan="5">STL Algorithms</th>
  </tr>
  <tr>
    <td class="tg-0pky"><a href="solutions/GroovyZone.html">GroovyZone</a></td>
    <td class="tg-c3ow"><img src="images/amber_face.png"></td>
    <td class="tg-c3ow"><img src="images/red_face.png"></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
  </tr>
  <tr>
    <td class="tg-0pky"><a href="solutions/LordVader.html">LordVader</a></td>
    <td class="tg-c3ow"><img src="images/amber_face.png"></td>
    <td class="tg-c3ow"><img src="images/red_face.png"></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
  </tr>
  <tr>
    <td class="tg-0pky"><a href="solutions/LordVader2_arh.html">LordVader2_arh</a></td>
    <td class="tg-c3ow"><img src="images/amber_face.png"></td>
    <td class="tg-c3ow"><img src="images/red_face.png"></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
  </tr>
  <tr>
    <th class="tg-0pky">Name</th>
    <th class="tg-0pky">Run time</th>
    <th class="tg-0pky">Memory allocation</th>
    <th class="tg-0pky">Maintainability</th>
    <th class="tg-0pky">Compile Time</th>
  </tr>
  <tr>
    <th class="tg-subhead" colspan="5">Threads</th>
  </tr>
  <tr>
    <td class="tg-0pky"><a href="solutions/Pixelf.html">Pixelf</a></td>
    <td class="tg-c3ow"><img src="images/vomit_face.png" style="width:70px"></td>
    <td class="tg-c3ow"><img src="images/red_face.png"></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
  </tr>
  <tr>
    <td class="tg-0pky"><a href="solutions/Pixelf_TBB_arh.html">Pixelf_TBB_arh</a></td>
    <td class="tg-c3ow"><img src="images/amber_face.png"></td>
    <td class="tg-c3ow"><img src="images/red_face.png"></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
  </tr>
  <tr>
    <td class="tg-0pky"><a href="solutions/Pixelf_TBB_scalable_alloc_arh.html">Pixelf_TBB_scalable_alloc_arh</a></td>
    <td class="tg-c3ow"><img src="images/amber_face.png"></td>
    <td class="tg-c3ow"><img src="images/red_face.png"></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
  </tr>
  <tr>
    <td class="tg-0pky"><a href="solutions/Pixelf_TBB_spans_alloc_arh.html">Pixelf_TBB_spans_arh</a></td>
    <td class="tg-c3ow"><img src="images/amber_face.png"></td>
    <td class="tg-c3ow"><img src="images/red_face.png"></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
  </tr>
  <tr>
    <td class="tg-0pky"><a href="solutions/Pixelf_TBB_boost_arh.html">Pixelf_TBB_boost_arh</a></td>
    <td class="tg-c3ow"><img src="images/amber_face.png"></td>
    <td class="tg-c3ow"><img src="images/red_face.png"></td>
    <td class="tg-c3ow"><img src="images/amber_face.png"></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
  </tr>
  <tr>
    <td class="tg-0pky"><a href="solutions/Pixelf_TBB_monotonic_alloc_arh.html">Pixelf_TBB_monotonic_alloc_arh</a></td>
    <td class="tg-c3ow"><img src="images/amber_face.png"></td>
    <td class="tg-c3ow"><img src="images/red_face.png"></td>
    <td class="tg-c3ow"><img src="images/amber_face.png"></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
  </tr>
  <tr>
    <td class="tg-0pky"><a href="solutions/Pixelf_TBB_single_array_arh.html">Pixelf_TBB_single_array_arh</a></td>
    <td class="tg-c3ow"><img src="images/amber_face.png"></td>
    <td class="tg-c3ow"><img src="images/red_face.png"></td>
    <td class="tg-c3ow"><img src="images/amber_face.png"></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
  </tr>
  <tr>
    <th class="tg-0pky">Name</th>
    <th class="tg-0pky">Run time</th>
    <th class="tg-0pky">Memory allocation</th>
    <th class="tg-0pky">Maintainability</th>
    <th class="tg-0pky">Compile Time</th>
  </tr>
  <tr>
    <th class="tg-subhead" colspan="5">Test Exploitation</th>
  </tr>
  <tr>
    <td class="tg-0pky"><a href="solutions/DigitalGerbil.html">DigitalGerbil</a></td>
    <td class="tg-c3ow"><img src="images/amber_face.png"></td>
    <td class="tg-c3ow"><img src="images/amber_face.png"></td>
    <td class="tg-c3ow"><img src="images/red_face.png"></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
  </tr>
  <tr>
    <td class="tg-0pky"><a href="solutions/TerrificPhantom.html">TerrificPhantom</a></td>
    <td class="tg-c3ow"><img src="images/amber_face.png"></td>
    <td class="tg-c3ow"><img src="images/amber_face.png"></td>
    <td class="tg-c3ow"><img src="images/red_face.png"></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
  </tr>
  <tr>
    <th class="tg-0pky">Name</th>
    <th class="tg-0pky">Run time</th>
    <th class="tg-0pky">Memory allocation</th>
    <th class="tg-0pky">Maintainability</th>
    <th class="tg-0pky">Compile Time</th>
  </tr>
  <tr>
    <th class="tg-subhead" colspan="5">Lazy Evaluation</th>
  </tr>
  <tr>
    <td class="tg-0pky"><a href="solutions/Porpoison.html">Porpoison</a></td>
    <td class="tg-c3ow"><img src="images/amber_face.png"></td>
    <td class="tg-c3ow"><img src="images/shiny_green_face.png"></td>
    <td class="tg-c3ow"><img src="images/red_face.png"></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
  </tr>
  <tr>
    <th class="tg-0pky">Name</th>
    <th class="tg-0pky">Run time</th>
    <th class="tg-0pky">Memory allocation</th>
    <th class="tg-0pky">Maintainability</th>
    <th class="tg-0pky">Compile Time</th>
  </tr>
  <tr>
    <th class="tg-subhead" colspan="5">Ranges</th>
  </tr>
  <tr>
    <td class="tg-0pky"><a href="solutions/ArchBanana.html">ArchBanana</a></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
    <td class="tg-c3ow"><img src="images/amber_face.png"></td>
    <td class="tg-c3ow"><img src="images/amber_face.png"></td>
    <td class="tg-c3ow"><img src="images/amber_face.png"></td>
  </tr>
  <tr>
    <td class="tg-0pky"><a href="solutions/ArchBanana2_arh.html">ArchBanana2_arh</a></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
    <td class="tg-c3ow"><img src="images/amber_face.png"></td>
    <td class="tg-c3ow"><img src="images/amber_face.png"></td>
    <td class="tg-c3ow"><img src="images/amber_face.png"></td>
  </tr>
  <tr>
    <td class="tg-0pky"><a href="solutions/EvilDoughnut.html">EvilDoughnut</a></td>
    <td class="tg-c3ow"><img src="images/amber_face.png"></td>
    <td class="tg-c3ow"><img src="images/shiny_green_face.png"></td>
    <td class="tg-c3ow"><img src="images/red_face.png"></td>
    <td class="tg-c3ow"><img src="images/amber_face.png"></td>
  </tr>
  <tr>
    <td class="tg-0pky"><a href="solutions/Proteus.html">Proteus</a></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
    <td class="tg-c3ow"><img src="images/amber_face.png"></td>
    <td class="tg-c3ow"><img src="images/amber_face.png"></td>
    <td class="tg-c3ow"><img src="images/amber_face.png"></td>
  </tr>
  <tr>
    <th class="tg-0pky">Name</th>
    <th class="tg-0pky">Run time</th>
    <th class="tg-0pky">Memory allocation</th>
    <th class="tg-0pky">Maintainability</th>
    <th class="tg-0pky">Compile Time</th>
  </tr>
  <tr>
    <th class="tg-subhead" colspan="5">Compile Time Computation</th>
  </tr>
  <tr>
    <td class="tg-0pky"><a href="solutions/Erwin.html">Erwin</a></td>
    <td class="tg-c3ow"><img src="images/amber_face.png"></td>
    <td class="tg-c3ow"><img src="images/amber_face.png"></td>
    <td class="tg-c3ow"><img src="images/red_face.png"></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
  </tr>
  <tr>
    <td class="tg-0pky"><a href="solutions/FireFly.html">FireFly</a></td>
    <td class="tg-c3ow"><img src="images/shiny_green_face.png"></td>
    <td class="tg-c3ow"><img src="images/shiny_green_face.png"></td>
    <td class="tg-c3ow"><img src="images/red_face.png"></td>
    <td class="tg-c3ow"><img src="images/amber_face.png"></td>
  </tr>
  <tr>
    <td class="tg-0pky"><a href="solutions/LightningHippo_arh.html">LightningHippo_arh</a></td>
    <td class="tg-c3ow"><img src="images/shiny_green_face.png"></td>
    <td class="tg-c3ow"><img src="images/shiny_green_face.png"></td>
    <td class="tg-c3ow"><img src="images/green_face.png"></td>
    <td class="tg-c3ow"><img src="images/amber_face.png"></td>
  </tr>
</tbody>
</table>
<h1><a class="header" href="#original-problem-statement" id="original-problem-statement">Original Problem Statement</a></h1>
<p>This was the original coding challenge that I set in May 2020.</p>
<h2><a class="header" href="#mini-coding-challenge---07-may-2020" id="mini-coding-challenge---07-may-2020">Mini coding challenge - 07 May 2020</a></h2>
<p>Pascal's Triangle is a triangular array containing the binomial coefficients.</p>
<p>Here's the first 9 rows:</p>
<pre><code class="language-shell">                    1
                  1   1
                1   2   1
              1   3   3   1
            1   4   6   4   1
          1   5  10  10   5   1
        1   6  15  20  15   6   1
      1   7  21  35  35  21   7   1
    1   8  28  56  70  56  28   8   1
</code></pre>
<p>To construct a new row, compute each entry by taking the sum of the two values
immediately above it in the previous row (i.e. above left and above right). At
the left and right hand ends where there is only one number directly above, we
place a 1.</p>
<h2><a class="header" href="#your-task" id="your-task">Your task</a></h2>
<p>Your task is to write a function that generates a given number of rows of
pascal's triangle. You can find a skeleton implementation of the function in
<code>pascals_triangle.h</code> and <code>pascals_triangle.cpp</code>.</p>
<p>Here are the steps you should follow:</p>
<ol>
<li>Make sure you can build the project.</li>
</ol>
<pre><code class="language-bash">mkdir pascals_triangle
cd pascals_triangle

git clone https://github.com/aharrison24/pascals_triangle.git src

mkdir build
cd build
cmake ../src

make
</code></pre>
<ol start="2">
<li>Run the tests</li>
</ol>
<pre><code class="language-bash">./pascals_triangle_tests
</code></pre>
<p>You should see a series of test failures.</p>
<ol start="3">
<li>Update the source files <code>pascals_triangle.h</code> and <code>pascals_triangle.cpp</code>
however you please in order to get the tests to pass.</li>
</ol>
<h2><a class="header" href="#questions-you-may-have" id="questions-you-may-have">Questions you may have</a></h2>
<h4><a class="header" href="#q-what-c-standard-can-i-use" id="q-what-c-standard-can-i-use">Q: What C++ standard can I use</a></h4>
<p>The project is set up to allow C++17. Please stick to that.</p>
<h4><a class="header" href="#q-can-my-solution-be-header-only" id="q-can-my-solution-be-header-only">Q: Can my solution be header-only?</a></h4>
<p>Sure. In the submission form, where it asks for the contents of the cpp file,
just leave the box empty.</p>
<h4><a class="header" href="#q-can-i-use-any-third-party-libraries" id="q-can-i-use-any-third-party-libraries">Q: Can I use any third-party libraries?</a></h4>
<p>You may use anything in the C++ standard library. If you wish, you may also use
the <a href="https://ericniebler.github.io/range-v3/">Range v3 library</a> and the
<a href="https://fmt.dev/latest/">fmt</a> library, both of which are included in the
thirdparty directory. Though they are <em>certainly not necessary</em> to solve the
challenge. The CMake project is set up to allow you to use both libraries
straight away in your source files.</p>
<p>Please do not use any other third-party libraries.</p>
<h4><a class="header" href="#q-whats-the-deal-with-that-weird-solution_namespace-macro" id="q-whats-the-deal-with-that-weird-solution_namespace-macro">Q: What's the deal with that weird <code>SOLUTION_NAMESPACE</code> macro?</a></h4>
<p>Sorry about that. I need to be able to take all the submitted solutions and drop
them into my master project for testing. I need each solution to go into its own
namespace to avoid violations of the One Definition Rule. The macro lets me
replace the namespace programmatically. Please do not modify the line that
contains:</p>
<pre><code class="language-c++">namespace SOLUTION_NAMESPACE {
</code></pre>
<h4><a class="header" href="#q-can-i-modify-the-test-file" id="q-can-i-modify-the-test-file">Q: Can I modify the test file?</a></h4>
<p>If it helps you to comment out some of the tests while you work on your solution
then sure. But your submitted result needs to pass with all of the tests
unmodified.</p>
<h4><a class="header" href="#q-can-i-change-the-function-signature-of-generate_rows" id="q-can-i-change-the-function-signature-of-generate_rows">Q: Can I change the function signature of <code>generate_rows</code>?</a></h4>
<p>Uh. If you like. You just have to get the tests to pass unmodified.</p>
<h1><a class="header" href="#appendix-ii---benchmark-hardware-and-compiler-flags" id="appendix-ii---benchmark-hardware-and-compiler-flags">Appendix II - Benchmark hardware and compiler flags</a></h1>
<p>I used the <a href="https://github.com/google/benchmark">Google Benchmark</a>
library to generate the microbenchmark results.</p>
<p>Most of the benchmarks were run on a 2.4GHz Intel Core i9 MacBook Pro
(I9-9980HK), with 8 real cores (allowing up to 16 parallel threads with Hyper
threading). Each core has 32kB L1 cache and 256kB L2 cache. There's also a 16MB
L3 cache which is shared between all cores.</p>
<p>Hyper-threading was <em>disabled</em>, as was automatic CPU throttling, as
they are both sources of non-determinism. When hyper-threading is enabled, the
OS might schedule a task on the same physical core as your benchmark and cause
resources to be randomly contended, which is not known to increase the quality
of results.</p>
<p>The compiler was Clang 11.0.0 and the optimisation/architecture flags were</p>
<pre><code>-O3 -mavx2 -mllvm -align-all-blocks=5
</code></pre>
<p>I allowed the compiler to generate AVX2 instructions by specifying the <code>-mavx2</code>
flag. These are an <a href="https://en.wikipedia.org/wiki/Advanced_Vector_Extensions">extension to the x86 instruction set</a>
which allow a single CPU instruction to operate on
<a href="https://en.wikipedia.org/wiki/SIMD">multiple pieces of data simultaneously</a>.
AVX2 has been around since 2013, and is widely supported by current desktop and
mobile CPUs. Enabling the flag does not automatically make your code go faster,
but compilers will try to use the extra instructions where possible.</p>
<p>The use of <code>-mllvm -align-all-blocks=5</code> flags was necessary to mitigate against
some hilariously unstable performance measurements. You can read more about this
in the <a href="appendices/../code_alignment_issues.html">code alignment</a> section.</p>
<h1><a class="header" href="#appendix-iii---submissions" id="appendix-iii---submissions">Appendix III - Submissions</a></h1>
<p>This is a list of all of the submissions received. The links will take you to 
the source code as well as any reviews that were received for the submission.</p>
<p><strong>Submissions that have the suffix <code>_arh</code> are ones that I created in order to
demonstrate interesting things.</strong></p>
<h3><a class="header" href="#baseline-solution-1" id="baseline-solution-1">Baseline solution</a></h3>
<ul>
<li><a href="./solutions/Baseline.html">Baseline</a></li>
</ul>
<h3><a class="header" href="#a-hrefloopsloopshtmlloops-make-the-world-go-round-and-rounda-1" id="a-hrefloopsloopshtmlloops-make-the-world-go-round-and-rounda-1"><a href="./loops/loops.html">Loops make the world go round (and round...)</a></a></h3>
<ul>
<li><a href="./solutions/AskingCrow.html">AskingCrow</a></li>
<li><a href="./solutions/BumbleBeetle.html">BumbleBeetle</a></li>
<li><a href="./solutions/CluelessWolverine.html">CluelessWolverine</a></li>
<li><a href="./solutions/CluelessWolverine2.html">CluelessWolverine2</a></li>
<li><a href="./solutions/Fortran4Ever.html">Fortran4Ever</a></li>
<li><a href="./solutions/simple_basic_solution.html">simple_basic_solution</a></li>
<li><a href="./solutions/user_usery.html">user_usery</a></li>
<li><a href="./solutions/FlyingDesitter_arh.html">FlyingDesitter_arh</a></li>
</ul>
<h3><a class="header" href="#a-hrefeverything_is_a_matrixhtmleverything-is-a-matrixa-1" id="a-hrefeverything_is_a_matrixhtmleverything-is-a-matrixa-1"><a href="everything_is_a_matrix.html">Everything is a matrix</a></a></h3>
<ul>
<li><a href="./solutions/pascalsTriangle.for.html">pascalsTriangle.for</a></li>
</ul>
<h3><a class="header" href="#a-hrefstl_algorithmshtmlstl-algorithms-have-awful-namesa-1" id="a-hrefstl_algorithmshtmlstl-algorithms-have-awful-namesa-1"><a href="stl_algorithms.html">STL algorithms have awful names</a></a></h3>
<ul>
<li><a href="./solutions/GroovyZone.html">GroovyZone</a></li>
<li><a href="./solutions/LordVader.html">LordVader</a></li>
</ul>
<h3><a class="header" href="#a-hrefthreadsthreads_to_the_rescuehtmlthreads-to-the-rescuea-1" id="a-hrefthreadsthreads_to_the_rescuehtmlthreads-to-the-rescuea-1"><a href="./threads/threads_to_the_rescue.html">Threads to the rescue!</a></a></h3>
<ul>
<li><a href="./solutions/Pixelf.html">Pixelf</a></li>
<li><a href="./solutions/Pixelf_TBB_arh.html">Pixelf_TBB_arh</a></li>
<li><a href="./solutions/Pixelf_TBB_scalable_alloc_arh.html">Pixelf_TBB_scalable_alloc_arh</a></li>
<li><a href="./solutions/Pixelf_TBB_spans_arh.html">Pixelf_TBB_spans_arh</a></li>
<li><a href="./solutions/Pixelf_TBB_boost_arh.html">Pixelf_TBB_boost_arh</a></li>
<li><a href="./solutions/Pixelf_TBB_monotonic_alloc_arh.html">Pixelf_TBB_monotonic_alloc_arh</a></li>
<li><a href="./solutions/Pixelf_TBB_single_array_arh.html">Pixelf_TBB_single_array_arh</a></li>
</ul>
<h3><a class="header" href="#a-hrefall_your_tests_are_terriblehtmlall-your-tests-are-terriblea-1" id="a-hrefall_your_tests_are_terriblehtmlall-your-tests-are-terriblea-1"><a href="./all_your_tests_are_terrible.html">All your tests are terrible</a></a></h3>
<ul>
<li><a href="./solutions/DigitalGerbil.html">DigitalGerbil</a></li>
<li><a href="./solutions/TerrificPhantom.html">TerrificPhantom</a></li>
</ul>
<h3><a class="header" href="#a-hreflazinesshtmllaziness-is-the-first-step-towards-efficiencya-1" id="a-hreflazinesshtmllaziness-is-the-first-step-towards-efficiencya-1"><a href="laziness.html">Laziness is the first step towards efficiency</a></a></h3>
<ul>
<li><a href="./solutions/Porpoison.html">Porpoison</a></li>
</ul>
<h3><a class="header" href="#a-hrefrangeshtmlhow-to-kill-your-compile-timesa-1" id="a-hrefrangeshtmlhow-to-kill-your-compile-timesa-1"><a href="ranges.html">How to kill your compile times</a></a></h3>
<ul>
<li><a href="./solutions/ArchBanana.html">ArchBanana</a></li>
<li><a href="./solutions/ArchBanana2_arh.html">ArchBanana2_arh</a></li>
<li><a href="./solutions/EvilDoughnut.html">EvilDoughnut</a></li>
<li><a href="./solutions/FrostyMongoose.html">FrostyMongoose</a></li>
<li><a href="./solutions/Proteus.html">Proteus</a></li>
</ul>
<h3><a class="header" href="#a-hrefconstexpr_cakehtmlhave-your-constexpr-cake-and-eat-ita-1" id="a-hrefconstexpr_cakehtmlhave-your-constexpr-cake-and-eat-ita-1"><a href="constexpr_cake.html">Have your constexpr cake and eat it</a></a></h3>
<ul>
<li><a href="./solutions/Erwin.html">Erwin</a></li>
<li><a href="./solutions/FireFly.html">FireFly</a></li>
<li><a href="./solutions/LightningHippo_arh.html">LightningHippo_arh</a></li>
</ul>
<h1><a class="header" href="#baseline-1" id="baseline-1">Baseline</a></h1>
<p>A copy of the CluelessWolverine2 submission, without the half-row optimisation.</p>
<h4><a class="header" href="#header" id="header">Header</a></h4>
<pre><code class="language-c++">#pragma once

#include &lt;cstdint&gt;
#include &lt;vector&gt;

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

auto generate_rows(uint32_t num_rows) -&gt; std::vector&lt;std::vector&lt;uint64_t&gt;&gt;;

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h4><a class="header" href="#source" id="source">Source</a></h4>
<pre><code class="language-c++">#include &lt;cstdint&gt;
#include &lt;vector&gt;

#include SOLUTION_HEADER

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

auto generate_rows(uint32_t num_rows) -&gt; std::vector&lt;std::vector&lt;uint64_t&gt;&gt; {

  std::vector&lt;std::vector&lt;uint64_t&gt;&gt; triangle;
  triangle.reserve(num_rows);

  for (uint32_t i = 0; i &lt; num_rows; ++i) {
    // Create row, pre-sized, all 1s.
    std::vector&lt;uint64_t&gt; row(i + 1, 1);

    for (uint32_t j = 1; j &lt; i; ++j) {
      // Compute internal row elements
      row[j] = triangle[i - 1][j - 1] + triangle[i - 1][j];
    }

    // Add to full triangle
    triangle.push_back(std::move(row));
  }

  return triangle;
}

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h2><a class="header" href="#reviews" id="reviews">Reviews</a></h2>
<p>None. This solution is only there as a baseline to measure others against.</p>
<h1><a class="header" href="#askingcrow-1" id="askingcrow-1">AskingCrow</a></h1>
<h4><a class="header" href="#header-1" id="header-1">Header</a></h4>
<pre><code class="language-c++">#pragma once

#include &lt;cstdint&gt;
#include &lt;vector&gt;

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

auto generate_rows(uint32_t num_rows) -&gt; std::vector&lt;std::vector&lt;uint64_t&gt;&gt;;

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h4><a class="header" href="#source-1" id="source-1">Source</a></h4>
<pre><code class="language-c++">#include &lt;cstdint&gt;
#include &lt;vector&gt;

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

// ANCHOR: snippet
auto generate_rows(uint32_t num_rows) -&gt; std::vector&lt;std::vector&lt;uint64_t&gt;&gt; {
  std::vector&lt;std::vector&lt;uint64_t&gt;&gt; rows;
  std::vector&lt;uint64_t&gt; previous_row;

  while (rows.size() &lt; num_rows) {
    std::vector&lt;uint64_t&gt; new_row;
    uint64_t previous_element = 0;
    for (const auto element : previous_row) {
      new_row.push_back(previous_element + element);
      previous_element = element;
    }

    new_row.push_back(1);
    rows.push_back(new_row);
    previous_row = new_row;
  }
  return rows;
}
// ANCHOR_END: snippet

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h2><a class="header" href="#reviews-1" id="reviews-1">Reviews</a></h2>
<table style="float:left">
<thead>
<tr><th>How easy to understand?</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>A newcomer to C++ could grok it                </td><td>X</td></tr>
<tr><td>A junior dev should be fine with it            </td><td>X</td></tr>
<tr><td>Most devs would be comfortable                 </td><td>X</td></tr>
<tr><td>Experienced C++ developers only                </td><td></td></tr>
<tr><td>You'd need to be on the C++ standards committee</td><td></td></tr>
</tbody>
<thead>
<tr><th>Maintainability</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>Wouldn't touch it with a barge pole                         </td><td>X</td></tr>
<tr><td>I could manage it I had to, but would worry I might break it</td><td>X</td></tr>
<tr><td>No problem at all                                           </td><td>X</td></tr>
</tbody>
<thead>
<tr><th>Performance compared to simple nested loop and vectors</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>Much worse</td><td></td></tr>
<tr><td>A bit worse</td><td>X</td></tr>
<tr><td>About the same</td><td>XX</td></tr>
<tr><td>A bit faster</td><td></td></tr>
<tr><td>Warp factor 9</td><td></td></tr>
</tbody>
<thead>
<tr><th>New things learned</th><th></th></tr>
</thead>
<tbody>
<tr><td></td><td></td></tr>
</tbody>
<thead>
<tr><th>Comments</th><th></th></tr>
</thead>
<tbody>
<tr><td></td><td></td></tr>
</tbody>
</table>
<h1><a class="header" href="#bumblebeetle" id="bumblebeetle">BumbleBeetle</a></h1>
<h4><a class="header" href="#header-2" id="header-2">Header</a></h4>
<pre><code class="language-c++">#pragma once

#include &lt;cstdint&gt;
#include &lt;vector&gt;

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

auto generate_rows(uint32_t num_rows) -&gt; std::vector&lt;std::vector&lt;uint64_t&gt;&gt;;

auto generate_single_row(std::vector&lt;uint64_t&gt;&amp; vec) -&gt; std::vector&lt;uint64_t&gt;;

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h4><a class="header" href="#source-2" id="source-2">Source</a></h4>
<pre><code class="language-c++">#include &lt;cstdint&gt;
#include &lt;vector&gt;

#include SOLUTION_HEADER

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

auto generate_single_row(std::vector&lt;uint64_t&gt;&amp; vec) -&gt; std::vector&lt;uint64_t&gt; {
  std::vector&lt;uint64_t&gt; single_row;

  single_row.push_back(1);

  // sum values from previous row
  for (uint32_t i = 1; i &lt; vec.size(); ++i) {
    single_row.push_back(vec[i - 1] + vec[i]);
  }

  // add last '1' element to grow the triangle
  single_row.push_back(1);

  return single_row;
}

auto generate_rows(uint32_t num_rows) -&gt; std::vector&lt;std::vector&lt;uint64_t&gt;&gt; {
  std::vector&lt;std::vector&lt;uint64_t&gt;&gt; answer;

  // return empty array for zero edge case
  if (num_rows == 0) {
    return answer;
  }

  // add first element of first row
  answer.emplace_back(std::vector&lt;uint64_t&gt;{1});

  // if num_rows &gt; 1, add more rows to the answer
  for (uint32_t i = 1; i &lt; num_rows; ++i) {
    const std::vector&lt;uint64_t&gt; new_row = generate_single_row(answer[i - 1]);
    answer.emplace_back(new_row);
  }

  return answer;
}

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h2><a class="header" href="#reviews-2" id="reviews-2">Reviews</a></h2>
<table style="float:left">
<thead>
<tr><th>How easy to understand?</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>A newcomer to C++ could grok it                </td><td>XX</td></tr>
<tr><td>A junior dev should be fine with it            </td><td></td></tr>
<tr><td>Most devs would be comfortable                 </td><td>X</td></tr>
<tr><td>Experienced C++ developers only                </td><td></td></tr>
<tr><td>You'd need to be on the C++ standards committee</td><td></td></tr>
</tbody>
<thead>
<tr><th>Maintainability</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>Wouldn't touch it with a barge pole                         </td><td></td></tr>
<tr><td>I could manage it I had to, but would worry I might break it</td><td></td></tr>
<tr><td>No problem at all                                           </td><td>XXX</td></tr>
</tbody>
<thead>
<tr><th>Performance compared to simple nested loop and vectors</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>Much worse</td><td></td></tr>
<tr><td>A bit worse</td><td>X</td></tr>
<tr><td>About the same</td><td>XX</td></tr>
<tr><td>A bit faster</td><td></td></tr>
<tr><td>Warp factor 9</td><td></td></tr>
</tbody>
<thead>
<tr><th>New things learned</th><th></th></tr>
</thead>
<tbody>
<tr><td></td><td></td></tr>
</tbody>
<thead>
<tr><th>Comments</th><th></th></tr>
</thead>
<tbody>
<tr><td>There is an easy efficient win on line 38 by moving new_row into the triangle</td><td></td></tr>
</tbody>
</table>
<h1><a class="header" href="#cluelesswolverine" id="cluelesswolverine">CluelessWolverine</a></h1>
<h4><a class="header" href="#header-3" id="header-3">Header</a></h4>
<pre><code class="language-c++">#pragma once

#include &lt;cstdint&gt;
#include &lt;vector&gt;

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

auto generate_rows(uint32_t num_rows) -&gt; std::vector&lt;std::vector&lt;uint64_t&gt;&gt;;

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h4><a class="header" href="#source-3" id="source-3">Source</a></h4>
<pre><code class="language-c++">#include &lt;cmath&gt;
#include &lt;cstdint&gt;
#include &lt;vector&gt;

#include SOLUTION_HEADER

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

auto generate_rows(uint32_t num_rows) -&gt; std::vector&lt;std::vector&lt;uint64_t&gt;&gt; {

  std::vector&lt;std::vector&lt;uint64_t&gt;&gt; triangle(num_rows);

  for (uint32_t i = 0; i &lt; num_rows; i++) {
    // Create row, pre-sized, all 1s.
    std::vector&lt;uint64_t&gt; row(i + 1, 1);

    for (uint32_t j = 1; j &lt; (i + 2) / 2; j++) {
      // Compute each non-1 entry and assign to both sides of triangle
      row[j] = row[i - j] = triangle[i - 1][j - 1] + triangle[i - 1][j];
    }

    // Add to full triangle
    triangle[i] = row;
  }

  return triangle;
}

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h2><a class="header" href="#reviews-3" id="reviews-3">Reviews</a></h2>
<table style="float:left">
<thead>
<tr><th>How easy to understand?</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>A newcomer to C++ could grok it                </td><td>XX</td></tr>
<tr><td>A junior dev should be fine with it            </td><td>X</td></tr>
<tr><td>Most devs would be comfortable                 </td><td></td></tr>
<tr><td>Experienced C++ developers only                </td><td></td></tr>
<tr><td>You'd need to be on the C++ standards committee</td><td></td></tr>
</tbody>
<thead>
<tr><th>Maintainability</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>Wouldn't touch it with a barge pole                         </td><td></td></tr>
<tr><td>I could manage it I had to, but would worry I might break it</td><td></td></tr>
<tr><td>No problem at all                                           </td><td>XXX</td></tr>
</tbody>
<thead>
<tr><th>Performance compared to simple nested loop and vectors</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>Much worse</td><td></td></tr>
<tr><td>A bit worse</td><td></td></tr>
<tr><td>About the same</td><td>XX</td></tr>
<tr><td>A bit faster</td><td>X</td></tr>
<tr><td>Warp factor 9</td><td></td></tr>
</tbody>
<thead>
<tr><th>New things learned</th><th></th></tr>
</thead>
<tbody>
<tr><td></td><td></td></tr>
</tbody>
<thead>
<tr><th>Comments</th><th></th></tr>
</thead>
<tbody>
<tr><td>the double assignment and the inner loop conditions are a bit confusing.</td><td></td></tr>
</tbody>
</table>
<h1><a class="header" href="#cluelesswolverine2-1" id="cluelesswolverine2-1">CluelessWolverine2</a></h1>
<h4><a class="header" href="#header-4" id="header-4">Header</a></h4>
<pre><code class="language-c++">#pragma once

#include &lt;cstdint&gt;
#include &lt;vector&gt;

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

auto generate_rows(uint32_t num_rows) -&gt; std::vector&lt;std::vector&lt;uint64_t&gt;&gt;;

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h4><a class="header" href="#source-4" id="source-4">Source</a></h4>
<pre><code class="language-c++">#include &lt;cmath&gt;
#include &lt;cstdint&gt;
#include &lt;vector&gt;

#include SOLUTION_HEADER

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

auto generate_rows(uint32_t num_rows) -&gt; std::vector&lt;std::vector&lt;uint64_t&gt;&gt; {
  std::vector&lt;std::vector&lt;uint64_t&gt;&gt; triangle;
  triangle.reserve(num_rows);

  for (uint32_t i = 0; i &lt; num_rows; i++) {
    // Create row, pre-sized, all 1s.
    std::vector&lt;uint64_t&gt; row(i + 1, 1);

    for (uint32_t j = 1; j &lt; (i + 2) / 2; j++) {
      // Compute each non-1 entry and assign to both sides of triangle
      row[j] = row[i - j] = triangle[i - 1][j - 1] + triangle[i - 1][j];
    }

    // Add to full triangle
    triangle.push_back(std::move(row));
  }

  return triangle;
}

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h2><a class="header" href="#reviews-4" id="reviews-4">Reviews</a></h2>
<table style="float:left">
<thead>
<tr><th>How easy to understand?</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>A newcomer to C++ could grok it                </td><td>X</td></tr>
<tr><td>A junior dev should be fine with it            </td><td></td></tr>
<tr><td>Most devs would be comfortable                 </td><td></td></tr>
<tr><td>Experienced C++ developers only                </td><td></td></tr>
<tr><td>You'd need to be on the C++ standards committee</td><td></td></tr>
</tbody>
<thead>
<tr><th>Maintainability</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>Wouldn't touch it with a barge pole                         </td><td></td></tr>
<tr><td>I could manage it I had to, but would worry I might break it</td><td></td></tr>
<tr><td>No problem at all                                           </td><td>X</td></tr>
</tbody>
<thead>
<tr><th>Performance compared to simple nested loop and vectors</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>Much worse</td><td></td></tr>
<tr><td>A bit worse</td><td></td></tr>
<tr><td>About the same</td><td></td></tr>
<tr><td>A bit faster</td><td>X</td></tr>
<tr><td>Warp factor 9</td><td></td></tr>
</tbody>
<thead>
<tr><th>New things learned</th><th></th></tr>
</thead>
<tbody>
<tr><td></td><td></td></tr>
</tbody>
<thead>
<tr><th>Comments</th><th></th></tr>
</thead>
<tbody>
<tr><td></td><td></td></tr>
</tbody>
</table>
<h1><a class="header" href="#fortran4ever" id="fortran4ever">Fortran4Ever</a></h1>
<h4><a class="header" href="#header-5" id="header-5">Header</a></h4>
<pre><code class="language-c++">#pragma once

#include &lt;cstdint&gt;
#include &lt;vector&gt;

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

auto generate_rows(uint32_t num_rows) -&gt; std::vector&lt;std::vector&lt;uint64_t&gt;&gt;;

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h4><a class="header" href="#source-5" id="source-5">Source</a></h4>
<pre><code class="language-c++">#include &lt;cstdint&gt;
#include &lt;vector&gt;

#include SOLUTION_HEADER

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

//----------------------------------------------------------------------------
auto generate_rows(uint32_t num_rows) -&gt; std::vector&lt;std::vector&lt;uint64_t&gt;&gt; {

  if (num_rows == 0) {
    return {};
  }

  std::vector&lt;std::vector&lt;uint64_t&gt;&gt; triangle_array(
      num_rows, std::vector&lt;uint64_t&gt;(num_rows + 1, 0));

  triangle_array[0][1] = 1;
  for (uint32_t m_i = 1; m_i &lt; num_rows; m_i++) {
    for (uint32_t m_j = 1; m_j &lt; num_rows + 1; m_j++) {
      triangle_array[m_i][m_j] =
          triangle_array[m_i - 1][m_j - 1] + triangle_array[m_i - 1][m_j];
    }
  }

  size_t n_entries = 1;
  for (auto&amp; row : triangle_array) {
    row.erase(std::begin(row));
    row.resize(n_entries);
    n_entries++;
  }

  return triangle_array;
}

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h2><a class="header" href="#reviews-5" id="reviews-5">Reviews</a></h2>
<table style="float:left">
<thead>
<tr><th>How easy to understand?</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>A newcomer to C++ could grok it                </td><td></td></tr>
<tr><td>A junior dev should be fine with it            </td><td></td></tr>
<tr><td>Most devs would be comfortable                 </td><td>X</td></tr>
<tr><td>Experienced C++ developers only                </td><td></td></tr>
<tr><td>You'd need to be on the C++ standards committee</td><td></td></tr>
</tbody>
<thead>
<tr><th>Maintainability</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>Wouldn't touch it with a barge pole                         </td><td></td></tr>
<tr><td>I could manage it I had to, but would worry I might break it</td><td>X</td></tr>
<tr><td>No problem at all                                           </td><td></td></tr>
</tbody>
<thead>
<tr><th>Performance compared to simple nested loop and vectors</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>Much worse</td><td></td></tr>
<tr><td>A bit worse</td><td></td></tr>
<tr><td>About the same</td><td>X</td></tr>
<tr><td>A bit faster</td><td></td></tr>
<tr><td>Warp factor 9</td><td></td></tr>
</tbody>
<thead>
<tr><th>New things learned</th><th></th></tr>
</thead>
<tbody>
<tr><td></td><td></td></tr>
</tbody>
<thead>
<tr><th>Comments</th><th></th></tr>
</thead>
<tbody>
<tr><td></td><td></td></tr>
</tbody>
</table>
<h1><a class="header" href="#simple_basic_solution" id="simple_basic_solution">simple_basic_solution</a></h1>
<h4><a class="header" href="#header-6" id="header-6">Header</a></h4>
<pre><code class="language-c++">#pragma once

#include &lt;cstdint&gt;
#include &lt;vector&gt;

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

auto generate_rows(uint32_t num_rows) -&gt; std::vector&lt;std::vector&lt;uint64_t&gt;&gt;;

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h4><a class="header" href="#source-6" id="source-6">Source</a></h4>
<pre><code class="language-c++">#include &lt;cstdint&gt;
#include &lt;vector&gt;

#include SOLUTION_HEADER

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

auto generate_rows(uint32_t num_rows) -&gt; std::vector&lt;std::vector&lt;uint64_t&gt;&gt; {
  std::vector&lt;std::vector&lt;uint64_t&gt;&gt; vv = {};

  for (uint32_t i = 1; i &lt;= num_rows; ++i) {
    std::vector&lt;uint64_t&gt; row(i);

    for (uint32_t j = 0; j &lt; i; ++j) {
      // first and last elements always 1.
      if (j == 0 || j == i - 1) {
        row.at(j) = 1;
      } else {
        // use a pair of iterators to the previous row.
        auto back_itr = (--vv.end())-&gt;begin() + j;
        auto front_itr = back_itr - 1;

        row.at(j) = *front_itr + *back_itr;
      }
    }

    vv.push_back(std::move(row));
  }
  return vv;
}

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h2><a class="header" href="#reviews-6" id="reviews-6">Reviews</a></h2>
<table style="float:left">
<thead>
<tr><th>How easy to understand?</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>A newcomer to C++ could grok it                </td><td></td></tr>
<tr><td>A junior dev should be fine with it            </td><td></td></tr>
<tr><td>Most devs would be comfortable                 </td><td>X</td></tr>
<tr><td>Experienced C++ developers only                </td><td></td></tr>
<tr><td>You'd need to be on the C++ standards committee</td><td></td></tr>
</tbody>
<thead>
<tr><th>Maintainability</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>Wouldn't touch it with a barge pole                         </td><td></td></tr>
<tr><td>I could manage it I had to, but would worry I might break it</td><td></td></tr>
<tr><td>No problem at all                                           </td><td>X</td></tr>
</tbody>
<thead>
<tr><th>Performance compared to simple nested loop and vectors</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>Much worse</td><td></td></tr>
<tr><td>A bit worse</td><td></td></tr>
<tr><td>About the same</td><td>X</td></tr>
<tr><td>A bit faster</td><td></td></tr>
<tr><td>Warp factor 9</td><td></td></tr>
</tbody>
<thead>
<tr><th>New things learned</th><th></th></tr>
</thead>
<tbody>
<tr><td></td><td></td></tr>
</tbody>
<thead>
<tr><th>Comments</th><th></th></tr>
</thead>
<tbody>
<tr><td></td><td></td></tr>
</tbody>
</table>
<h1><a class="header" href="#user_usery" id="user_usery">user_usery</a></h1>
<h4><a class="header" href="#header-7" id="header-7">Header</a></h4>
<pre><code class="language-c++">#pragma once

#include &lt;cstdint&gt;
#include &lt;vector&gt;

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

auto generate_rows(uint32_t num_rows) -&gt; std::vector&lt;std::vector&lt;uint64_t&gt;&gt;;

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h4><a class="header" href="#source-7" id="source-7">Source</a></h4>
<pre><code class="language-c++">#include &lt;cstdint&gt;
#include &lt;vector&gt;

#include SOLUTION_HEADER

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

void BuildNewRowWithoutStartAndEndElements(
    const std::vector&lt;uint64_t&gt; &amp;previous_row, std::vector&lt;uint64_t&gt; &amp;new_row) {

  if (previous_row.size() &lt;= 1) {
    return;
  } else {
    for (size_t i = 0; i &lt; previous_row.size(); i++) {
      if ((i + 1) &lt; previous_row.size()) {
        new_row[i + 1] = previous_row[i] + previous_row[i + 1];
      }
    }
  }
}

auto generate_rows(uint32_t num_rows) -&gt; std::vector&lt;std::vector&lt;uint64_t&gt;&gt; {

  std::vector&lt;std::vector&lt;uint64_t&gt;&gt; solution;

  if (num_rows == 0) {
    return solution;
  }

  // Resize everything to avoid multiple reallocations.
  solution.resize(num_rows);
  for (size_t i = 0; i &lt; num_rows; i++) {
    // Resize each row with the number of elemenets that it will hold.
    solution[i].resize(i + 1);
  }

  // Adding the first row to the solution.
  // We know that we will need at least one row.
  solution[0] = {1};

  for (size_t row_idx = 1; row_idx &lt; num_rows; row_idx++) {
    BuildNewRowWithoutStartAndEndElements(solution[row_idx - 1],
                                          solution[row_idx]);
    solution[row_idx][0] = 1;
    solution[row_idx][solution[row_idx].size() - 1] = 1;
  }

  return solution;
}

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h2><a class="header" href="#reviews-7" id="reviews-7">Reviews</a></h2>
<table style="float:left">
<thead>
<tr><th>How easy to understand?</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>A newcomer to C++ could grok it                </td><td>X</td></tr>
<tr><td>A junior dev should be fine with it            </td><td></td></tr>
<tr><td>Most devs would be comfortable                 </td><td></td></tr>
<tr><td>Experienced C++ developers only                </td><td></td></tr>
<tr><td>You'd need to be on the C++ standards committee</td><td></td></tr>
</tbody>
<thead>
<tr><th>Maintainability</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>Wouldn't touch it with a barge pole                         </td><td></td></tr>
<tr><td>I could manage it I had to, but would worry I might break it</td><td></td></tr>
<tr><td>No problem at all                                           </td><td>X</td></tr>
</tbody>
<thead>
<tr><th>Performance compared to simple nested loop and vectors</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>Much worse</td><td></td></tr>
<tr><td>A bit worse</td><td></td></tr>
<tr><td>About the same</td><td>X</td></tr>
<tr><td>A bit faster</td><td></td></tr>
<tr><td>Warp factor 9</td><td></td></tr>
</tbody>
<thead>
<tr><th>New things learned</th><th></th></tr>
</thead>
<tbody>
<tr><td></td><td></td></tr>
</tbody>
<thead>
<tr><th>Comments</th><th></th></tr>
</thead>
<tbody>
<tr><td>It is written in simple C++, so it is understandable, but there are a few bits that are unnecessary and could be cleaned up (the check at line 15 for example)</td><td></td></tr>
</tbody>
</table>
<h1><a class="header" href="#flyingdesitter_arh" id="flyingdesitter_arh">FlyingDesitter_arh</a></h1>
<p>A fast loop-based solution that neurotically avoids doing expensive things. In
particular, it allocates a single contiguous chunk of memory and then uses
lightweight <code>span</code> objects to point at individual row ranges within that memory.</p>
<h4><a class="header" href="#header-8" id="header-8">Header</a></h4>
<pre><code class="language-c++">#pragma once

#include &lt;cstdint&gt;
#include &lt;memory&gt;
#include &lt;range/v3/view/span.hpp&gt;
#include &lt;vector&gt;

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

namespace detail {
class PascalsTriangle {
  std::unique_ptr&lt;uint64_t[]&gt; values_;
  std::vector&lt;ranges::span&lt;uint64_t&gt;&gt; rows_;

 public:
  PascalsTriangle(uint32_t num_rows);

  auto begin() const { return rows_.cbegin(); }
  auto end() const { return rows_.cend(); }
};
}  // namespace detail

inline auto generate_rows(uint32_t num_rows) -&gt; detail::PascalsTriangle {
  return detail::PascalsTriangle(num_rows);
}

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h4><a class="header" href="#source-8" id="source-8">Source</a></h4>
<pre><code class="language-c++">#include SOLUTION_HEADER

#include &lt;cstdint&gt;
#include &lt;vector&gt;

namespace {
constexpr auto row_begin_index(uint64_t row) noexcept -&gt; uint64_t {
  return (row * (row + 1)) / 2;
}
}  // namespace

namespace SOLUTION_NAMESPACE::detail {

PascalsTriangle::PascalsTriangle(uint32_t num_rows)
    : values_(new uint64_t[row_begin_index(num_rows)]) {
  rows_.reserve(num_rows);

  uint64_t* p = values_.get();
  auto row = ranges::span&lt;uint64_t&gt;();
  for (uint32_t i = 0; i &lt; num_rows; ++i, p += i) {
    auto prev_row = std::exchange(row, ranges::span&lt;uint64_t&gt;(p, i + 1));

    row[0] = 1;
    for (uint32_t j = 1; j &lt; i; ++j) {
      row[j] = prev_row[j - 1] + prev_row[j];
    }
    row[i] = 1;

    rows_.push_back(row);
  }
}

}  // namespace SOLUTION_NAMESPACE::detail
</code></pre>
<h2><a class="header" href="#reviews-8" id="reviews-8">Reviews</a></h2>
<p>None. This solution was created by arh to show the effect of minimizing memory
allocations and maximising cache coherency.</p>
<h1><a class="header" href="#pascalstrianglefor" id="pascalstrianglefor">pascalsTriangle.for</a></h1>
<pre><code class="language-shell">C
C develop.for						       Version 1.0
C	Paul Kyberd						       20 May 2020
C 
C     Version 1.0     Main routine to drive the building and display of
C                     the triangle
C
C   V1.0      Call the build function and then print it out
C
	
      program pascalsTriangle

      real	version/1.0/
      integer	flag, element

      write (6,2000) version
2000  format(' Programme to create Pascals triangle:: version  ', 
     +  F4.2)

      flag = triangleMake(8)
      if (flag .LT. 0) write(6,3000) flag
3000  format(1x,'triangle build error: return flag ',i4)

      call trianglePrint()

      element = triangleElement(5,3)
      write(6,2010) element
2010  format(1x, &quot;element is &quot;, i6)

      flag = triangleMake(1)
      if (flag .LT. 0) write(6,3000) flag
      call trianglePrint()

      flag = triangleMake(5)
      if (flag .LT. 0) write(6,3000) flag
      call trianglePrint()

      flag = triangleMake(0)
      if (flag .LT. 0) write(6,3000) flag
      call trianglePrint()

      end program pascalsTriangle
C
C  =======================================================================
C
      function triangleMake(rows)
C
C  Version 1.0        Paul Kyberd         10 May 2020
C  
C  V1.0          Create pascal's triangle with a given number of rows  
C
C   Call:    triangleMake(number of rows of the triangle)
C            number of rows must be greater than zero and less than 100.
C            by editting the store array the maximum size can be increased
C
C   Return:  0    success
C            -1   fail
C
C   builds a triangle in a two dimensional array - this array is then passed
C   between the functions and subroutines to allow access to the data structure
C   allow pseudo OO encapsulation in a non OO language
C
       common / pt / pRows, store(100,100)
       integer pRows, store

       integer rows
       
       write (6,2010) rows
2010   format(&quot; number of rows is &quot;, i4)
       pRows = rows

       if (rows .GT. 100) then
         write (6, 3000) rows
3000     format(1x, 'Number of rows ', i4, ' exceeds limits of 100')
         triangleMaker = -10
         return
      endif

C  In fortran 77 arrays are not initialised - elements contain random values
C  and need initialising modern compilers fill with zeros. Since we can't create
C  a new instance of the triangle, this is required to reset the initial conditions
C  when a second or subsequent triangle is created

      do MI=1, pRows
        do MJ = 1, pRows
          store(MI, MJ) = 0
        enddo
      enddo

C
      store(2,2) = 1 
      do MI = 3, rows+1
        nEntries = nEntries + 1
        do MJ = 2, rows+1
          store(MI, MJ) = store(MI-1, MJ-1) + store(MI-1, MJ)
        enddo
      enddo

C
      triangleMake = 0
      return 
      end function triangleMake
C
C =========================================================
C
      function triangleElement(row, column)
C
C  Version 1.0        Paul Kyberd         10 May 2020
C  
C  V1.0       Print out a particular element in terms of rows and
C             columns. Check for a legal value
C      
C   Call:    trianglePrint() - must have already called triangleMake
C
C   Return:  &gt;0       requested element returned
C            -1       illegal value of row or column
C

      common / pt / pRows, store(100,100)
      integer pRows, store

      integer row, column

      if ((row .LE. 0) .OR. (row .GT. pRows)) then
        write (6,3000)
3000    format(1x,'Number of row illegal')
        triangleElement = -1
        return
      else if ((column .LE. pRows) .OR. (column .GT. pRows)) then
        write (6,3010)
3010    format(1x,'Number of column illegal')
        triangleElement = -1
        return
       endif

      triangleElement = store(row+1, column+1)
      return

      end function

C
C =========================================================
C
      subroutine trianglePrint()
C
C  V1.0          Print out the pascal's triangle that has been created  
C
C   Call:    trianglePrint() - must have already called triangleMake
C
C   Return:  none
C
C   prints out the &quot;interesting part of the structure&quot;
C   access to the data via the named common block

      common / pt / pRows, store(100,100)
      integer  pRows, store


      write (6,2000)
2000  format(1x,'Pascals triangle')

      do MI=2, pRows+1
        do MJ=2, pRows+1
          write(6,2010) store(MI, MJ)
2010      format (1x, I6, $)
          if (store(MI, MJ+1) .EQ. 0) then
            exit
          endif
        enddo
        write (6,2020)
2020    format()
      enddo

      write (6,2030)
2030  format('end')
      return
      end subroutine trianglePrint
C
C  ======================================
C  
C  Notes:
C   the print routine is to show that the triangle has been created
C   there is no way to produce the data structure required in fortran 77
C   triangleElement(row, Column) allows you to access a particular element
C   of the triangle and effectively encapsulates the data (although don't
C   let a fortran programmer use the word!) A similar function could be
C   used to return a whole row
</code></pre>
<h2><a class="header" href="#authors-comments" id="authors-comments">Author's comments</a></h2>
<blockquote>
<p>Here is a fortran solution - it is compiled with the gcc compiler.</p>
<pre><code class="language-bash">gfortran -o PT pascalsTriangle.for
</code></pre>
<p>It is just in F77 you only have a DO ... enddo and a Do While - the ability to iterate over
an existing structure was certainly not there. Because you can do that you don't need
to check for the zero. I can't iterate over a limited set of values and so need to find
a way to check when the structure is essentially filled - which I do with the zero.</p>
<p>Starting from a square array I was enamoured of the fact you could use zeros to delimit the interesting size.
Lesson: your target language can affect the way you approach the problem and I immediately put the data in a square array. </p>
<p>So the only reason for submitting mine - apart from a piece of fossilised code is
to make the point that framing the problem in terms of the target language is likely
to limit the range of algorithms you consider.</p>
<p>The main routine simply acts as the driving routine, which is the test harness
in the C++ programme.</p>
<p>triangleMake - is the algorithm which makes the triangle in a standard 2d array.
so at the end of that there is an array which looks like</p>
<pre><code class="language-shell">0     0     0     0     0     0  ...
0     1     0     0     0     0  ...
0     1     1     0     0     0  ...
0     1     2     1     0     0  ...
...
</code></pre>
<p>The array is 100 by 100, there is no way to create a sized data structure in F77
indeed no way of creating anything but an array.</p>
<p>So this if you like is the generating algorithm.</p>
<p>trianglePrint  - then scans this array and prints out the actual triangle as</p>
<pre><code class="language-shell">1
1   1
1   2   1
1   3   3   1
etc
</code></pre>
<p>if you look it prints nothing if the triangle with no rows is requested and note
nowhere do I treat 0 rows as a special case - quite proud of that.
The code thus far could be ported pretty much line be line to C++</p>
<p>If instead of printing out the value you created the data structure an element
at a time, this would actually solve the problem as set. so replace lines
164 and 165 by something to fill the data structure.</p>
<p>I don't think I will do the translation into C++ - just noticed</p>
<p>Algorithm relies on filling a 2d array of suitable size - this can be smaller
than than the 100 by 100 I used if you can create memory structures on
the fly. It must be at least 1 more row and 2 more columns than the triangle
you need to create. Columns in fortran start at 1 and this is the convention
I am using</p>
<p>The elements of the array need to be zeroed. Then the second row and
second column is set to 1. Then starting at row three every column from
column 2 onward is filled by adding the same column from the row above
and the previous column from the row above. This is repeated until the
sum is equal to zero. Then the row is complete and the next row
is started.
The print starts every row at column 2 and starts at row 2 and continues
along the row until it finds zero, which it doesn't print - because it starts
at row 2 and loops until the size of pascal's triangle + 1, it never loops
for size of 0 and thus there is no output as required.</p>
<p>Fun problem - thinking back to fortran usually makes me nostalgic, but this
problem makes the point, that the lack of data structures in the language is
a real pain</p>
</blockquote>
<h1><a class="header" href="#groovyzone-1" id="groovyzone-1">GroovyZone</a></h1>
<h4><a class="header" href="#header-9" id="header-9">Header</a></h4>
<pre><code class="language-c++">#pragma once

#include &lt;cstdint&gt;
#include &lt;vector&gt;

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

/**
 * Inspired by Marshall Clow
 * https://www.youtube.com/watch?v=h4Jl1fk3MkQ
 */
template &lt;typename ForwardIter, typename Func&gt;
void adjacent_pair(ForwardIter first, ForwardIter last, Func f) {
  if (first != last) {
    ForwardIter trailer = first;
    ++first;
    for (; first != last; ++first, ++trailer) {
      f(*trailer, *first);
    }
  }
}

auto generate_rows(uint32_t num_rows) -&gt; std::vector&lt;std::vector&lt;uint64_t&gt;&gt;;

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h4><a class="header" href="#source-9" id="source-9">Source</a></h4>
<pre><code class="language-c++">#include &lt;cstdint&gt;
#include &lt;vector&gt;

#include SOLUTION_HEADER

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

auto generate_rows(uint32_t num_rows) -&gt; std::vector&lt;std::vector&lt;uint64_t&gt;&gt; {
  std::vector&lt;std::vector&lt;uint64_t&gt;&gt; rows(num_rows);
  for (auto row = rows.begin(); row != rows.end(); ++row) {
    *row = std::vector&lt;uint64_t&gt;(
        1u + static_cast&lt;size_t&gt;(std::distance(rows.begin(), row)));
    row-&gt;front() = 1u;
    row-&gt;back() = 1u;
  }

  if (num_rows &lt; 3) {  // no internal elements to process
    return rows;
  }

  for (auto row = rows.begin() + 2; row != rows.end(); ++row) {
    const auto previous_row = row - 1;
    auto summed_entry = row-&gt;begin() + 1;

    adjacent_pair(previous_row-&gt;begin(), previous_row-&gt;end(),
                  [&amp;summed_entry](const auto trailer, const auto first) {
                    *summed_entry = trailer + first;
                    ++summed_entry;
                  });
  }

  return rows;
}

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h2><a class="header" href="#reviews-9" id="reviews-9">Reviews</a></h2>
<table style="float:left">
<thead>
<tr><th>How easy to understand?</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>A newcomer to C++ could grok it                </td><td></td></tr>
<tr><td>A junior dev should be fine with it            </td><td>XXX</td></tr>
<tr><td>Most devs would be comfortable                 </td><td>X</td></tr>
<tr><td>Experienced C++ developers only                </td><td>X</td></tr>
<tr><td>You'd need to be on the C++ standards committee</td><td></td></tr>
</tbody>
<thead>
<tr><th>Maintainability</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>Wouldn't touch it with a barge pole                         </td><td>X</td></tr>
<tr><td>I could manage it I had to, but would worry I might break it</td><td>XX</td></tr>
<tr><td>No problem at all                                           </td><td>XX</td></tr>
</tbody>
<thead>
<tr><th>Performance compared to simple nested loop and vectors</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>Much worse</td><td></td></tr>
<tr><td>A bit worse</td><td></td></tr>
<tr><td>About the same</td><td>XXX</td></tr>
<tr><td>A bit faster</td><td>XX</td></tr>
<tr><td>Warp factor 9</td><td></td></tr>
</tbody>
<thead>
<tr><th>New things learned</th><th></th></tr>
</thead>
<tbody>
<tr><td>I like the use of the adjacent_pair helper function</td><td></td></tr>
<tr><td>Meaning of 1u</td><td></td></tr>
</tbody>
<thead>
<tr><th>Comments</th><th></th></tr>
</thead>
<tbody>
<tr><td>Not elegant, but took me around 1/3 of the time to understand whats happening</td><td></td></tr>
<tr><td>The idea is understandable, but it might be a bit tricky to follow (or maintain) the various iterators used.</td><td></td></tr>
</tbody>
</table>
<h1><a class="header" href="#lordvader-1" id="lordvader-1">LordVader</a></h1>
<h4><a class="header" href="#header-10" id="header-10">Header</a></h4>
<pre><code class="language-c++">#pragma once

#include &lt;cstdint&gt;
#include &lt;vector&gt;

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

auto generate_rows(uint32_t num_rows) -&gt; std::vector&lt;std::vector&lt;uint64_t&gt;&gt;;

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h4><a class="header" href="#source-10" id="source-10">Source</a></h4>
<pre><code class="language-c++">#include &lt;cassert&gt;
#include &lt;cstdint&gt;
#include &lt;functional&gt;
#include &lt;numeric&gt;
#include &lt;vector&gt;

#include SOLUTION_HEADER

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

namespace {

auto generate_next_row(std::vector&lt;uint64_t&gt; const&amp; last_row)
    -&gt; std::vector&lt;uint64_t&gt; {
  std::vector&lt;uint64_t&gt; new_row;
  new_row.reserve(last_row.size() + 1);

  // Find the pairwise sums of the elements in the last row and add to the new row.
  std::adjacent_difference(std::cbegin(last_row), std::cend(last_row),
                           std::back_inserter(new_row), std::plus&lt;&gt;{});
  new_row.push_back(1);  // Add final 1.

  return new_row;
};

}  // namespace

auto generate_rows(uint32_t num_rows) -&gt; std::vector&lt;std::vector&lt;uint64_t&gt;&gt; {
  assert(num_rows &gt;= 0);

  if (num_rows == 0) {
    return {};
  }

  auto rows = std::vector&lt;std::vector&lt;uint64_t&gt;&gt;{{1}};
  rows.reserve(num_rows);

  for (uint32_t i = 1; i &lt; num_rows; ++i) {
    rows.push_back(generate_next_row(rows[i - 1]));
  }

  return rows;
}

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h2><a class="header" href="#reviews-10" id="reviews-10">Reviews</a></h2>
<table style="float:left">
<thead>
<tr><th>How easy to understand?</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>A newcomer to C++ could grok it                </td><td></td></tr>
<tr><td>A junior dev should be fine with it            </td><td>XXX</td></tr>
<tr><td>Most devs would be comfortable                 </td><td>X</td></tr>
<tr><td>Experienced C++ developers only                </td><td></td></tr>
<tr><td>You'd need to be on the C++ standards committee</td><td></td></tr>
</tbody>
<thead>
<tr><th>Maintainability</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>Wouldn't touch it with a barge pole                         </td><td></td></tr>
<tr><td>I could manage it I had to, but would worry I might break it</td><td></td></tr>
<tr><td>No problem at all                                           </td><td>XXXX</td></tr>
</tbody>
<thead>
<tr><th>Performance compared to simple nested loop and vectors</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>Much worse</td><td></td></tr>
<tr><td>A bit worse</td><td></td></tr>
<tr><td>About the same</td><td>XXXX</td></tr>
<tr><td>A bit faster</td><td></td></tr>
<tr><td>Warp factor 9</td><td></td></tr>
</tbody>
<thead>
<tr><th>New things learned</th><th></th></tr>
</thead>
<tbody>
<tr><td>adjacent_difference (c++17)</td><td></td></tr>
</tbody>
<thead>
<tr><th>Comments</th><th></th></tr>
</thead>
<tbody>
<tr><td>Nice use of adjacent_difference. The assert on .cpp:29 is always satisfied.</td><td></td></tr>
<tr><td>
<p>line 35:  Reserving after assigning is inefficient.   auto is not always better.</p>
<p>putting the inner loop in another function may be inefficient as the output is getting copied into the vector.  Consider moving the output</p>
<p>There may be some unnecessary memory allocation and copying in this solution.</p>
</td><td></td></tr>
<tr><td>*using adjacent difference is nice.</br>
*the assert is redundant as input is an unsigned int and asserts make me sad</br>
*the way rows are placed on the triangle could be more efficient using emplace_back and returning a vector from the row-makes seems expensive. could pass a const and non const reference instead</br>
* no check for overflow when n becomes large its going to overflow.</td><td></td></tr>
</tbody>
</table>
<h1><a class="header" href="#lordvader2_arh-1" id="lordvader2_arh-1">LordVader2_arh</a></h1>
<h4><a class="header" href="#header-11" id="header-11">Header</a></h4>
<pre><code class="language-c++">#pragma once

#include &lt;cstdint&gt;
#include &lt;vector&gt;

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

auto generate_rows(uint32_t num_rows) -&gt; std::vector&lt;std::vector&lt;uint64_t&gt;&gt;;

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h4><a class="header" href="#source-11" id="source-11">Source</a></h4>
<pre><code class="language-c++">#include &lt;cassert&gt;
#include &lt;cstdint&gt;
#include &lt;functional&gt;
#include &lt;numeric&gt;
#include &lt;vector&gt;

#include SOLUTION_HEADER

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

namespace {

auto generate_next_row(std::vector&lt;uint64_t&gt; const&amp; last_row)
    -&gt; std::vector&lt;uint64_t&gt; {
  std::vector&lt;uint64_t&gt; new_row(last_row.size() + 1);

  // Find the pairwise sums of the elements in the last row and add to the new row.
  std::adjacent_difference(std::cbegin(last_row), std::cend(last_row),
                           std::begin(new_row), std::plus&lt;&gt;{});
  new_row.back() = 1;  // Add final 1

  return new_row;
};

}  // namespace

auto generate_rows(uint32_t num_rows) -&gt; std::vector&lt;std::vector&lt;uint64_t&gt;&gt; {
  if (num_rows == 0) {
    return {};
  }

  auto rows = std::vector&lt;std::vector&lt;uint64_t&gt;&gt;();
  rows.reserve(num_rows);

  rows.emplace_back(1, 1);
  for (uint32_t i = 1; i &lt; num_rows; ++i) {
    rows.push_back(generate_next_row(rows[i - 1]));
  }

  return rows;
}

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h2><a class="header" href="#reviews-11" id="reviews-11">Reviews</a></h2>
<p>None. This is a modified version of <a href="solutions/./LordVader.html">LordVader</a> created by arh.</p>
<h1><a class="header" href="#pixelf-1" id="pixelf-1">Pixelf</a></h1>
<h4><a class="header" href="#header-12" id="header-12">Header</a></h4>
<pre><code class="language-c++">#pragma once

#include &lt;cstdint&gt;
#include &lt;vector&gt;

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

auto generate_rows(uint32_t num_rows) -&gt; std::vector&lt;std::vector&lt;uint64_t&gt;&gt;;

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h4><a class="header" href="#source-12" id="source-12">Source</a></h4>
<pre><code class="language-c++">#include &lt;cstdint&gt;
#include &lt;future&gt;
#include &lt;vector&gt;

#include SOLUTION_HEADER

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

const int MAXIMUM_PASCAL_ROWS_FOR_64_BIT_ARCH = 63;

void FillRowN(std::vector&lt;uint64_t&gt;&amp; row, uint32_t n) {
  row.resize(n);
  *row.begin() = 1;
  for (uint32_t k = 1; k &lt; n / 2 + 1; ++k) {  //loop noting symmetry
    row[k] = (row[k - 1] * (n - k)) / k;      //leverage recursive nature of nCk
  }
  std::copy(row.begin(), row.begin() + n / 2, row.rbegin());
}

void FillRowsInParallel(std::vector&lt;std::vector&lt;uint64_t&gt;&gt;&amp; rows,
                        uint32_t n_rows) {
  rows.resize(n_rows);
  std::vector&lt;std::future&lt;void&gt;&gt; futures;
  for (uint32_t i = 0; i &lt; n_rows; ++i) {
    futures.emplace_back(std::async(FillRowN, std::ref(rows[i]), i + 1));
  }

  for (auto&amp; f : futures) {
    f.get();
  }
}

auto generate_rows(uint32_t num_rows) -&gt; std::vector&lt;std::vector&lt;uint64_t&gt;&gt; {
  std::vector&lt;std::vector&lt;uint64_t&gt;&gt; rows;
  if (num_rows == 0) {
    return rows;
  } else if (num_rows &gt; MAXIMUM_PASCAL_ROWS_FOR_64_BIT_ARCH) {
    throw std::runtime_error(&quot;out of range for 64 bit architecture&quot;);
  } else {
    FillRowsInParallel(rows, num_rows);  //and we dont need a pyramid
  }
  return rows;
}

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h2><a class="header" href="#reviews-12" id="reviews-12">Reviews</a></h2>
<table style="float:left">
<thead>
<tr><th>How easy to understand?</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>A newcomer to C++ could grok it                </td><td></td></tr>
<tr><td>A junior dev should be fine with it            </td><td>X</td></tr>
<tr><td>Most devs would be comfortable                 </td><td>XX</td></tr>
<tr><td>Experienced C++ developers only                </td><td>X</td></tr>
<tr><td>You'd need to be on the C++ standards committee</td><td></td></tr>
</tbody>
<thead>
<tr><th>Maintainability</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>Wouldn't touch it with a barge pole                         </td><td>X</td></tr>
<tr><td>I could manage it I had to, but would worry I might break it</td><td></td></tr>
<tr><td>No problem at all                                           </td><td>XXX</td></tr>
</tbody>
<thead>
<tr><th>Performance compared to simple nested loop and vectors</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>Much worse</td><td>X</td></tr>
<tr><td>A bit worse</td><td>X</td></tr>
<tr><td>About the same</td><td></td></tr>
<tr><td>A bit faster</td><td></td></tr>
<tr><td>Warp factor 9</td><td>XX</td></tr>
</tbody>
<thead>
<tr><th>New things learned</th><th></th></tr>
</thead>
<tbody>
<tr><td>I don't have much experience writing threaded C++ code, so this was a good example. I also didn't think of limiting the maximum number of rows.</td><td></td></tr>
<tr><td>Properties of pascal's triangle</td><td></td></tr>
<tr><td>The formula for row calculation independent of preceding rows</td><td></td></tr>
<tr><td>A closed form solution for generating triangular numbers</td><td></td></tr>
</tbody>
<thead>
<tr><th>Comments</th><th></th></tr>
</thead>
<tbody>
<tr><td>Pretty straightforward and efficient, no need to overcomplicate the problem :)</td><td></td></tr>
<tr><td>
<p>std::async is flawed.  It runs the first N jobs in parallel, then runs the rest sequentially, unless you specifically ask it to create a new thread for every iteration.  Starting a new thread carries a large overhead.  It does NOT use a pool.</p>
<p>The overall cost is the cost of the longest row, which is N multiplies.  This is a lot slower than N adds.    As the multiplies are sequential, they cannot use SIMD instructions.  In the reference solution, the whole row adds would mostly be done in big chunks.</p>
<p>micro-threading is usually a bad idea.   If anything use OpenMP for this.</p>
</td><td></td></tr>
<tr><td>Not sure of the performance implications of potentially many futures. Could use a work-stealing setup with an atomic int for threads to grab the next available row, and signal when there's no more work. Would only require waiting on (num threads) signals.</td><td></td></tr>
<tr><td>This won't actually use async behaviour because they haven't set the std::async policy to std::launch::async - I believe the default is deferred so the new thread won't be started until 
the get is called which torpedos any multithreaded benefit as written</td><td></td></tr>
</tbody>
</table>
<h1><a class="header" href="#pixelf_tbb_arh" id="pixelf_tbb_arh">Pixelf_TBB_arh</a></h1>
<h4><a class="header" href="#header-13" id="header-13">Header</a></h4>
<pre><code class="language-c++">#pragma once

#include &lt;cstdint&gt;
#include &lt;vector&gt;

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

auto generate_rows(uint32_t num_rows) -&gt; std::vector&lt;std::vector&lt;uint64_t&gt;&gt;;

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h4><a class="header" href="#source-13" id="source-13">Source</a></h4>
<pre><code class="language-c++">#include SOLUTION_HEADER

#include &lt;tbb/tbb.h&gt;

#include &lt;cstdint&gt;
#include &lt;vector&gt;

using namespace tbb;

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

void FillRowN(std::vector&lt;uint64_t&gt;&amp; row, uint32_t n) {
  row.resize(n);
  *row.begin() = 1;
  for (uint32_t k = 1; k &lt; n / 2 + 1; ++k) {  //loop noting symmetry
    row[k] = (row[k - 1] * (n - k)) / k;      //leverage recursive nature of nCk
  }
  std::copy(row.begin(), row.begin() + n / 2, row.rbegin());
}

void FillRowBlock(std::vector&lt;std::vector&lt;uint64_t&gt;&gt;&amp; rows,
                  const blocked_range&lt;uint32_t&gt;&amp; r) {
  for (auto i = r.begin(); i &lt; r.end(); ++i) {
    FillRowN(rows[i], i + 1);
  }
}

auto generate_rows(uint32_t num_rows) -&gt; std::vector&lt;std::vector&lt;uint64_t&gt;&gt; {
  std::vector&lt;std::vector&lt;uint64_t&gt;&gt; rows(num_rows);
  if (num_rows == 0) {
    return rows;
  }

  {
    parallel_for(blocked_range&lt;uint32_t&gt;(0, num_rows),
                 [&amp;rows](auto const&amp; r) { FillRowBlock(rows, r); });
  }
  return rows;
}

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h2><a class="header" href="#reviews-13" id="reviews-13">Reviews</a></h2>
<p>None. This is a modified version of <a href="solutions/./Pixelf.html">Pixelf</a> created by arh.</p>
<h1><a class="header" href="#pixelf_tbb_scalable_alloc_arh" id="pixelf_tbb_scalable_alloc_arh">Pixelf_TBB_scalable_alloc_arh</a></h1>
<h2><a class="header" href="#benchmark-note" id="benchmark-note">Benchmark note</a></h2>
<p>The memory benchmarks for this solution are not correct, as the memory
benchmarking mechanism does not track allocations made by the TBB allocators.</p>
<h4><a class="header" href="#header-14" id="header-14">Header</a></h4>
<pre><code class="language-c++">#pragma once

#include &lt;tbb/scalable_allocator.h&gt;

#include &lt;cstdint&gt;
#include &lt;vector&gt;

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

template &lt;typename T&gt;
using scalable_vec = std::vector&lt;T, tbb::scalable_allocator&lt;uint64_t&gt;&gt;;

auto generate_rows(uint32_t num_rows) -&gt; std::vector&lt;scalable_vec&lt;uint64_t&gt;&gt;;

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h4><a class="header" href="#source-14" id="source-14">Source</a></h4>
<pre><code class="language-c++">#include SOLUTION_HEADER

#include &lt;tbb/tbb.h&gt;

#include &lt;cstdint&gt;
#include &lt;future&gt;
#include &lt;vector&gt;

using namespace tbb;

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

void FillRowN(scalable_vec&lt;uint64_t&gt;&amp; row, uint32_t n) {
  row.resize(n);
  *row.begin() = 1;
  for (uint32_t k = 1; k &lt; n / 2 + 1; ++k) {  //loop noting symmetry
    row[k] = (row[k - 1] * (n - k)) / k;      //leverage recursive nature of nCk
  }
  std::copy(row.begin(), row.begin() + n / 2, row.rbegin());
}

void FillRowBlock(std::vector&lt;scalable_vec&lt;uint64_t&gt;&gt;&amp; rows,
                  const blocked_range&lt;uint32_t&gt;&amp; r) {
  for (auto i = r.begin(); i &lt; r.end(); ++i) {
    FillRowN(rows[i], i + 1);
  }
}

auto generate_rows(uint32_t num_rows) -&gt; std::vector&lt;scalable_vec&lt;uint64_t&gt;&gt; {
  std::vector&lt;scalable_vec&lt;uint64_t&gt;&gt; rows(num_rows);
  if (num_rows == 0) {
    return rows;
  } else {
    parallel_for(blocked_range&lt;uint32_t&gt;(0, num_rows),
                 [&amp;rows](auto const&amp; r) { FillRowBlock(rows, r); });
  }
  return rows;
}

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h2><a class="header" href="#reviews-14" id="reviews-14">Reviews</a></h2>
<p>None. This is a modified version of <a href="solutions/./Pixelf.html">Pixelf</a> created by arh.</p>
<h1><a class="header" href="#pixelf_tbb_boost_arh" id="pixelf_tbb_boost_arh">Pixelf_TBB_boost_arh</a></h1>
<h4><a class="header" href="#header-15" id="header-15">Header</a></h4>
<pre><code class="language-c++">#pragma once

#include &lt;boost/container/pmr/monotonic_buffer_resource.hpp&gt;
#include &lt;boost/container/pmr/vector.hpp&gt;
#include &lt;cstdint&gt;
#include &lt;vector&gt;

namespace SOLUTION_NAMESPACE {  // Please do not modify this line
namespace pmr = boost::container::pmr;

class pascals_triangle {
  pmr::monotonic_buffer_resource res_;
  std::vector&lt;pmr::vector&lt;uint64_t&gt;&gt; rows_;

 public:
  pascals_triangle(uint32_t num_rows);

  auto begin() const noexcept { return rows_.begin(); }
  auto end() const noexcept { return rows_.end(); }
};

inline auto generate_rows(uint32_t num_rows) -&gt; pascals_triangle {
  return pascals_triangle(num_rows);
}

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h4><a class="header" href="#source-15" id="source-15">Source</a></h4>
<pre><code class="language-c++">#include SOLUTION_HEADER

#include &lt;tbb/tbb.h&gt;

#include &lt;algorithm&gt;
#include &lt;cstdint&gt;

using namespace tbb;

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

constexpr auto RowBeginIndex(uint64_t row) noexcept -&gt; uint64_t {
  return (row * (row + 1)) / 2;
}

void FillRowN(pmr::vector&lt;uint64_t&gt;&amp; row, uint32_t n) {
  row.resize(n);
  *row.begin() = 1;
  for (uint32_t k = 1; k &lt; n / 2 + 1; ++k) {  //loop noting symmetry
    row[k] = (row[k - 1] * (n - k)) / k;      //leverage recursive nature of nCk
  }
  std::copy(row.begin(), row.begin() + n / 2, row.rbegin());
}

void FillRowBlock(std::vector&lt;pmr::vector&lt;uint64_t&gt;&gt;&amp; rows,
                  const blocked_range&lt;uint32_t&gt;&amp; r) {
  for (auto i = r.begin(); i &lt; r.end(); ++i) {
    FillRowN(rows[i], i + 1);
  }
}

pascals_triangle::pascals_triangle(uint32_t num_rows)
    : res_(RowBeginIndex(num_rows) * sizeof(uint64_t)) {
  std::vector&lt;pmr::vector&lt;uint64_t&gt;&gt; rows(num_rows,
                                          pmr::vector&lt;uint64_t&gt;(&amp;res_));

  for (uint32_t i = 0; i &lt; num_rows; ++i) {
    rows[i].reserve(i + 1);
  }

  parallel_for(blocked_range&lt;uint32_t&gt;(0, num_rows),
               [&amp;rows](auto const&amp; r) { FillRowBlock(rows, r); });

  rows_ = std::move(rows);
}

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h2><a class="header" href="#reviews-15" id="reviews-15">Reviews</a></h2>
<p>None. This is a modified version of <a href="solutions/./Pixelf.html">Pixelf</a> created by arh.</p>
<h1><a class="header" href="#pixelf_tbb_monotonic_alloc_arh" id="pixelf_tbb_monotonic_alloc_arh">Pixelf_TBB_monotonic_alloc_arh</a></h1>
<h4><a class="header" href="#header-16" id="header-16">Header</a></h4>
<pre><code class="language-c++">#pragma once

#include &lt;pt/allocators.h&gt;

#include &lt;cstdint&gt;
#include &lt;vector&gt;

namespace pt {
template &lt;typename T&gt;
using vector = std::vector&lt;T, pt::MonotonicAllocator&lt;T&gt;&gt;;
}

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

class pascals_triangle {
  pt::MonotonicBufferResource res_;
  std::vector&lt;pt::vector&lt;uint64_t&gt;&gt; rows_;

 public:
  pascals_triangle(uint32_t num_rows);

  auto begin() const noexcept { return rows_.begin(); }
  auto end() const noexcept { return rows_.end(); }
};

inline auto generate_rows(uint32_t num_rows) -&gt; pascals_triangle {
  return pascals_triangle(num_rows);
}

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h4><a class="header" href="#source-16" id="source-16">Source</a></h4>
<pre><code class="language-c++">#include SOLUTION_HEADER

#include &lt;tbb/tbb.h&gt;

#include &lt;algorithm&gt;
#include &lt;cstdint&gt;

using namespace tbb;

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

constexpr auto RowBeginIndex(uint64_t row) noexcept -&gt; uint64_t {
  return (row * (row + 1)) / 2;
}

void FillRowN(pt::vector&lt;uint64_t&gt;&amp; row, uint32_t n) {
  row.resize(n);
  row[0] = 1;
  for (uint32_t k = 1; k &lt; n / 2 + 1; ++k) {  //loop noting symmetry
    row[k] = (row[k - 1] * (n - k)) / k;      //leverage recursive nature of nCk
  }
  std::copy(row.begin(), row.begin() + n / 2, row.rbegin());
}

void FillRowBlock(std::vector&lt;pt::vector&lt;uint64_t&gt;&gt;&amp; rows,
                  const blocked_range&lt;uint32_t&gt;&amp; r) {
  for (auto i = r.begin(); i &lt; r.end(); ++i) {
    FillRowN(rows[i], i + 1);
  }
}

pascals_triangle::pascals_triangle(uint32_t num_rows)
    : res_(RowBeginIndex(num_rows) * sizeof(uint64_t)) {

  auto rows =
      std::vector&lt;pt::vector&lt;uint64_t&gt;&gt;(num_rows, pt::vector&lt;uint64_t&gt;(&amp;res_));
  for (uint32_t i = 0; i &lt; num_rows; ++i) {
    rows[i].reserve(i + 1);
  }

  parallel_for(blocked_range&lt;uint32_t&gt;(0, num_rows),
               [&amp;rows](auto const&amp; r) { FillRowBlock(rows, r); });

  rows_ = std::move(rows);
}

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h4><a class="header" href="#source-of-ancillary-ptallocatorsh-header" id="source-of-ancillary-ptallocatorsh-header">Source of ancillary <code>pt/allocators.h</code> header</a></h4>
<pre><code class="language-c++">// MonotonicAllocator is an extremely simple allocator for use with vectors of
// known size, that never need to resize. You can use it to ensure that
// objects sharing this allocator have contiguous memory allocations.
//
// It grabs a buffer of memory up-front and simply hands out contiguous chunks.
// When the pool is exhausted, the allocator throws std::bad_alloc.
// When allocated chunks are returned, they are never reused.
// This allocator is not thread safe, and should not go even remotely near any
// production code.

#pragma once

#include &lt;cstdlib&gt;
#include &lt;new&gt;
#include &lt;utility&gt;

namespace pt {

// A ridiculously minimal implementation of C++17's
// std::pmr::monotonic_buffer_resource. If you have alignment requirements then
// look elsewhere.
class MonotonicBufferResource {
  char* begin_;
  char* end_;
  char* p_;

 public:
  explicit MonotonicBufferResource(std::size_t size)
      : begin_(static_cast&lt;char*&gt;(::operator new(size))),
        end_(begin_ + size),
        p_(begin_) {}
  ~MonotonicBufferResource() { ::operator delete(begin_); };

  MonotonicBufferResource(MonotonicBufferResource const&amp;) = delete;
  MonotonicBufferResource&amp; operator=(MonotonicBufferResource const&amp;) = delete;

  void* allocate(std::size_t num_bytes) {
    auto p = p_ + num_bytes;
    if (p &gt; end_) {
      throw std::bad_alloc();
    }

    return std::exchange(p_, p);
  }

  void deallocate(void*) {}
};

template &lt;typename T&gt;
class MonotonicAllocator {
  MonotonicBufferResource* res_;

 public:
  using value_type = T;

  MonotonicAllocator(MonotonicBufferResource* res) : res_(res) {}

  MonotonicBufferResource* get_resource() const noexcept { return res_; }

  value_type* allocate(std::size_t num_objects) {
    return static_cast&lt;value_type*&gt;(
        res_-&gt;allocate(sizeof(value_type) * num_objects));
  }

  void deallocate(void* p, std::size_t) { res_-&gt;deallocate(p); }
};

template &lt;typename T, typename U&gt;
bool operator==(MonotonicAllocator&lt;T&gt; const&amp; x,
                MonotonicAllocator&lt;U&gt; const&amp; y) noexcept {
  return x.get_resource() == y.get_resource();
}

template &lt;typename T, typename U&gt;
bool operator!=(MonotonicAllocator&lt;T&gt; const&amp; x,
                MonotonicAllocator&lt;U&gt; const&amp; y) noexcept {
  return !(x == y);
}

}  // namespace pt
</code></pre>
<h2><a class="header" href="#reviews-16" id="reviews-16">Reviews</a></h2>
<p>None. This is a modified version of <a href="solutions/./Pixelf.html">Pixelf</a> created by arh.</p>
<h1><a class="header" href="#pixelf_tbb_single_array_arh" id="pixelf_tbb_single_array_arh">Pixelf_TBB_single_array_arh</a></h1>
<h4><a class="header" href="#header-17" id="header-17">Header</a></h4>
<pre><code class="language-c++">#pragma once

#include &lt;pt/iterators.h&gt;

#include &lt;cstdint&gt;
#include &lt;memory&gt;

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

namespace detail {

constexpr inline auto RowBeginIndex(uint64_t row) noexcept -&gt; uint64_t {
  return (row * (row + 1)) / 2;
}

auto BuildLookupTable(uint32_t num_rows) -&gt; std::unique_ptr&lt;uint64_t[]&gt;;
}  // namespace detail

class pascals_triangle {
  std::unique_ptr&lt;uint64_t[]&gt; values_;
  uint32_t num_rows_;

 public:
  pascals_triangle(uint32_t num_rows)
      : values_(detail::BuildLookupTable(num_rows)), num_rows_(num_rows) {}

  using cursor = pt::contiguous_row_cursor;
  using iterator = pt::contiguous_row_iterator;

  auto begin() const noexcept -&gt; iterator {
    return iterator(cursor(values_.get()));
  }

  auto end() const noexcept -&gt; iterator {
    return iterator(cursor(values_.get() + detail::RowBeginIndex(num_rows_)));
  }
};

inline auto generate_rows(uint32_t num_rows) -&gt; pascals_triangle {
  return pascals_triangle(num_rows);
}

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h4><a class="header" href="#source-17" id="source-17">Source</a></h4>
<pre><code class="language-c++">#include SOLUTION_HEADER

#include &lt;tbb/tbb.h&gt;

#include &lt;cstdint&gt;
#include &lt;memory&gt;

using namespace tbb;
using namespace SOLUTION_NAMESPACE;

namespace {
void FillRowN(uint64_t* row, uint32_t n) {
  row[0] = 1;
  for (uint32_t k = 1; k &lt; n / 2 + 1; ++k) {  //loop noting symmetry
    row[k] = (row[k - 1] * (n - k)) / k;      //leverage recursive nature of nCk
  }
  std::copy(row, row + n / 2, std::reverse_iterator(row + n));
}

void FillRowBlock(uint64_t* values, const blocked_range&lt;uint32_t&gt;&amp; r) {
  auto* p = values + detail::RowBeginIndex(r.begin());
  for (auto i = r.begin(); i &lt; r.end(); ++i, p += i) {
    FillRowN(p, i + 1);
  }
}
}  // namespace

namespace SOLUTION_NAMESPACE::detail {
auto BuildLookupTable(uint32_t num_rows) -&gt; std::unique_ptr&lt;uint64_t[]&gt; {
  auto values = std::unique_ptr&lt;uint64_t[]&gt;(
      new uint64_t[detail::RowBeginIndex(num_rows)]);

  parallel_for(blocked_range&lt;uint32_t&gt;(0, num_rows),
               [p = values.get()](auto const&amp; r) { FillRowBlock(p, r); });
  return values;
}
}  // namespace SOLUTION_NAMESPACE::detail
</code></pre>
<h4><a class="header" href="#source-of-ancillary-ptiteratorsh-header" id="source-of-ancillary-ptiteratorsh-header">Source of ancillary <code>pt/iterators.h</code> header</a></h4>
<pre><code class="language-c++">#pragma once

#include &lt;range/v3/iterator/basic_iterator.hpp&gt;
#include &lt;range/v3/view/subrange.hpp&gt;

namespace pt {

// Provides the basic operations for iterating over the rows of pascals
// triangle, when the elements of every row are stored contiguously.
//
// The cursor is adapted into an STL-compliant iterator by
// ranges::basic_iterator.
class contiguous_row_cursor {
  using value_type = ranges::subrange&lt;uint64_t const*&gt;;
  value_type next_row_;

 public:
  contiguous_row_cursor() = default;
  explicit contiguous_row_cursor(uint64_t const* p) noexcept
      : next_row_(p, p + 1) {}
  value_type const&amp; read() const noexcept { return next_row_; }
  bool equal(contiguous_row_cursor const&amp; rhs) const noexcept {
    return next_row_.begin() == rhs.next_row_.begin();
  }
  void next() noexcept {
    auto const row_len = std::distance(next_row_.begin(), next_row_.end());
    next_row_ = value_type(next_row_.end(), next_row_.end() + row_len + 1);
  }
};

using contiguous_row_iterator = ranges::basic_iterator&lt;contiguous_row_cursor&gt;;

// Given a contiguous array of pascal's triangle elements, returns a range
// object which will iterate lazily over each of the rows in turn. This allows
// the elements to be accessed using a nested for loop, just as you would for a
// vector&lt;vector&lt;uint64_t&gt;&gt;
//
// Example:
// -----------------------------------------------------------------------------
// uint64_t const table[] = {1,1,1,1,2,1,1,3,3,1};
// auto rows = make_pascal_table_range(std::begin(table), std::end(table));
//
// // Prints the rows of the triangle
// for (auto const&amp; row : rows) {
//   for (uint64_t elem : row) {
//     std::cout &lt;&lt; elem &lt;&lt; &quot;,&quot;;
//   }
//   std::cout &lt;&lt; '\n';
// }
// -----------------------------------------------------------------------------
inline auto make_pascal_table_range(uint64_t const* first,
                                    uint64_t const* last) noexcept {
  using cursor = contiguous_row_cursor;
  using iterator = contiguous_row_iterator;
  return ranges::make_subrange(  //
      iterator(cursor(first)),   //
      iterator(cursor(last))     //
  );
}

}  // namespace pt
</code></pre>
<h2><a class="header" href="#reviews-17" id="reviews-17">Reviews</a></h2>
<p>None. This is a modified version of <a href="solutions/./Pixelf.html">Pixelf</a> created by arh.</p>
<h1><a class="header" href="#pixelf_tbb_spans_arh" id="pixelf_tbb_spans_arh">Pixelf_TBB_spans_arh</a></h1>
<h4><a class="header" href="#header-18" id="header-18">Header</a></h4>
<pre><code class="language-c++">#pragma once

#include &lt;cstdint&gt;
#include &lt;memory&gt;
#include &lt;range/v3/view/span.hpp&gt;
#include &lt;vector&gt;

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

namespace detail {
class PascalsTriangle {
  std::unique_ptr&lt;uint64_t[]&gt; values_;
  std::vector&lt;ranges::span&lt;uint64_t&gt;&gt; rows_;

 public:
  PascalsTriangle(uint32_t num_rows);

  auto begin() const { return rows_.cbegin(); }
  auto end() const { return rows_.cend(); }
};
}  // namespace detail

inline auto generate_rows(uint32_t num_rows) -&gt; detail::PascalsTriangle {
  return detail::PascalsTriangle(num_rows);
}

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h4><a class="header" href="#source-18" id="source-18">Source</a></h4>
<pre><code class="language-c++">#include SOLUTION_HEADER

#include &lt;tbb/tbb.h&gt;

#include &lt;cstdint&gt;
#include &lt;vector&gt;

using namespace tbb;

namespace {
constexpr auto row_begin_index(uint64_t row) noexcept -&gt; uint64_t {
  return (row * (row + 1)) / 2;
}

void FillRowN(ranges::span&lt;uint64_t&gt; row) {
  auto const n = static_cast&lt;uint32_t&gt;(row.size());
  row[0] = 1;
  for (uint32_t k = 1; k &lt; n / 2 + 1; ++k) {  //loop noting symmetry
    row[k] = (row[k - 1] * (n - k)) / k;      //leverage recursive nature of nCk
  }
  std::copy(row.begin(), row.begin() + n / 2, row.rbegin());
}

[[maybe_unused]] void FillRowBlock(std::vector&lt;ranges::span&lt;uint64_t&gt;&gt;&amp; rows,
                                   uint64_t* values,
                                   const blocked_range&lt;uint32_t&gt;&amp; r) {

  uint64_t* p = values + row_begin_index(r.begin());
  for (auto i = r.begin(); i &lt; r.end(); ++i, p += i) {
    auto row = ranges::span&lt;uint64_t&gt;(p, i + 1);
    FillRowN(row);
    rows[i] = row;
  }
}

}  // namespace

namespace SOLUTION_NAMESPACE::detail {

PascalsTriangle::PascalsTriangle(uint32_t num_rows) {
  if (num_rows == 0) {
    return;
  }

  auto values =
      std::unique_ptr&lt;uint64_t[]&gt;(new uint64_t[row_begin_index(num_rows)]);
  auto rows = std::vector&lt;ranges::span&lt;uint64_t&gt;&gt;(num_rows);

  parallel_for(
      blocked_range&lt;uint32_t&gt;(0, num_rows),
      [&amp;rows, &amp;values](auto const&amp; r) { FillRowBlock(rows, values.get(), r); });

  using std::swap;
  swap(values_, values);
  swap(rows_, rows);
}

}  // namespace SOLUTION_NAMESPACE::detail
</code></pre>
<h2><a class="header" href="#reviews-18" id="reviews-18">Reviews</a></h2>
<p>None. This is a modified version of <a href="solutions/./Pixelf.html">Pixelf</a> created by arh.</p>
<h1><a class="header" href="#digitalgerbil" id="digitalgerbil">DigitalGerbil</a></h1>
<h4><a class="header" href="#header-19" id="header-19">Header</a></h4>
<pre><code class="language-c++">#pragma once

#include &lt;cstdint&gt;
#include &lt;vector&gt;

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

auto generate_rows(uint32_t num_rows) -&gt; std::vector&lt;std::vector&lt;uint64_t&gt;&gt;;

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h4><a class="header" href="#source-19" id="source-19">Source</a></h4>
<pre><code class="language-c++">#include &lt;cstdint&gt;
#include &lt;vector&gt;

#include SOLUTION_HEADER

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

// solution inspired by https://github.com/AceLewis/my_first_calculator.py

auto generate_rows(uint32_t num_rows) -&gt; std::vector&lt;std::vector&lt;uint64_t&gt;&gt; {
  if (num_rows == 0) {
    return {};
  } else if (num_rows == 1) {
    return {{1}};
  } else if (num_rows == 2) {
    return {{1}, {1, 1}};
  } else if (num_rows == 3) {
    return {{1}, {1, 1}, {1, 2, 1}};
  } else if (num_rows == 4) {
    return {{1}, {1, 1}, {1, 2, 1}, {1, 3, 3, 1}};
  } else if (num_rows == 5) {
    return {{1}, {1, 1}, {1, 2, 1}, {1, 3, 3, 1}, {1, 4, 6, 4, 1}};
  } else if (num_rows == 6) {
    return {{1},          {1, 1},          {1, 2, 1},
            {1, 3, 3, 1}, {1, 4, 6, 4, 1}, {1, 5, 10, 10, 5, 1}};
  } else if (num_rows == 7) {
    return {{1},
            {1, 1},
            {1, 2, 1},
            {1, 3, 3, 1},
            {1, 4, 6, 4, 1},
            {1, 5, 10, 10, 5, 1},
            {1, 6, 15, 20, 15, 6, 1}};
  } else if (num_rows == 8) {
    return {{1},
            {1, 1},
            {1, 2, 1},
            {1, 3, 3, 1},
            {1, 4, 6, 4, 1},
            {1, 5, 10, 10, 5, 1},
            {1, 6, 15, 20, 15, 6, 1},
            {1, 7, 21, 35, 35, 21, 7, 1}};
  } else if (num_rows == 9) {
    return {{1},
            {1, 1},
            {1, 2, 1},
            {1, 3, 3, 1},
            {1, 4, 6, 4, 1},
            {1, 5, 10, 10, 5, 1},
            {1, 6, 15, 20, 15, 6, 1},
            {1, 7, 21, 35, 35, 21, 7, 1},
            {1, 8, 28, 56, 70, 56, 28, 8, 1}};
  } else if (num_rows == 10) {
    return {{1},
            {1, 1},
            {1, 2, 1},
            {1, 3, 3, 1},
            {1, 4, 6, 4, 1},
            {1, 5, 10, 10, 5, 1},
            {1, 6, 15, 20, 15, 6, 1},
            {1, 7, 21, 35, 35, 21, 7, 1},
            {1, 8, 28, 56, 70, 56, 28, 8, 1},
            {1, 9, 36, 84, 126, 126, 84, 36, 9, 1}};
  }

  return {};
}

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h2><a class="header" href="#reviews-19" id="reviews-19">Reviews</a></h2>
<table style="float:left">
<thead>
<tr><th>How easy to understand?</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>A newcomer to C++ could grok it                </td><td>XX</td></tr>
<tr><td>A junior dev should be fine with it            </td><td>X</td></tr>
<tr><td>Most devs would be comfortable                 </td><td></td></tr>
<tr><td>Experienced C++ developers only                </td><td></td></tr>
<tr><td>You'd need to be on the C++ standards committee</td><td></td></tr>
</tbody>
<thead>
<tr><th>Maintainability</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>Wouldn't touch it with a barge pole                         </td><td>X</td></tr>
<tr><td>I could manage it I had to, but would worry I might break it</td><td></td></tr>
<tr><td>No problem at all                                           </td><td>XX</td></tr>
</tbody>
<thead>
<tr><th>Performance compared to simple nested loop and vectors</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>Much worse</td><td></td></tr>
<tr><td>A bit worse</td><td></td></tr>
<tr><td>About the same</td><td></td></tr>
<tr><td>A bit faster</td><td>X</td></tr>
<tr><td>Warp factor 9</td><td>XX</td></tr>
</tbody>
<thead>
<tr><th>New things learned</th><th></th></tr>
</thead>
<tbody>
<tr><td>Hard coding answers can be fast but isn't very flexible.</td><td></td></tr>
<tr><td>Well cute, to at compile time give the whole triangle rather than rows (as another solution did) so if the tests represent the whole scope of the program (ie n<=9) is a specification this is pretty damn fast.</td><td></td></tr>
</tbody>
<thead>
<tr><th>Comments</th><th></th></tr>
</thead>
<tbody>
<tr><td>
<p>Definition of generate_rows would be better as `void(uint32_t const num_rows)` this is especially true when doing comparisons `num_rows == x` could lead to an accidental assignment. For the same reason it is better to do `x == num_rows`.</p>
<p>The result to generate_rows(x) where x > 10 will be wrong.</p>
<p>Copying the rows of the triangle is also error prone. In the style of this answer ti would perhaps be better to define constants for each row ...</p>
<pre><code class="language-c++">constexpr auto row1 = {1};
constexpr auto row2 = {1,2,1};
constexpr auto row3 = {1, 3, 3, 1};
constexpr auto rows123 = {row1, row2, row3};
</code></pre>
</td><td></td></tr>
<tr><td>I feel uncomfortable about baking in n<=9</td><td></td></tr>
</tbody>
</table>
<h1><a class="header" href="#terrificphantom" id="terrificphantom">TerrificPhantom</a></h1>
<h4><a class="header" href="#header-20" id="header-20">Header</a></h4>
<pre><code class="language-c++">#pragma once

#include &lt;cstdint&gt;
#include &lt;vector&gt;

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

auto generate_rows(uint32_t num_rows) -&gt; std::vector&lt;std::vector&lt;uint64_t&gt;&gt;;

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h4><a class="header" href="#source-20" id="source-20">Source</a></h4>
<pre><code class="language-c++">#include &lt;fmt/format.h&gt;

#include &lt;cmath&gt;
#include &lt;cstdint&gt;
#include &lt;iostream&gt;
#include &lt;stdexcept&gt;
#include &lt;vector&gt;

#include SOLUTION_HEADER

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

std::vector&lt;uint64_t&gt; get_row(uint32_t num_row) {
  if (num_row == 0)
    return {1};
  if (num_row == 1)
    return {1, 1};
  if (num_row == 2)
    return {1, 2, 1};
  if (num_row == 3)
    return {1, 3, 3, 1};
  if (num_row == 4)
    return {1, 4, 6, 4, 1};
  if (num_row == 5)
    return {1, 5, 10, 10, 5, 1};
  if (num_row == 6)
    return {1, 6, 15, 20, 15, 6, 1};
  if (num_row == 7)
    return {1, 7, 21, 35, 35, 21, 7, 1};
  if (num_row == 8)
    return {1, 8, 28, 56, 70, 56, 28, 8, 1};
  if (num_row == 9)
    return {1, 9, 36, 84, 126, 126, 84, 36, 9, 1};
  else
    throw std::invalid_argument(&quot;I wasn't thinking this far ahead...&quot;);
}

auto generate_rows(uint32_t num_rows) -&gt; std::vector&lt;std::vector&lt;uint64_t&gt;&gt; {

  std::vector&lt;std::vector&lt;uint64_t&gt;&gt; triangle(num_rows);
  for (uint32_t i = 0; i &lt; num_rows; i++) {
    triangle[i] = get_row(i);
  }

  return triangle;
}

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h2><a class="header" href="#reviews-20" id="reviews-20">Reviews</a></h2>
<table style="float:left">
<thead>
<tr><th>How easy to understand?</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>A newcomer to C++ could grok it                </td><td>XXXX</td></tr>
<tr><td>A junior dev should be fine with it            </td><td></td></tr>
<tr><td>Most devs would be comfortable                 </td><td></td></tr>
<tr><td>Experienced C++ developers only                </td><td></td></tr>
<tr><td>You'd need to be on the C++ standards committee</td><td></td></tr>
</tbody>
<thead>
<tr><th>Maintainability</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>Wouldn't touch it with a barge pole                         </td><td>X</td></tr>
<tr><td>I could manage it I had to, but would worry I might break it</td><td></td></tr>
<tr><td>No problem at all                                           </td><td>XXX</td></tr>
</tbody>
<thead>
<tr><th>Performance compared to simple nested loop and vectors</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>Much worse</td><td></td></tr>
<tr><td>A bit worse</td><td></td></tr>
<tr><td>About the same</td><td>X</td></tr>
<tr><td>A bit faster</td><td>X</td></tr>
<tr><td>Warp factor 9</td><td>XX</td></tr>
</tbody>
<thead>
<tr><th>New things learned</th><th></th></tr>
</thead>
<tbody>
<tr><td>People can and will overfit their solution to the provided specification, if they can get away with it, so beware!</td><td></td></tr>
<tr><td>This is the obvious 0(1) solution for a-prior limited numbers of rows. perhaps it was built to pass the tests rather that leverage the tests. I suspect this one was written to make a point. So it will be lightening fast (fastest possible?) for n<=9 but hopeless above that. But if the tests were actually the specification (and n>9) was not needed then this is a good solution.</td><td></td></tr>
</tbody>
<thead>
<tr><th>Comments</th><th></th></tr>
</thead>
<tbody>
<tr><td>This was fun</td><td></td></tr>
<tr><td>So we could be more efficient by use of references passing and we could think further ahead  than rows==9. It is super easy to understand. So that lovely </td><td></td></tr>
</tbody>
</table>
<h1><a class="header" href="#porpoison" id="porpoison">Porpoison</a></h1>
<h4><a class="header" href="#header-21" id="header-21">Header</a></h4>
<pre><code class="language-c++">#pragma once

#include &lt;cstdint&gt;
#include &lt;tuple&gt;
#include &lt;type_traits&gt;
#include &lt;utility&gt;
#include &lt;vector&gt;

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

namespace detail {

// Wraps a pair of iterators into a type that can be used with range-for loops
// and range-based algorithms.
//
// Example:
//
// auto range = iter_range(begin_iter, end_iter);
// for (auto val : range) {
//   ...
// }
//
template &lt;typename Iter&gt;
struct iter_range : private std::pair&lt;Iter, Iter&gt; {
  constexpr iter_range(Iter first, Iter second)
      : std::pair&lt;Iter, Iter&gt;(first, second) {}
  constexpr Iter begin() const noexcept { return this-&gt;first; }
  constexpr Iter end() const noexcept { return this-&gt;second; }
};

// Iterates lazily over the values in a single row of pascal's triangle.
// Values are computed when the iterator is incremented.
//
// Example:
//
// auto it = pascal_column_iterator(4);
// REQUIRE(*it == 1); ++it;
// REQUIRE(*it == 4); ++it;
// REQUIRE(*it == 6); ++it;
// REQUIRE(*it == 4); ++it;
// REQUIRE(*it == 1); ++it;
class pascal_column_iterator {
 public:
  using iterator_category = std::input_iterator_tag;
  using value_type = uint64_t;
  using difference_type = std::ptrdiff_t;
  using pointer = value_type const*;
  using reference = value_type const&amp;;

  // When default constructed, behaves like an 'end' iterator that compares
  // equal with an exhausted pascal_column_iterator.
  constexpr pascal_column_iterator() = default;

  constexpr explicit pascal_column_iterator(uint32_t row) noexcept
      : row_(row), col_(0) {}

  constexpr value_type const&amp; operator*() const noexcept { return next_value_; }

  constexpr value_type const* operator-&gt;() const noexcept {
    return std::addressof(next_value_);
  }

  pascal_column_iterator&amp; operator++() noexcept {
    ++col_;
    next_value_ = next_value_ * (row_ + value_type(1) - col_) / col_;
    return (*this);
  }

  pascal_column_iterator operator++(int) noexcept {
    pascal_column_iterator temp(*this);
    ++(*this);
    return temp;
  }

  friend constexpr bool operator==(pascal_column_iterator const&amp; lhs,
                                   pascal_column_iterator const&amp; rhs) noexcept {
    if (lhs.exhausted() &amp;&amp; rhs.exhausted()) {
      return true;
    }
    return std::pair(lhs.row_, lhs.col_) == std::pair(rhs.row_, rhs.col_);
  }

  friend constexpr bool operator!=(pascal_column_iterator const&amp; lhs,
                                   pascal_column_iterator const&amp; rhs) noexcept {
    return !(lhs == rhs);
  }

 private:
  constexpr bool exhausted() const noexcept { return col_ &gt; row_; }

 private:
  value_type row_ = 0;
  value_type col_ =
      1;  // When col_ &gt; row_ the iterator is considered exhausted.
  value_type next_value_ = 1;
};

// Wraps a pair of pascal_column_iterators into a range-like object that
// can be used with a range-for loop.
//
// Example:
//
// // Iterates over all values in row 4 of pascal's triangle
// for (uint64_t val : pascal_column_range(4)) {
//   ...
// }
struct pascal_column_range : iter_range&lt;pascal_column_iterator&gt; {
  constexpr pascal_column_range() noexcept
      : iter_range(pascal_column_iterator(), pascal_column_iterator()) {}
  constexpr pascal_column_range(uint32_t row) noexcept
      : iter_range(pascal_column_iterator(row), pascal_column_iterator()) {}
};

// Iterates lazily over the rows of pascal's triangle. Each row is itself
// a lazy range over the columns/values in the row (represented by a
// pascal_column_range object)
//
// Example:
//
// auto it = pascal_row_iterator(4);
// REQUIRE(*it == pascal_column_range(0)); ++it;
// REQUIRE(*it == pascal_column_range(1)); ++it;
// REQUIRE(*it == pascal_column_range(2)); ++it;
// REQUIRE(*it == pascal_column_range(3)); ++it;
class pascal_row_iterator {
 public:
  using iterator_category = std::input_iterator_tag;
  using value_type = pascal_column_range;
  using difference_type = std::ptrdiff_t;
  using pointer = value_type const*;
  using reference = value_type const&amp;;

  // When default constructed, behaves like an 'end' iterator that compares
  // equal with an exhausted pascal_row_iterator.
  constexpr pascal_row_iterator() = default;

  constexpr explicit pascal_row_iterator(uint32_t num_rows) noexcept
      : num_rows_(num_rows), next_value_(pascal_column_range(0)) {}

  constexpr value_type const&amp; operator*() const noexcept { return next_value_; }

  constexpr value_type const* operator-&gt;() const noexcept {
    return std::addressof(next_value_);
  }
  pascal_row_iterator&amp; operator++() noexcept {
    next_value_ = pascal_column_range(++row_);
    return (*this);
  }

  pascal_row_iterator operator++(int) noexcept {
    pascal_row_iterator temp(*this);
    ++(*this);
    return temp;
  }

  friend constexpr bool operator==(pascal_row_iterator const&amp; lhs,
                                   pascal_row_iterator const&amp; rhs) noexcept {
    if (lhs.exhausted() &amp;&amp; rhs.exhausted()) {
      return true;
    }
    return std::tie(lhs.num_rows_, lhs.row_) ==
           std::tie(rhs.num_rows_, rhs.row_);
  }

  friend constexpr bool operator!=(pascal_row_iterator const&amp; lhs,
                                   pascal_row_iterator const&amp; rhs) noexcept {
    return !(lhs == rhs);
  }

 private:
  constexpr bool exhausted() const noexcept { return row_ &gt;= num_rows_; }

 private:
  uint32_t num_rows_ = 0;
  uint32_t row_ = 0;  // When row_ &gt;= num_rows_ the iterator is exhausted
  value_type next_value_ = pascal_column_range();
};

// Wraps a pair of pascal_row_iterators into a range-like object that
// can be used with a range-for loop.
//
// Example:
//
// // Iterates over first 4 rows of pascal's triangle
// for (auto row : pascal_row_range(4)) {
//   for (uint64_t val : row) {
//     ...
//   }
// }
struct pascal_row_range : iter_range&lt;pascal_row_iterator&gt; {
  constexpr pascal_row_range() noexcept
      : iter_range(pascal_row_iterator(), pascal_row_iterator()) {}
  constexpr pascal_row_range(uint32_t num_rows) noexcept
      : iter_range(pascal_row_iterator(num_rows), pascal_row_iterator()) {}
};

}  // namespace detail

using pascals_triangle = detail::pascal_row_range;

constexpr inline auto generate_rows(uint32_t num_rows) noexcept
    -&gt; pascals_triangle {
  return pascals_triangle(num_rows);
}

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h2><a class="header" href="#reviews-21" id="reviews-21">Reviews</a></h2>
<table style="float:left">
<thead>
<tr><th>How easy to understand?</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>A newcomer to C++ could grok it                </td><td></td></tr>
<tr><td>A junior dev should be fine with it            </td><td></td></tr>
<tr><td>Most devs would be comfortable                 </td><td></td></tr>
<tr><td>Experienced C++ developers only                </td><td>X</td></tr>
<tr><td>You'd need to be on the C++ standards committee</td><td>X</td></tr>
</tbody>
<thead>
<tr><th>Maintainability</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>Wouldn't touch it with a barge pole                         </td><td>X</td></tr>
<tr><td>I could manage it I had to, but would worry I might break it</td><td>X</td></tr>
<tr><td>No problem at all                                           </td><td></td></tr>
</tbody>
<thead>
<tr><th>Performance compared to simple nested loop and vectors</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>Much worse</td><td></td></tr>
<tr><td>A bit worse</td><td></td></tr>
<tr><td>About the same</td><td>X</td></tr>
<tr><td>A bit faster</td><td>X</td></tr>
<tr><td>Warp factor 9</td><td></td></tr>
</tbody>
<thead>
<tr><th>New things learned</th><th></th></tr>
</thead>
<tbody>
<tr><td>there are quite a few things that I *would* like to learn in this solution. will take a bit of time though to assimilate all the new knowledge and be able to use it.</td><td></td></tr>
<tr><td>How many lines of code one can write to solve a simple problem</td><td></td></tr>
</tbody>
<thead>
<tr><th>Comments</th><th></th></tr>
</thead>
<tbody>
<tr><td>except from the learning element, is there a value in such a complicated solution for a trivial problem?</td><td></td></tr>
</tbody>
</table>
<h1><a class="header" href="#archbanana" id="archbanana">ArchBanana</a></h1>
<h4><a class="header" href="#header-22" id="header-22">Header</a></h4>
<pre><code class="language-c++">#pragma once

#include &lt;cstdint&gt;
#include &lt;range/v3/all.hpp&gt;
#include &lt;vector&gt;

namespace SOLUTION_NAMESPACE {

namespace impl {
static auto sum = [](auto&amp;&amp; range) -&gt; uint64_t {
  return ranges::accumulate(range, uint64_t(0));
};

inline auto compute_next_row(std::vector&lt;uint64_t&gt; const&amp; prev_row)
    -&gt; std::vector&lt;uint64_t&gt; {
  namespace rv = ranges::views;
  auto middle = prev_row | rv::sliding(2) | rv::transform(sum);
  return rv::concat(rv::single(uint64_t(1)), middle, rv::single(uint64_t(1))) |
         ranges::to_vector;
}

}  // namespace impl

inline auto generate_rows(uint32_t num_rows) {
  auto pascal_rows = [stored_row = std::vector&lt;uint64_t&gt;{1}]() mutable {
    return std::exchange(stored_row, impl::compute_next_row(stored_row));
  };

  return ranges::views::generate_n(pascal_rows, num_rows);
}

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h4><a class="header" href="#header-with-extra-exposition-encluded-enside" id="header-with-extra-exposition-encluded-enside">Header with extra exposition encluded enside</a></h4>
<pre><code class="language-c++">#pragma once

#include &lt;cstdint&gt;
#include &lt;range/v3/all.hpp&gt;
#include &lt;vector&gt;

namespace SOLUTION_NAMESPACE {

namespace impl {

// Sum all of the elements in a range.
//
// # Example
//
// REQUIRE(sum(std::vector{1,2,3,4,5}) == 15);
static auto sum = [](auto&amp;&amp; range) -&gt; uint64_t {
  return ranges::accumulate(range, uint64_t(0));
};

// Given a valid row of pascal's triangle, computes the next row in the
// sequence.
//
// # Example
//
// auto result = compute_next_row(std::vector&lt;uint64_t&gt;{1,4,6,4,1});
// auto expected = std::vector&lt;uint64_t&gt;{1,5,10,10,5,1});
// REQUIRE(result == expected);
inline auto compute_next_row(std::vector&lt;uint64_t&gt; const&amp; prev_row)
    -&gt; std::vector&lt;uint64_t&gt; {
  namespace rv = ranges::views;

  // Sum adjacent pairs of internal elements
  // {1, 4, 6, 4, 1} -&gt; {{1,4}, {4,6}, {6,4}, {4,1}} -&gt; {5, 10, 10, 5}
  // prev_row         | sliding(win_size=2)           | transform(sum)
  auto middle = prev_row | rv::sliding(2) | rv::transform(sum);

  // Tack a 1 on to either end of the range and convert to a vector
  // {1} + {5, 10, 10, 5} + {1} -&gt; vector&lt;uint64_t&gt;{1, 5, 10, 10, 5, 1}
  return rv::concat(rv::single(uint64_t(1)), middle, rv::single(uint64_t(1))) |
         ranges::to_vector;
}

}  // namespace impl

// Generates pascal's triangle up to a requested number of rows
//
// # Example
//
// auto result = generate_rows(4);
// auto expected = std::vector&lt;std:vector&lt;uint64_t&gt;&gt;
//   {{1}, {1,1}, {1,2,1}, {1,3,3,1}};
// REQUIRE(result == expected);
inline auto generate_rows(uint32_t num_rows) {
  // On each call, this lambda will return the next row of the triangle.
  // When called, it returns the stored row, and computes one to be stored for
  // next time.
  // REQUIRE(pascal_rows() == {1});
  // REQUIRE(pascal_rows() == {1,1});
  // REQUIRE(pascal_rows() == {1,2,1});
  // etc...
  auto pascal_rows = [stored_row = std::vector&lt;uint64_t&gt;{1}]() mutable {
    return std::exchange(stored_row, impl::compute_next_row(stored_row));
  };

  // Apply generator function the requested number of times
  return ranges::views::generate_n(pascal_rows, num_rows);
}

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h2><a class="header" href="#bug-fix-" id="bug-fix-">Bug-fix 💥</a></h2>
<p>The original source of ArchBanana had its <code>sum</code> function implemented like this:</p>
<pre><code class="language-c++">static auto sum = [](auto&amp;&amp; range) { return ranges::accumulate(range, 0); }; 
</code></pre>
<p><a href="solutions/../property_based_testing.html">Property based testing</a> showed it to contain a
subtle overflow bug, so I took the liberty of adding a fix before benchmarking
the solution. That fix is included in the sources above, but wasn't in the
version that reviewers saw.</p>
<h2><a class="header" href="#reviews-22" id="reviews-22">Reviews</a></h2>
<table style="float:left">
<thead>
<tr><th>How easy to understand?</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>A newcomer to C++ could grok it                </td><td></td></tr>
<tr><td>A junior dev should be fine with it            </td><td></td></tr>
<tr><td>Most devs would be comfortable                 </td><td>XXXXX</td></tr>
<tr><td>Experienced C++ developers only                </td><td>XX</td></tr>
<tr><td>You'd need to be on the C++ standards committee</td><td></td></tr>
</tbody>
<thead>
<tr><th>Maintainability</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>Wouldn't touch it with a barge pole                         </td><td>X</td></tr>
<tr><td>I could manage it I had to, but would worry I might break it</td><td>XXX</td></tr>
<tr><td>No problem at all                                           </td><td>XXX</td></tr>
</tbody>
<thead>
<tr><th>Performance compared to simple nested loop and vectors</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>Much worse</td><td></td></tr>
<tr><td>A bit worse</td><td></td></tr>
<tr><td>About the same</td><td>XXX</td></tr>
<tr><td>A bit faster</td><td>XXXX</td></tr>
<tr><td>Warp factor 9</td><td></td></tr>
</tbody>
<thead>
<tr><th>New things learned</th><th></th></tr>
</thead>
<tbody>
<tr><td>Range Views!</td><td></td></tr>
<tr><td>Very nice use of range and std::exchange, neither of which I have used before.</td><td></td></tr>
<tr><td>Another ranges library!</td><td></td></tr>
<tr><td>Didn't know about the range library - is it good enough to use in production code?</td><td></td></tr>
<tr><td>https://ericniebler.github.io/range-v3/ is a thing</td><td></td></tr>
<tr><td>How the ranges library works or at least an example of it</td><td></td></tr>
</tbody>
<thead>
<tr><th>Comments</th><th></th></tr>
</thead>
<tbody>
<tr><td>Really interesting and elegant approach - if I was asked what this does when encountering this in the wild, I would have no idea</td><td></td></tr>
<tr><td>Very short and elegant. The only con is that I think it computes one more row than required (although not used), which may be unnecessary.</td><td></td></tr>
<tr><td>It's very interesting, but doesn't look like traditional C++ at all, meaning retraining for lots of devs to understand its patterns. It's compact, but doesn't take advantage of the symmetry of rows or the ability to compute them independently of each other, so doesn't seem to gain any performance for all the cool factor. Unless ranges does something multithreaded internally, which we can't tell just from reading the code.</td><td></td></tr>
<tr><td>Functionalarific!</td><td></td></tr>
</tbody>
</table>
<h1><a class="header" href="#archbanana2_arh" id="archbanana2_arh">ArchBanana2_arh</a></h1>
<h4><a class="header" href="#header-23" id="header-23">Header</a></h4>
<pre><code class="language-c++">#pragma once

#include &lt;cstdint&gt;
#include &lt;range/v3/algorithm/copy.hpp&gt;
#include &lt;range/v3/numeric/accumulate.hpp&gt;
#include &lt;range/v3/view/generate_n.hpp&gt;
#include &lt;range/v3/view/sliding.hpp&gt;
#include &lt;range/v3/view/span.hpp&gt;
#include &lt;range/v3/view/transform.hpp&gt;
#include &lt;vector&gt;

namespace SOLUTION_NAMESPACE {

namespace impl {
static auto sum = [](auto&amp;&amp; range) noexcept -&gt; uint64_t {
  return ranges::accumulate(range, uint64_t(0));
};

template &lt;typename InputRange, typename OutputIter&gt;
inline void compute_next_row(InputRange&amp;&amp; prev_row, OutputIter out) noexcept {
  namespace rv = ranges::views;
  auto const middle = prev_row | rv::sliding(2) | rv::transform(sum);
  ranges::copy(middle, out + 1);
}

class pascals_triangle {
  std::vector&lt;uint64_t&gt; prev_buffer_;
  std::vector&lt;uint64_t&gt; curr_buffer_;
  int64_t curr_row_len_{0};

 public:
  explicit pascals_triangle(uint32_t num_rows)
      : prev_buffer_(num_rows + 1, 1), curr_buffer_(num_rows + 1, 1) {}

  auto next_row() noexcept {
    ranges::swap(prev_buffer_, curr_buffer_);
    auto prev_row = ranges::span(prev_buffer_.data(), curr_row_len_);
    auto next_row = ranges::span(curr_buffer_.data(), ++curr_row_len_);

    compute_next_row(prev_row, curr_buffer_.begin());

    return next_row;
  }
};

}  // namespace impl

inline auto generate_rows(uint32_t num_rows) {
  return ranges::views::generate_n(
      [triangle = impl::pascals_triangle(num_rows)]() mutable {
        return triangle.next_row();
      },
      num_rows);
}

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h2><a class="header" href="#reviews-23" id="reviews-23">Reviews</a></h2>
<p>None. This is a modified version of <a href="solutions/./ArchBanana.html">ArchBanana</a> created by arh.</p>
<h1><a class="header" href="#evildoughnut" id="evildoughnut">EvilDoughnut</a></h1>
<h4><a class="header" href="#header-24" id="header-24">Header</a></h4>
<pre><code class="language-c++">#pragma once

#include &lt;cstdint&gt;

#include &quot;range/v3/all.hpp&quot;

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

inline auto generate_rows(uint32_t num_rows) noexcept {
  return ranges::views::for_each(
      ranges::views::iota(uint32_t{0}, num_rows), [](uint32_t row) {
        return ranges::yield(ranges::views::concat(
            ranges::views::single(uint32_t{1}),
            ranges::views::iota(uint32_t{1}, row + 1) |
                ranges::views::transform(
                    [row, p = uint64_t{1}](uint32_t col) mutable {
                      p = (p * (row - col + 1)) / col;
                      return p;
                    })));
      });
}

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h2><a class="header" href="#reviews-24" id="reviews-24">Reviews</a></h2>
<table style="float:left">
<thead>
<tr><th>How easy to understand?</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>A newcomer to C++ could grok it                </td><td></td></tr>
<tr><td>A junior dev should be fine with it            </td><td></td></tr>
<tr><td>Most devs would be comfortable                 </td><td></td></tr>
<tr><td>Experienced C++ developers only                </td><td>XX</td></tr>
<tr><td>You'd need to be on the C++ standards committee</td><td>X</td></tr>
</tbody>
<thead>
<tr><th>Maintainability</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>Wouldn't touch it with a barge pole                         </td><td>X</td></tr>
<tr><td>I could manage it I had to, but would worry I might break it</td><td>XX</td></tr>
<tr><td>No problem at all                                           </td><td></td></tr>
</tbody>
<thead>
<tr><th>Performance compared to simple nested loop and vectors</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>Much worse</td><td></td></tr>
<tr><td>A bit worse</td><td></td></tr>
<tr><td>About the same</td><td></td></tr>
<tr><td>A bit faster</td><td>XX</td></tr>
<tr><td>Warp factor 9</td><td>X</td></tr>
</tbody>
<thead>
<tr><th>New things learned</th><th></th></tr>
</thead>
<tbody>
<tr><td>Ok - yeah, groovy, there is detail in there I would have to look up especially around the yield. But at least each row is being calculated as a series and there is a counting iterator in there  because nCk needs "k". Thats elegant. Not sure though this is the clearest way to code this. Its hard to pull apart the nested lambdas.</td><td></td></tr>
<tr><td>Range library (I still have to check it out so I get the most of it though)</td><td></td></tr>
<tr><td>A new level of nesting beyond that thought possible by man</td><td></td></tr>
</tbody>
<thead>
<tr><th>Comments</th><th></th></tr>
</thead>
<tbody>
<tr><td>
* its linear time so I think each row could be done in parallels</br>
* there is no overflow check</td><td></td></tr>
</tbody>
</table>
<h1><a class="header" href="#frostymongoose" id="frostymongoose">FrostyMongoose</a></h1>
<h4><a class="header" href="#header-25" id="header-25">Header</a></h4>
<pre><code class="language-c++">#pragma once
#include &lt;cstdint&gt;
#include &lt;cstdlib&gt;
#include &lt;functional&gt;
#include &lt;iterator&gt;
#include &lt;numeric&gt;
#include &lt;vector&gt;

#include &quot;range/v3/all.hpp&quot;

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

struct Rows {
  Rows(uint32_t n) { row.reserve(n / 2 + 1); }
  auto operator()() noexcept {
    namespace rv = ranges::views;
    if (size(row) == a) {
      row.push_back(empty(row) ? 1 : row.back());
    } else {
      ++a;
    }
    std::adjacent_difference(begin(row), end(row), begin(row), std::plus&lt;&gt;{});
    return rv::concat(row, row | rv::slice(decltype(a){0}, a) | rv::reverse);
  }
  std::vector&lt;uint64_t&gt; row;
  std::vector&lt;uint64_t&gt;::size_type a = 0;
};

inline auto generate_rows(uint32_t num_rows) noexcept {
  namespace rv = ranges::views;
  return rv::generate_n(Rows{num_rows}, num_rows);
}

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h2><a class="header" href="#reviews-25" id="reviews-25">Reviews</a></h2>
<p>There aren't any reviews of this one, because it was received 8 months after the
deadline. It does an interesting thing where it computes only half of each row
and then concatenates a lazy forward-traversal with a lazy reverse traversal,
thus producing values for a complete row.</p>
<p>It performs well, but not as well as the high-performing range-v3 solutions that
compute a whole row of values. I suspect that's because the concatenated range
requires an extra branch on every increment to determine which sub-range to
traverse.</p>
<h1><a class="header" href="#proteus" id="proteus">Proteus</a></h1>
<h4><a class="header" href="#header-26" id="header-26">Header</a></h4>
<pre><code class="language-c++">#pragma once

#include SOLUTION_HEADER

#include &lt;algorithm&gt;
#include &lt;cassert&gt;
#include &lt;range/v3/all.hpp&gt;
#include &lt;vector&gt;

namespace SOLUTION_NAMESPACE {

namespace detail {

class PascalRow {
  std::vector&lt;uint64_t&gt; row_values_;
  int row_ = 0;

 public:
  explicit PascalRow(uint32_t num_rows) : row_values_(num_rows + 1, 0) {
    row_values_[0] = 1;
  }

  // Compute values for next row and return them as an iterable range.
  // Invalidates all existing iterators returned by begin and end.
  auto operator()() noexcept -&gt; PascalRow const&amp; {
    assert(row_ &lt; static_cast&lt;int&gt;(row_values_.size()));

    // Compute new values in-place by summing pairs of previous values.
    // Work backwards to avoid overwriting values before we've used them.
    auto row_end = next(row_values_.begin(), row_ + 1);
    auto const input_begin = std::reverse_iterator(row_end);
    auto const input_end = std::reverse_iterator(next(row_values_.begin()));
    auto const output_begin = std::reverse_iterator(row_end);

    std::transform(input_begin, input_end,  // First input range
                   next(input_begin),       // Second input range
                   output_begin,            // Output range
                   std::plus&lt;&gt;{});

    ++row_;
    return *this;
  }

  auto begin() const noexcept { return cbegin(row_values_); }
  auto end() const noexcept { return next(cbegin(row_values_), row_); }
};

}  // namespace detail

inline auto generate_rows(uint32_t num_rows) {
  using ranges::views::generate_n;
  return generate_n(detail::PascalRow(num_rows), num_rows);
}

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h2><a class="header" href="#reviews-26" id="reviews-26">Reviews</a></h2>
<table style="float:left">
<thead>
<tr><th>How easy to understand?</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>A newcomer to C++ could grok it                </td><td></td></tr>
<tr><td>A junior dev should be fine with it            </td><td></td></tr>
<tr><td>Most devs would be comfortable                 </td><td>XX</td></tr>
<tr><td>Experienced C++ developers only                </td><td>X</td></tr>
<tr><td>You'd need to be on the C++ standards committee</td><td></td></tr>
</tbody>
<thead>
<tr><th>Maintainability</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>Wouldn't touch it with a barge pole                         </td><td></td></tr>
<tr><td>I could manage it I had to, but would worry I might break it</td><td>XXX</td></tr>
<tr><td>No problem at all                                           </td><td></td></tr>
</tbody>
<thead>
<tr><th>Performance compared to simple nested loop and vectors</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>Much worse</td><td></td></tr>
<tr><td>A bit worse</td><td></td></tr>
<tr><td>About the same</td><td>XX</td></tr>
<tr><td>A bit faster</td><td>X</td></tr>
<tr><td>Warp factor 9</td><td></td></tr>
</tbody>
<thead>
<tr><th>New things learned</th><th></th></tr>
</thead>
<tbody>
<tr><td>It was useful to see ranges::views::generate_n used in practice (I haven't used range before) and I found the way the rows were constructed in-place interesting.</td><td></td></tr>
</tbody>
<thead>
<tr><th>Comments</th><th></th></tr>
</thead>
<tbody>
<tr><td>Nice and clean implementation, but very un-clear who is calling who</td><td></td></tr>
<tr><td>I struggled to understand what was going on straight away, maybe a few more comments would have been helpful.</td><td></td></tr>
</tbody>
</table>
<h1><a class="header" href="#erwin" id="erwin">Erwin</a></h1>
<h4><a class="header" href="#header-27" id="header-27">Header</a></h4>
<pre><code class="language-c++">#pragma once

#include &lt;array&gt;
#include &lt;cstdio&gt;
#include &lt;vector&gt;

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

template &lt;int N&gt;
struct Factorial {
  enum { value = N * Factorial&lt;N - 1&gt;::value };
};

template &lt;&gt;
struct Factorial&lt;0&gt; {
  enum { value = 1 };
};

/**
 * Variadic template for a recursive helper struct.
 */
template &lt;int TABLE_SIZE, int INDEX = 0, int... D&gt;
struct Helper : Helper&lt;TABLE_SIZE,
                       INDEX + 1,
                       D...,
                       Factorial&lt;TABLE_SIZE - 1&gt;::value /
                           (Factorial&lt;TABLE_SIZE - 1 - INDEX&gt;::value *
                            Factorial&lt;INDEX&gt;::value)&gt; {};

/**
 * Specialization of the template to end the recursion when the table size reaches TABLE_SIZE.
 */
template &lt;int TABLE_SIZE, int... D&gt;
struct Helper&lt;TABLE_SIZE, TABLE_SIZE, D...&gt; {
  static constexpr std::array&lt;int, TABLE_SIZE&gt; table = {D...};
};

constexpr std::array&lt;int, 1&gt; table1 = Helper&lt;1&gt;::table;
constexpr std::array&lt;int, 2&gt; table2 = Helper&lt;2&gt;::table;
constexpr std::array&lt;int, 3&gt; table3 = Helper&lt;3&gt;::table;
constexpr std::array&lt;int, 4&gt; table4 = Helper&lt;4&gt;::table;
constexpr std::array&lt;int, 5&gt; table5 = Helper&lt;5&gt;::table;
constexpr std::array&lt;int, 6&gt; table6 = Helper&lt;6&gt;::table;
constexpr std::array&lt;int, 7&gt; table7 = Helper&lt;7&gt;::table;
constexpr std::array&lt;int, 8&gt; table8 = Helper&lt;8&gt;::table;
constexpr std::array&lt;int, 9&gt; table9 = Helper&lt;9&gt;::table;
constexpr std::array&lt;int, 10&gt; table10 = Helper&lt;10&gt;::table;

inline std::vector&lt;std::vector&lt;uint64_t&gt;&gt; result = {
    std::vector&lt;uint64_t&gt;(table1.begin(), table1.end()),
    std::vector&lt;uint64_t&gt;(table2.begin(), table2.end()),
    std::vector&lt;uint64_t&gt;(table3.begin(), table3.end()),
    std::vector&lt;uint64_t&gt;(table4.begin(), table4.end()),
    std::vector&lt;uint64_t&gt;(table5.begin(), table5.end()),
    std::vector&lt;uint64_t&gt;(table6.begin(), table6.end()),
    std::vector&lt;uint64_t&gt;(table7.begin(), table7.end()),
    std::vector&lt;uint64_t&gt;(table8.begin(), table8.end()),
    std::vector&lt;uint64_t&gt;(table9.begin(), table9.end()),
    std::vector&lt;uint64_t&gt;(table10.begin(), table10.end()),
};

inline auto generate_rows(uint32_t num_rows)
    -&gt; std::vector&lt;std::vector&lt;uint64_t&gt;&gt; {
  return std::vector&lt;std::vector&lt;uint64_t&gt;&gt;(result.begin(),
                                            result.begin() + num_rows);
}

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h2><a class="header" href="#reviews-27" id="reviews-27">Reviews</a></h2>
<table style="float:left">
<thead>
<tr><th>How easy to understand?</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>A newcomer to C++ could grok it                </td><td></td></tr>
<tr><td>A junior dev should be fine with it            </td><td>X</td></tr>
<tr><td>Most devs would be comfortable                 </td><td></td></tr>
<tr><td>Experienced C++ developers only                </td><td>XX</td></tr>
<tr><td>You'd need to be on the C++ standards committee</td><td></td></tr>
</tbody>
<thead>
<tr><th>Maintainability</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>Wouldn't touch it with a barge pole                         </td><td>X</td></tr>
<tr><td>I could manage it I had to, but would worry I might break it</td><td>XX</td></tr>
<tr><td>No problem at all                                           </td><td></td></tr>
</tbody>
<thead>
<tr><th>Performance compared to simple nested loop and vectors</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>Much worse</td><td></td></tr>
<tr><td>A bit worse</td><td></td></tr>
<tr><td>About the same</td><td></td></tr>
<tr><td>A bit faster</td><td>X</td></tr>
<tr><td>Warp factor 9</td><td>XX</td></tr>
</tbody>
<thead>
<tr><th>New things learned</th><th></th></tr>
</thead>
<tbody>
<tr><td>Template recursion technique</td><td></td></tr>
</tbody>
<thead>
<tr><th>Comments</th><th></th></tr>
</thead>
<tbody>
<tr><td>It looks fast - but what does it even do?</td><td></td></tr>
<tr><td>I wonder about compilation time for this one.</td><td></td></tr>
</tbody>
</table>
<h1><a class="header" href="#firefly" id="firefly">FireFly</a></h1>
<h4><a class="header" href="#header-28" id="header-28">Header</a></h4>
<pre><code class="language-c++">#pragma once

#include &lt;cstdint&gt;
#include &lt;range/v3/all.hpp&gt;

namespace SOLUTION_NAMESPACE {  // Please do not modify this line

class pascals_triangle : public ranges::view_facade&lt;pascals_triangle&gt; {
 public:
  friend ranges::range_access;
  pascals_triangle() = default;
  pascals_triangle(uint64_t end_row) : end_size_(end_row + 1) {}

  auto read() const { return ranges::make_subrange(begin_, begin_ + size_); }
  void next() { begin_ += size_++; }
  bool equal(const pascals_triangle&amp; other) const {
    return size_ == other.size_;
  }
  bool equal(ranges::default_sentinel_t) const { return size_ == end_size_; }

 private:
  uint64_t size_{1};
  uint64_t end_size_{1};
  const uint64_t* begin_{values};

  static const uint64_t values[];
};

inline auto generate_rows(uint64_t num_rows) {
  return pascals_triangle(num_rows);
}

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h4><a class="header" href="#source-21" id="source-21">Source</a></h4>
<pre><code class="language-c++">#include SOLUTION_HEADER

namespace SOLUTION_NAMESPACE {

const uint64_t pascals_triangle::values[] = {  //
    1,                                         //
    1, 1,                                      //
    1, 2, 1,                                   //
    1, 3, 3,  1,                               //
    1, 4, 6,  4,  1,                           //
    1, 5, 10, 10, 5,   1,                      //
    1, 6, 15, 20, 15,  6,   1,                 //
    1, 7, 21, 35, 35,  21,  7,  1,             //
    1, 8, 28, 56, 70,  56,  28, 8,  1,         //
    1, 9, 36, 84, 126, 126, 84, 36, 9, 1};     //

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h2><a class="header" href="#reviews-28" id="reviews-28">Reviews</a></h2>
<table style="float:left">
<thead>
<tr><th>How easy to understand?</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>A newcomer to C++ could grok it                </td><td></td></tr>
<tr><td>A junior dev should be fine with it            </td><td></td></tr>
<tr><td>Most devs would be comfortable                 </td><td></td></tr>
<tr><td>Experienced C++ developers only                </td><td>X</td></tr>
<tr><td>You'd need to be on the C++ standards committee</td><td></td></tr>
</tbody>
<thead>
<tr><th>Maintainability</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>Wouldn't touch it with a barge pole                         </td><td></td></tr>
<tr><td>I could manage it I had to, but would worry I might break it</td><td>X</td></tr>
<tr><td>No problem at all                                           </td><td></td></tr>
</tbody>
<thead>
<tr><th>Performance compared to simple nested loop and vectors</th><th>Votes</th></tr>
</thead>
<tbody>
<tr><td>Much worse</td><td></td></tr>
<tr><td>A bit worse</td><td></td></tr>
<tr><td>About the same</td><td></td></tr>
<tr><td>A bit faster</td><td></td></tr>
<tr><td>Warp factor 9</td><td>X</td></tr>
</tbody>
<thead>
<tr><th>New things learned</th><th></th></tr>
</thead>
<tbody>
<tr><td>About ranges::view_facade</td><td></td></tr>
</tbody>
<thead>
<tr><th>Comments</th><th></th></tr>
</thead>
<tbody>
<tr><td></td><td></td></tr>
</tbody>
</table>
<h1><a class="header" href="#lightninghippo_arh" id="lightninghippo_arh">LightningHippo_arh</a></h1>
<h4><a class="header" href="#header-29" id="header-29">Header</a></h4>
<pre><code class="language-c++">#pragma once

#include &lt;array&gt;
#include &lt;cassert&gt;
#include &lt;cstdint&gt;
#include &lt;range/v3/view/subrange.hpp&gt;
#include &lt;range/v3/view_facade.hpp&gt;

namespace SOLUTION_NAMESPACE {
namespace detail {

// -----------------------------------------------------------------------------
// Compute number of elements in a triangle of a given number of rows
constexpr auto num_elements_total(uint64_t num_rows) -&gt; uint64_t {
  return (num_rows * (num_rows + 1)) / 2;
}

// -----------------------------------------------------------------------------
constexpr uint32_t max_rows = 63;
extern std::array&lt;uint64_t, num_elements_total(max_rows)&gt; const&amp;
    triangle_values;

// -----------------------------------------------------------------------------
// A lightweight view onto the rows of a pre-computed triangle that is stored
// in a single contiguous array.
// -----------------------------------------------------------------------------
class pascals_triangle : public ranges::view_facade&lt;pascals_triangle&gt; {
  uint64_t const* begin_;
  int64_t num_rows_;
  int64_t row_ = 0;

 public:
  pascals_triangle() = default;
  pascals_triangle(uint64_t const* first, uint32_t num_rows)
      : begin_(first), num_rows_(num_rows) {}

  auto read() const { return ranges::make_subrange(begin_, begin_ + row_ + 1); }
  void next() {
    ++row_;
    begin_ += row_;
  }
  bool equal(const pascals_triangle&amp; other) const {
    return begin_ == other.begin_;
  }
  bool equal(ranges::default_sentinel_t) const { return row_ &gt;= num_rows_; }
};

}  // namespace detail

inline auto generate_rows(uint32_t num_rows) noexcept
    -&gt; detail::pascals_triangle {
  assert(num_rows &lt;= detail::max_rows);

  return detail::pascals_triangle(detail::triangle_values.begin(), num_rows);
}

}  // namespace SOLUTION_NAMESPACE
</code></pre>
<h4><a class="header" href="#source-22" id="source-22">Source</a></h4>
<pre><code class="language-c++">#include SOLUTION_HEADER

#include &lt;pt/algorithms.h&gt;

#include &lt;range/v3/view/span.hpp&gt;

namespace SOLUTION_NAMESPACE::detail {

namespace {
// -----------------------------------------------------------------------------
// Compute values of a row, given the previous row
constexpr void compute_next_row(ranges::span&lt;uint64_t const&gt; prev_row,
                                ranges::span&lt;uint64_t&gt; next_row) {
  assert(next_row.size() == prev_row.size() + 1);

  next_row.front() = 1;

  // Sum adjacent elements from the previous row.
  pt::transform_adjacent_pairs(prev_row.begin(),      // Input begin
                               prev_row.end(),        // Input end
                               next_row.begin() + 1,  // Output begin
                               std::plus&lt;&gt;{});

  next_row.back() = 1;
}

// -----------------------------------------------------------------------------
// Stores a lookup table of pascal triangle rows.
// Can be constructed at compile time if required.
// -----------------------------------------------------------------------------
template &lt;uint32_t max_rows&gt;
struct pascal_lookup_table {
  constexpr pascal_lookup_table() noexcept {
    auto next_row = ranges::span(values.begin(), 0);

    while (next_row.size() &lt; max_rows) {
      auto prev_row = pt::exchange(
          next_row, ranges::span(next_row.end(), next_row.size() + 1));

      compute_next_row(prev_row, next_row);
    }
  }

  std::array&lt;uint64_t, num_elements_total(max_rows)&gt; values{};
};

// Compute pascals triangle at compile time. We're doing this inside a separate
// translation unit so that the work only needs to get done once.
constexpr auto triangle_full = pascal_lookup_table&lt;max_rows&gt;();
}  // namespace

// Make the computed values available to other translation units
std::array&lt;uint64_t, num_elements_total(max_rows)&gt; const&amp; triangle_values =
    triangle_full.values;

}  // namespace SOLUTION_NAMESPACE::detail
</code></pre>
<h4><a class="header" href="#source-of-ancillary-ptalgorithmsh-header" id="source-of-ancillary-ptalgorithmsh-header">Source of ancillary <code>pt/algorithms.h</code> header</a></h4>
<p>These are separately tested library functions that should be treated as we'd
treat STL algorithms. The complexity (or simplicity) of their implementations
should not be conflated with the 'maintainability' of the code that calls
them. I've only included their source here for completeness.</p>
<p>They actually replicate the functionality of existing STL algorithms, but add
the <code>constexpr</code> keyword to allow them to be executed at compile-time.</p>
<pre><code class="language-c++">#pragma once
#include &lt;iterator&gt;

namespace pt {

template &lt;typename InputIt, typename OutputIt, typename BinaryOp&gt;
constexpr OutputIt transform_adjacent_pairs(InputIt first,
                                            InputIt last,
                                            OutputIt d_first,
                                            BinaryOp op) {
  if (first == last)
    return d_first;

  typedef typename std::iterator_traits&lt;InputIt&gt;::value_type value_t;
  value_t acc = *first;
  while (++first != last) {
    value_t val = *first;
    *d_first++ = op(val, std::move(acc));
    acc = std::move(val);
  }
  return ++d_first;
}

template &lt;class T, class U = T&gt;
constexpr T exchange(T&amp; obj, U&amp;&amp; new_value) {
  T old_value = std::move(obj);
  obj = std::forward&lt;U&gt;(new_value);
  return old_value;
}

}  // namespace pt
</code></pre>
<h2><a class="header" href="#reviews-29" id="reviews-29">Reviews</a></h2>
<p>None. This was created by arh by taking useful bits from all the submitted
solutions.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                

                
            </nav>

        </div>

        

        

        

        
        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        

        

        
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        
        
        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
        
        

    </body>
</html>
